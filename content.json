[{"title":"Powershell 完美配置","path":"/article/powershell-perfect-setup/","text":"坑边闲话：忆往昔岁月，不堪回首，伟大的 Windows 竟然拿不出一个像样的终端模拟器。mintty.exe 和封装后的 cmder 之流，总是有各种问题，而且不兼容 emoji 字符。后来，全网 Windows 用户随着一个华丽的广告沸腾了，微软宣布了终端软件 Windows Terminal 的开发进程，而且开源！如今，Windows Terminal 正式版已经陪伴我们走过了很长一段时间，其稳定性和易用性已经非常不错，关键是颜值相当高。如果你是一个追求完美与和谐的 User，那么请跟上我的步伐，我们重新起航！ ** 重要提醒：** 本文的所有配置经过无数网友的多重考验，请勿在配置过程中突发奇想而走弯路，一定要认真阅读每一个段落、每一个句子！ 安装 Windows Terminal 相信这一步对大多数人不构成任何困难，去 Microsoft Store 搜索下载就是了。 该项难度系数：⭐ 安装字体 这里仅推荐一款字体：Fira Code Nerd Font。该字体支持 ligature 连字功能，而且是一款专门为代码显示准备的字体，该字体也支持很多有趣的特殊字符，非常适合在终端里使用。该字体开源，广受海内外程序员好评！ 单击此处从 GitHub 下载。 装上该字体，即可进入下一步。 该项难度系数：⭐⭐ （或许有人登 Github 有网络问题，请自行解决。） 安装新款 Powershell Core 首先声明，我们这儿用的 Powershell 与 Windows 自带的 Powershell 是完全不同的两个东西，除了功能相似和名字相同，两者内在已经天差地别。 现阶段 Windows 11 自带的 Powershell 错误提示冗长，颜值低，速度慢，总之就是不太值得去用了。 那么 Powershell Core 是什么呢？这是伟大的.Net Core 跨平台战略的一个重要组成部分，微软设想，要让强大的.Net 在所有平台上通用，让这么强大的 Powershell 在所有平台上都能用，古老的 bash 可以退休了！ 基于以上愿景，微软开始了漫长而辉煌的征程。 在 https://github.com/PowerShell/PowerShell/releases 这个 GitHub 链接里，有目前 Powershell 的最新版，我建议你从 release 里选个最新的版本。 直接单击此处下载 x86-64 Windows 64 位.msi 安装包。 2022 年下半年开始，可以到微软商店下载了。 直接在商店中搜索 Powershell 该项难度系数：⭐ 安装 PowerShell 插件 这一步是灵魂。 直接上代码：打开刚装好的新版 PowerShell，执行以下命令。 12# 安装 oh-my-posh 包，让你的命令行更酷炫、优雅winget install JanDeDobbeleer.OhMyPosh -s winget 安装过程可能有点慢，好像卡住了一样，但是请耐心等待几分钟。等不及的同学自行搜索科学方法访问 GitHub. oh my posh 官网 - https://ohmyposh.dev/ 该项难度系数：⭐ 配置 Windows Terminal 这一项也是灵魂。 只有新款 Powershell 而没有 Windows Terminal，好比吃肉不放盐。 简单点，直接上配置代码，遇到不懂的地方，自己读注释。记得将此设置默认配置（代码已经给出）。 12345678910111213141516171819// 默认的配置就是我们的新 powershell（重要！！！）\"defaultProfile\": \"{574e775e-4f2a-5b96-ac1e-a2962a402336}\",{ // 键标记 \"guid\": \"{574e775e-4f2a-5b96-ac1e-a2962a402336}\", \"name\": \"PowerShell\", \"source\": \"Windows.Terminal.PowershellCore\", // 行为 \"closeOnExit\": true, \"commandline\": \"pwsh -nol\", \"hidden\": false, // 外观 \"fontFace\": \"MesloLGM NF\", \"fontSize\": 14, \"padding\": \"5, 5, 20, 25\", // 颜色主题 \"colorScheme\": \"MyStyle\"}, 同时附上 Homebrew 配色，该配色经过我改良。 1234567891011121314151617181920212223{ \"background\": \"#282C34\", \"black\": \"#282C34\", \"blue\": \"#409EFF\", \"brightBlack\": \"#EC7259\", \"brightBlue\": \"#729FCF\", \"brightCyan\": \"#56B6C2\", \"brightGreen\": \"#98C379\", \"brightPurple\": \"#C678DD\", \"brightRed\": \"#CB0000\", \"brightWhite\": \"#DCDFE4\", \"brightYellow\": \"#E5C07B\", \"cursorColor\": \"#FFFFFF\", \"cyan\": \"#56B6C2\", \"foreground\": \"#FFFFFF\", \"green\": \"#4E9A06\", \"name\": \"MyStyle\", \"purple\": \"#C678DD\", \"red\": \"#E06C75\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#DCDFE4\", \"yellow\": \"#E5C07B\"}, 特别注意，用其他配色可能降低颜值。 完整配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352{ \"$help\": \"https://aka.ms/terminal-documentation\", \"$schema\": \"https://aka.ms/terminal-profiles-schema\", \"actions\": [ { \"command\": { \"action\": \"copy\", \"singleLine\": false }, \"keys\": \"ctrl+c\" }, { \"command\": \"paste\", \"keys\": \"ctrl+v\" }, { \"command\": \"find\", \"keys\": \"ctrl+shift+f\" }, { \"command\": { \"action\": \"splitPane\", \"split\": \"auto\", \"splitMode\": \"duplicate\" }, \"keys\": \"alt+shift+d\" } ], \"copyFormatting\": \"none\", \"copyOnSelect\": false, \"defaultProfile\": \"{574e775e-4f2a-5b96-ac1e-a2962a402336}\", \"launchMode\": \"maximized\", \"profiles\": { \"defaults\": { \"font\": { \"face\": \"MesloLGM NF\", \"size\": 14, \"padding\": \"5, 5, 20, 25\" }, \"colorScheme\": \"MyStyle\" }, \"list\": [ { \"commandline\": \"%SystemRoot%\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\", \"guid\": \"{61c54bbd-c2c6-5271-96e7-009a87ff44bf}\", \"hidden\": true, \"name\": \"Windows PowerShell\" }, { \"guid\": \"{574e775e-4f2a-5b96-ac1e-a2962a402336}\", \"hidden\": false, \"name\": \"PowerShell\", \"commandline\": \"pwsh -nol\", \"source\": \"Windows.Terminal.PowershellCore\" }, { \"commandline\": \"%SystemRoot%\\\\System32\\\\cmd.exe\", \"guid\": \"{0caa0dad-35be-5f56-a8ff-afceeeaa6101}\", \"hidden\": false, \"name\": \"\\u547d\\u4ee4\\u63d0\\u793a\\u7b26\" }, { \"guid\": \"{b453ae62-4e3d-5e58-b989-0a998ec441b8}\", \"hidden\": true, \"name\": \"Azure Cloud Shell\", \"source\": \"Windows.Terminal.Azure\" }, { \"guid\": \"{0cf0707b-7ef7-5a76-9608-ee3d44b4be46}\", \"hidden\": false, \"name\": \"Developer Command Prompt for VS 2022\", \"source\": \"Windows.Terminal.VisualStudio\" }, { \"guid\": \"{99575e71-49f6-5357-bc8b-ed308f81a80c}\", \"hidden\": false, \"name\": \"Developer PowerShell for VS 2022\", \"source\": \"Windows.Terminal.VisualStudio\" }, { \"guid\": \"{16208362-94fc-5b1f-a491-5b2624d5ab56}\", \"hidden\": true, \"name\": \"Visual Studio Debug Console\", \"source\": \"VSDebugConsole\" } ] }, \"schemes\": [ { \"background\": \"#283033\", \"black\": \"#000000\", \"blue\": \"#6666E9\", \"brightBlack\": \"#666666\", \"brightBlue\": \"#0000FF\", \"brightCyan\": \"#00E5E5\", \"brightGreen\": \"#00D900\", \"brightPurple\": \"#E500E5\", \"brightRed\": \"#E50000\", \"brightWhite\": \"#E5E5E5\", \"brightYellow\": \"#E5E500\", \"cursorColor\": \"#FFFFFF\", \"cyan\": \"#00A6B2\", \"foreground\": \"#00FF00\", \"green\": \"#00A600\", \"name\": \"Homebrew\", \"purple\": \"#B200B2\", \"red\": \"#FC5275\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#BFBFBF\", \"yellow\": \"#999900\" }, { \"background\": \"#282C34\", \"black\": \"#282C34\", \"blue\": \"#409EFF\", \"brightBlack\": \"#EC7259\", \"brightBlue\": \"#729FCF\", \"brightCyan\": \"#56B6C2\", \"brightGreen\": \"#98C379\", \"brightPurple\": \"#C678DD\", \"brightRed\": \"#CB0000\", \"brightWhite\": \"#DCDFE4\", \"brightYellow\": \"#E5C07B\", \"cursorColor\": \"#FFFFFF\", \"cyan\": \"#56B6C2\", \"foreground\": \"#FFFFFF\", \"green\": \"#4E9A06\", \"name\": \"MyStyle\", \"purple\": \"#C678DD\", \"red\": \"#E06C75\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#DCDFE4\", \"yellow\": \"#E5C07B\" }, { \"background\": \"#0C0C0C\", \"black\": \"#0C0C0C\", \"blue\": \"#0037DA\", \"brightBlack\": \"#767676\", \"brightBlue\": \"#3B78FF\", \"brightCyan\": \"#61D6D6\", \"brightGreen\": \"#16C60C\", \"brightPurple\": \"#B4009E\", \"brightRed\": \"#E74856\", \"brightWhite\": \"#F2F2F2\", \"brightYellow\": \"#F9F1A5\", \"cursorColor\": \"#FFFFFF\", \"cyan\": \"#3A96DD\", \"foreground\": \"#CCCCCC\", \"green\": \"#13A10E\", \"name\": \"Campbell\", \"purple\": \"#881798\", \"red\": \"#C50F1F\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#CCCCCC\", \"yellow\": \"#C19C00\" }, { \"background\": \"#012456\", \"black\": \"#0C0C0C\", \"blue\": \"#0037DA\", \"brightBlack\": \"#767676\", \"brightBlue\": \"#3B78FF\", \"brightCyan\": \"#61D6D6\", \"brightGreen\": \"#16C60C\", \"brightPurple\": \"#B4009E\", \"brightRed\": \"#E74856\", \"brightWhite\": \"#F2F2F2\", \"brightYellow\": \"#F9F1A5\", \"cursorColor\": \"#FFFFFF\", \"cyan\": \"#3A96DD\", \"foreground\": \"#CCCCCC\", \"green\": \"#13A10E\", \"name\": \"Campbell Powershell\", \"purple\": \"#881798\", \"red\": \"#C50F1F\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#CCCCCC\", \"yellow\": \"#C19C00\" }, { \"background\": \"#282C34\", \"black\": \"#282C34\", \"blue\": \"#61AFEF\", \"brightBlack\": \"#5A6374\", \"brightBlue\": \"#61AFEF\", \"brightCyan\": \"#56B6C2\", \"brightGreen\": \"#98C379\", \"brightPurple\": \"#C678DD\", \"brightRed\": \"#E06C75\", \"brightWhite\": \"#DCDFE4\", \"brightYellow\": \"#E5C07B\", \"cursorColor\": \"#FFFFFF\", \"cyan\": \"#56B6C2\", \"foreground\": \"#DCDFE4\", \"green\": \"#98C379\", \"name\": \"One Half Dark\", \"purple\": \"#C678DD\", \"red\": \"#E06C75\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#DCDFE4\", \"yellow\": \"#E5C07B\" }, { \"background\": \"#FAFAFA\", \"black\": \"#383A42\", \"blue\": \"#0184BC\", \"brightBlack\": \"#4F525D\", \"brightBlue\": \"#61AFEF\", \"brightCyan\": \"#56B5C1\", \"brightGreen\": \"#98C379\", \"brightPurple\": \"#C577DD\", \"brightRed\": \"#DF6C75\", \"brightWhite\": \"#FFFFFF\", \"brightYellow\": \"#E4C07A\", \"cursorColor\": \"#4F525D\", \"cyan\": \"#0997B3\", \"foreground\": \"#383A42\", \"green\": \"#50A14F\", \"name\": \"One Half Light\", \"purple\": \"#A626A4\", \"red\": \"#E45649\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#FAFAFA\", \"yellow\": \"#C18301\" }, { \"background\": \"#002B36\", \"black\": \"#002B36\", \"blue\": \"#268BD2\", \"brightBlack\": \"#073642\", \"brightBlue\": \"#839496\", \"brightCyan\": \"#93A1A1\", \"brightGreen\": \"#586E75\", \"brightPurple\": \"#6C71C4\", \"brightRed\": \"#CB4B16\", \"brightWhite\": \"#FDF6E3\", \"brightYellow\": \"#657B83\", \"cursorColor\": \"#FFFFFF\", \"cyan\": \"#2AA198\", \"foreground\": \"#839496\", \"green\": \"#859900\", \"name\": \"Solarized Dark\", \"purple\": \"#D33682\", \"red\": \"#DC322F\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#EEE8D5\", \"yellow\": \"#B58900\" }, { \"background\": \"#FDF6E3\", \"black\": \"#002B36\", \"blue\": \"#268BD2\", \"brightBlack\": \"#073642\", \"brightBlue\": \"#839496\", \"brightCyan\": \"#93A1A1\", \"brightGreen\": \"#586E75\", \"brightPurple\": \"#6C71C4\", \"brightRed\": \"#CB4B16\", \"brightWhite\": \"#FDF6E3\", \"brightYellow\": \"#657B83\", \"cursorColor\": \"#002B36\", \"cyan\": \"#2AA198\", \"foreground\": \"#657B83\", \"green\": \"#859900\", \"name\": \"Solarized Light\", \"purple\": \"#D33682\", \"red\": \"#DC322F\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#EEE8D5\", \"yellow\": \"#B58900\" }, { \"background\": \"#000000\", \"black\": \"#000000\", \"blue\": \"#3465A4\", \"brightBlack\": \"#555753\", \"brightBlue\": \"#729FCF\", \"brightCyan\": \"#34E2E2\", \"brightGreen\": \"#8AE234\", \"brightPurple\": \"#AD7FA8\", \"brightRed\": \"#EF2929\", \"brightWhite\": \"#EEEEEC\", \"brightYellow\": \"#FCE94F\", \"cursorColor\": \"#FFFFFF\", \"cyan\": \"#06989A\", \"foreground\": \"#D3D7CF\", \"green\": \"#4E9A06\", \"name\": \"Tango Dark\", \"purple\": \"#75507B\", \"red\": \"#CC0000\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#D3D7CF\", \"yellow\": \"#C4A000\" }, { \"background\": \"#FFFFFF\", \"black\": \"#000000\", \"blue\": \"#3465A4\", \"brightBlack\": \"#555753\", \"brightBlue\": \"#729FCF\", \"brightCyan\": \"#34E2E2\", \"brightGreen\": \"#8AE234\", \"brightPurple\": \"#AD7FA8\", \"brightRed\": \"#EF2929\", \"brightWhite\": \"#EEEEEC\", \"brightYellow\": \"#FCE94F\", \"cursorColor\": \"#000000\", \"cyan\": \"#06989A\", \"foreground\": \"#555753\", \"green\": \"#4E9A06\", \"name\": \"Tango Light\", \"purple\": \"#75507B\", \"red\": \"#CC0000\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#D3D7CF\", \"yellow\": \"#C4A000\" }, { \"background\": \"#000000\", \"black\": \"#000000\", \"blue\": \"#000080\", \"brightBlack\": \"#808080\", \"brightBlue\": \"#0000FF\", \"brightCyan\": \"#00FFFF\", \"brightGreen\": \"#00FF00\", \"brightPurple\": \"#FF00FF\", \"brightRed\": \"#FF0000\", \"brightWhite\": \"#FFFFFF\", \"brightYellow\": \"#FFFF00\", \"cursorColor\": \"#FFFFFF\", \"cyan\": \"#008080\", \"foreground\": \"#C0C0C0\", \"green\": \"#008000\", \"name\": \"Vintage\", \"purple\": \"#800080\", \"red\": \"#800000\", \"selectionBackground\": \"#FFFFFF\", \"white\": \"#C0C0C0\", \"yellow\": \"#808000\" } ], \"theme\": \"system\", \"themes\": []} 该项难度系数：⭐ 需要懂点 json，还需要会配置 Windows Terminal。 添加 Powershell 启动参数 在 Powershell 中输入 123456# 这一步使用的是记事本notepad.exe $Profile# 如果安装有VSCode，可以使用这条命令# 优点是可以代码高亮code $Profile 紧接着在弹出的页面中输入下面这一长串代码，保存并关闭。这个 Profile 配置文件与.zshrc / .bashrc 文件一样，都是控制启动前参数的。 1234567891011121314151617181920oh-my-posh init pwsh --config \"$env:POSH_THEMES_PATH/1_shell.omp.json\" | Invoke-Expression#------------------------------- Set Hot-keys BEGIN -------------------------------# 设置预测文本来源为历史记录Set-PSReadLineOption -PredictionSource History# 每次回溯输入历史，光标定位于输入内容末尾Set-PSReadLineOption -HistorySearchCursorMovesToEnd# 设置 Tab 为菜单补全和 IntellisenseSet-PSReadLineKeyHandler -Key \"Tab\" -Function MenuComplete# 设置向上键为后向搜索历史记录Set-PSReadLineKeyHandler -Key UpArrow -Function HistorySearchBackward# 设置向下键为前向搜索历史纪录Set-PSReadLineKeyHandler -Key DownArrow -Function HistorySearchForward#------------------------------- Set Hot-keys END ------------------------------- OhMyPosh 主题预览 - https://ohmyposh.dev/docs/themes 国内网络可能访问不了。 好了，Perfect。😋 结束语 为什么不用 WSL 作为默认界面？当然，这也很好，但是在某些编辑和交互控制上，Powershell 才是 Windows 上的正主，WSL 说白了，就是个临时替代之用的。对于老程序员，当然是 “我全都要”。 经过测试，该做法界面美观，性能优异，配置简单，值得大家使用。在此强烈推荐！"},{"title":"黑苹果一键 HiDPI","path":"/article/hackintosh-one-key-hidip/","text":"搞了一台飞利浦的 2K 显示屏，本来以为只要外接显示屏的分辨率够了就可以获得 Retina 的细腻效果。但事与愿违，后来查询后发现苹果的 Retina 效果是外接显示器不可能达到那样的细腻，但外接显示器只要分辨率够，可以通过软件渲染得来 Retina 效果，这就是 HiDPI 技术。 HiDPI 本质上是用软件的方式实现单位面积内的高密度像素。用四个像素点来表现一个像素，因此能够更加清晰细腻。 高 PPI (硬件) + HiDPI 渲染 (软件) = 更细腻的显示效果 (retina) 但是悲剧的是，苹果觉得 2K 显示器没法做到真 HiDPI（4K 刚好渲染出真 1080P 的 retina 效果），所以只有在 4K 屏幕上才能直接开启 HiDPI。 所以这里先划下重点，如果想要完美效果，那直接上 4K 屏！ 但是已经买了 2K 屏，总不能退掉，而且 4K 屏的价格也是 2K 屏的 2 倍以上。所以 2K 屏也可以通过软件强行告诉系统，这个屏幕可以开 HiDPI，你就直接开吧！ 下面就记录在给 2K 屏开启 HiDPI 碰到的问题，有手动和脚本自动两种方法，但是不知道怎么回事，海天手动的方法就是没开启成功，最后使用脚本却成功开启了。 开启 HiDPI 的对比 下面两张是用 iphone 手机手持在一个相对差不多的位置拍摄的，可以看出，开启后字体的显示还是清晰很多。 手动开启 HiDPI 获取外接显示器 DisplayVendorID 和 DisplayProductID 在终端工具输入： 1234# 获取DisplayVendorIDioreg -l | grep \"DisplayVendorID\"# 获取DisplayProductIDioreg -l | grep \"DisplayProductID\" 就可以获得显示器的 DisplayVendorID 和 DisplayProductID，如果获得两个，那说明的你的 macbook 还在亮着，可以合盖来排除掉，获得外接显示器的 DisplayVendorID 和 DisplayProductID。 制作外接显示屏系统配置文件 转换为 16 进制 将 DisplayVendorID 和 DisplayProductID 的数值，转换为 16 进制，网上有很多工具，这里就不提供了。 创建显示器配置文件夹 然后新建文件夹，命名为：DisplayVendorID-XXXX，其中 XXXX 是刚才转换的 DisplayVendorID 的 16 进制值小写。 创建显示器配置内容 这一步需要借助工具来生成，点击这里进行生成，将显示器的名称、DisplayVendorID 和 DisplayProductID 对应填写进去，即可获得配置文件，然后下载文件到，刚创建的 DisplayVendorID-XXXX 文件夹内。（记得将 plist 的后缀去掉） 到这一步，显示器的配置文件已经手动创建好了，需要将文件放到系统的 /System/Library/Displays/Contents/Resources/Overrides/ 文件夹内。（这里需要打开 SIP，方法可参考文末） 然后使用软件 RDM 即可开启 HiDPI。 脚本开启 HiDPI 找到两个脚本，大家都可以试一下，我是使用国人制作的 one-key-hidpi 开启成功的。 Enable-HiDPI-OSX one-key-hidpi 看介绍 one-key-hidpi 的作者还是参考的 Enable-HiDPI-OSX，但是我使用 Enable-HiDPI-OSX 却没有成功。 脚本一键开启很方便，将脚本下载下来，运行脚本，按照提示操作即可。 下载脚本并运行 1234567# 下载脚本curl -o ~/onekeyhidpi.sh https://raw.githubusercontent.com/xzhih/one-key-hidpi/master/hidpi.sh# 运行脚本chmod +x ~/onekeyhidpi.sh~/onekeyhidpi.sh 按照脚本提示输入对应数字即可 开启 SIP 苹果操作系统对于系统的保护是很严格的，不管是上面的手动操作，还是脚本，都必须打开 SIP 也就是系统防火墙。 查看 SIP 状态 在终端中输入 csrutil status，就可以看到是 enabled 还是 disabled。 关闭 SIP 重启 MAC，按住 cmd+R 直到屏幕上出现苹果的标志和进度条，进入 Recovery 模式 在屏幕左上方的工具栏找到实用工具（左数第 3 个），打开终端，输入：csrutil disable 重启 mac 打开 SIP 重启 MAC，按住 cmd+R 直到屏幕上出现苹果的标志和进度条，进入 Recovery 模式 在屏幕左上方的工具栏找到实用工具（左数第 3 个），打开终端，输入：csrutil enable 重启 mac 使用 RDM 设置分辨率 RDM 全称为 Retina Display Manage，下载安装即可：http://avi.alkalay.net/software/RDM/ 重启后打开 RDM，选取带雷电符号的 1920x1080，即可开启 HiDPI。 注意 最后在提醒一下，最好用一个好的扩展坞连接，我一开始用一个山泽的扩展坞，怎么也点不了 1920×1080 的 HiDPI 的设置，但是换了个绿联的就可以了。 神奇的是，HiDPI 开启成功后，我换回山泽的，却还是可以正常使用。"},{"title":"Meta Keywords：是什么、为什么不","path":"/article/say-no-to-meta-keywords/","text":"形如 &lt;meta keywords=\"shiux, shiux.com\"&gt; 的 Meta Keywords 是 Meta 标签的一种，仅存在于 HTML 代码中、不会在浏览器中展示。过去，Meta Keywords 标签被用于告诉搜索引擎爬虫关于网页的信息。但是，现在搜索引擎还尊重 Meta Keywords 么？Meta Keywords 是否仍然是 SEO 的最佳实践？ Meta Keywords 的历史 Meta Keywords 的历史可以追溯到 1995 年，当时的 HTML 标准制定者认为通过 Meta Keywords 可以帮助搜索引擎获取关于页面的信息。然而，Meta Keywords 只存在于 HTML 源码中，对搜索引擎爬虫可见，但是在浏览器中不会显示、大部分访客也看不到这些关键词。于是，从 1999 年开始，几乎所有网站都开始滥用 Meta Keywords，在 Meta Keywords 其中塞入大量不相关的标签和关键词以欺骗搜索引擎排名、抢夺流量。 有人甚至认为，正是网站对 Meta Keywords 的滥用才导致了 Google 的崛起。Google 并不是全世界第一个搜索引擎（而是第 11 个、或者第 13 个？），但是 Google 是第一个认识到 Meta Keywords 滥用问题严重性的搜索引擎。于是 Google 不再依赖网站提供关键词，转而依赖更多的因素，例如网站全文内容、内链和外链。除了 Google，其他搜索引擎如 Yahoo 也开始使用更多的网页衡量指标。但是 Meta Keywords 实在太容易被滥用了，2000 年以来，几乎所有网站仍然在滥用 Meta Keywords。 2009 年是一个分水岭，Google 首次公开明确宣布他们不使用 Meta Keywords。同年，Yahoo 也透漏他们很久以前就不再将 Meta Keywords 作为衡量指标了。到了 2015 年，绝大部分搜索引擎都不再将 Meta Keywords 作为关键衡量指标。 Google - 完全忽略 Google 自 2009 年以来就不再使用 Meta Keywords 标签作为衡量 Ranking 的因素；Google 还会对滥用 Meta Keywords 的网站进行降权惩罚。 Our web search (the well-known search at Google.com that hundreds of millions of people use each day) disregards keyword metatags completely. They simply don’t have any effect in our search ranking at present. Google does not use the keywords meta tag in web ranking - Google Search Central Blog, 2009 年 9 月 21 日 Unsupported tags and attributes - Google Search Central Documentation Bing - 完全忽略 Microsoft Bing 于 2014 年正式公开宣布，Meta Keywords 对于 Bing SEO 来说毫无价值： Today, it’s pretty clear the meta keyword tag is dead in terms of SEO value. Sure, it might have value for contextual ad systems or serve as a signal to ‘bots plying the web looking for topics to target, but as far as search goes, that tag flat lined years ago as a booster. 2020 年，Microsoft Bing 时任 CEO 在 Twitter 上回推时再次表示，Bing 会无视、忽略、排除 Meta Keywords。 Blame The Meta Keyword Tag - Microsoft Bing Blog, 2014 年 10 月 4 日 The meta keyword tag is dead in terms of SEO value for @BingWMC. We exclude it and ignore it - ChristiJOlson, Head of Paid Search at Microsoft, 2020 年 5 月 29 日 Yahoo - 几乎不用 在 2009 年 Search Marketing Expo 大会上，Yahoo 时任搜索部门负责人 Cris Pierry 在问答环节上表示，Yahoo 其实早就不再将 Meta Keywords 作为一个指标。Search Engine Land 于是进行了一项测试，发现 Yahoo 仍然会索引 Meta Keywords 的信息。Yahoo 官方对此的回复是，当 Yahoo 无法从网页的标题、description、链接、媒体文件等获取有关网页的信息时，Yahoo 仍然会使用 Meta Keywords 作为最后的稻草。 Yahoo Search No Longer Uses Meta Keywords Tag, 2009 年 10 月 6 日 The news came during the Ask The Search Engines session at SMX East in New York today. The search engines were all asked about their support of the tag. Moderator Danny Sullivan noted that only Yahoo provided support of the tag — prompting Cris Pierry, senior director of search at Yahoo, to announce that support actually had been ended unannounced “several” months ago. Sorry, Yahoo, You DO Index The Meta Keywords Tag, 2009 年 10 月 14 日 What changed with Yahoo’s ranking algorithms is that while we still index the meta keyword tag, the ranking importance given to meta keyword tags receives the lowest ranking signal in our system. Words that appear in any other part of documents, including the body, title, description, anchor text etc., will take priority in ranking the document – the re-occurrence of these words in the meta keyword tag will not help in boosting the signal for these words. Therefore, keyword stuffing in the keyword tag will not help a page’s recall or ranking, it will actually have less effect than introducing those same words in the body of the document, or any other section. 百度 - 非关键衡量指标 自从 2012 年以来，百度一直在刻意弱化 Meta Keywords 的重要性。2018 年，一名来自中国的中文 SEO 专家写了一篇博客，援引 2013 年时一名百度搜索工程师公开发表的观点，介绍为什么你不应该使用 Meta Keywords 作为优化百度 SEO 的手段： Meta Keywords 早就进了历史的垃圾堆了，我们会直接忽略。 Why You shouldn’t Use Meta Keywords Tag for Baidu SEO Anymore - Jinray China SEO Diary, 2018 年 7 月 4 日 Yandex - 非关键衡量指标 俄罗斯最大的搜索引擎 Yandex 也是为数不多仍然使用 Meta Keywords 作为衡量指标之一的搜索引擎，但是许多来自俄罗斯的 SEO 专家都曾表示过 Meta Keywords 对改善 Yandex SEO 收效甚微。 Meta tags that Yandex takes into account “Officially” they say they still do, but I think this is a very low weight factor, even for яндекс. This is the consensus among most of us who have done SEO in Russian 😃 - orun bhuiyan on Twitter, 2020 年 5 月 30 日 结论 Meta Keywords 已死。网站应该停止使用 Meta Keywords 标签。搜索引擎更加注重于其它维度，如 Title 标签、Meta Description 和结构化数据。对于内容导向的网站，我推荐采取一些我之前在「如何写一篇同时面向人和搜索引擎的文章」一文中提到的手段。"},{"title":"黑群晖 DSM7.X 引导编译","path":"/article/dsm7-x-boot-compilation/","text":"上个月，一位巴西人在 github 上分享的源代码（GitHub），让黑群晖 DSM7.X 引导的编译变得非常简单，一点都不夸张的说：简单到连小学生都能操作！感谢这位巴西的大佬！ 编译要求 掌握计算机基本操作，有耐心。 有同学举手说：“我看不懂英语。” 那么你会百度吗？ 会！ 好的，百度搜索栏输入 “翻译” 回车，会吗？ 会！ Very Good！我们继续。。。。。。 编译前的准备工作 由于需要在 NAS 的机器上进行引导的编译，请事先准一下： 如果你决定使用物理机安装群晖系统的，那么需要把机器装好，包括键盘、鼠标、显示器、硬盘、网线等等，如果还有其他外设（比如：额外添加的网卡、扩展卡、阵列卡等）要装起来，让所有的硬件处于可以正常工作的状态，编译系统会自动检测你使用的硬件并且自动加载驱动进行编译； 如果你决定使用虚拟机安装群晖系统的，那么需要配置好虚拟机，包括设置 CPU、内存、存储大小等等，以及有直通硬盘、直通核显、直通网卡、直通扩展卡、直通阵列卡等外设的，全部设置好，编译系统会自动检测虚拟机的硬件信息并且自动加载驱动进行编译； 如果你有科学出国的环境能正常访问 GitHub 网站和 Google 网站的，那是最好的，可以减少编译等待的时间。要是没有也可以编译，只需要耐心等就是了。 编译步骤 下载文件 到 GitHub 把编译引导需要用的文件下载到电脑上（不是在 NAS 这台机器）。截止 2022 年 8 月 13 日，github 上最新的版本是 v1.0-beta11a（如果将来作者更新，可以下载最新的版本），我下载的 img 文件，这个格式是通用的，物理机可以用，虚拟机也可以用。 下载后的文件名是 arpl-1.0-beta11a.img.zip，这个是一个压缩包。 利用电脑的解压软件，把 arpl-1.0-beta11a.img.zip 解压出来，得到另外一个文件 arpl.img。 删除 arpl-1.0-beta11a.img.zip，只留下 arpl.img 即可。 如果你是用物理机安装的，可以使用 rufus 写盘工具把 arpl.img 刷到 U 盘。如果是 PVE 虚拟机安装群晖的，可以上传 arpl.img 到 PVE，用 qm importdisk 命令转换成群晖虚拟机的虚拟引导文件。如果是用 ESXI 或者 VMware 安装的群晖虚拟机，可以使用 StarWind V2V Image Converter 工具来转换格式。我是用 ESXI 虚拟机安装的，所以把 arpl.img 转成了 arpl.vmdk 和 arpl-flat.vmdk。 把 arpl.vmdk 和 arpl-flat.vmdk 两个文件上传到 ESXI，设置为群晖虚拟机的引导。 配置虚拟机 我的群晖虚拟机配置很简单，你们不用照抄我的，请根据自己实际使用环境配置即可。 虚拟机配置好了就打开虚拟机的电源。物理机安装的话，把刷好的 U 盘放到 NAS 主机上，开机进 BIOS 设置从 U 盘启动。编译系统启动后会显示以下的界面，直接按回车进入。 编译系统启动中，如果你的路由器已经开启 DHCP 的话，此时系统会自动去获取 IP 地址，请耐心等待。 当编译系统最下面一行显示有 “root@” 开头的时候，就表示已经启动好了，需要找出编译系统的 IP 地址。 在局域网另外一台电脑的浏览器（建议使用谷歌浏览器），打开编译系统显示的 IP 地址和端口，会显示以下界面。 在第一行 “Choose a model” 回车。 这时会显示出本机可编译黑群晖的型号，如果你的 CPU 比较老的话，有可能不会显示 “DS918+” 这个型号。 选择你想要编译的黑群晖型号，我这选择的是 DS918+，用方向键选好以后按回车键。 在 “Choose a Build Number” 处回车。 选择你想要编译黑群晖的版本，我选择的是最新的 7.1.1-42951 版本，用方向键选择以后按回车键。 在 “Choose a serial number” 处回车。 选择 “Generate a random serial number” 回车的话，编译系统会随机生成一个序列号。如果你想使用自定义的序列号，可以选择 “Enter a serial number” 回车后输入你想要使用的序列号。我这里使用随机生成。 需要加载十代 CPU 核显驱动的，在 “Addons” 处回车。如果使用的 CPU 不是 10 代，此步骤跳过不做。 需要加载十代 CPU 核显驱动的，在 “Add an addon” 处回车。如果使用的 CPU 不是 10 代，此步骤跳过不做。 需要加载十代 CPU 核显驱动的，在 “i915 Intel iGPU Drivers (10th Gen)” 处回车。如果使用的 CPU 不是 10 代，此步骤跳过不做。 需要加载十代 CPU 核显驱动的，在这个界面直接回车就行，不要输入任何内容（温馨提醒：有些主板可能存在兼容性问题，建议编译引导时先不开启该补丁，等安装好系统以后再去打补丁。）。如果使用的 CPU 不是 10 代，此步骤跳过不做。 在 “Exit” 处回车返回上级菜单。 在 “Build the loader” 处回车，开始编译。 编译过程中，界面上会有进度条在跑进度，请耐心等待，等待的时间视你的网络环境而定（如果有科学出国的环境，请把此 IP 地址放到强制代理名单，可以加快编译速度）。 引导编译完成后，系统会自动跳回这个界面，并且会多出一行菜单 “Boot the loder”，在这行菜单上回车。 加快引导盘启动 屏幕菜单上的内容会显示 “Switch direct boot：false”，先确认一下光标停留在这行内容上面，然后按一次回车键； 屏幕上的菜单内容会变成 “Switch direct boot：true”，同时光标会自动跳到下一行 “Boot the Loader”； 确认当前光标处在 “Boot the Loader” 这一行上面，按一次回车； 屏幕上会显示 “Reboot to boot directly in DSM”； 同时 NAS 主机会自动重启，并且跳过编译系统直接进入群晖引导启动界面； 只要你的 CPU 性能足够强大，那么直接从群晖引导启动，就很完美了。 其他 把 NAS 主机手动重启一次，编译好的引导就会自动启动，该项目编译出来的引导启动后显示的界面如下，会显示有：系统型号，系统版本，pid，vid，sn，mac 等等。 在电脑上打开群晖助手，等待一段时间后，会搜索到 DSM 未安装的信息，IP 地址、型号和版本与刚才编译的一致，这就对了。如果你的电脑搜索不出来的话，把电脑防火墙关掉后再试一下。 接下来就可以安装系统了，怎么样，是不是超级简单？后面的安装过程我就不演示了。 温馨提醒 使用该项目编译引导有任何建议或者意见的，请直接向项目作者的 Issues 提交，提交之前先看一下 Issuse 的内容，看看是否有人跟你一样的问题已经得到解决，避免重复提交同样的问题。 作者是巴西人，不懂中文，提交 Issue 请使用英文进行书写。 arpl 编译好的引导，修改 SN/MAC 和添加多网卡的方法 把 NAS 重启一次，在启动菜单选第三行回车； 在 “Choose a serial number” 处回车； 在 “Enter a serial number” 处回车； 输入你想要使用的 SN，输完了按一次回车； 在 “yes” 处回车； 在 “Cmdline menu” 处回车； 在 “Define a custom MAC” 处回车； 输入你想要使用的 mac 地址（这里修改的是 mac1），输完了按一次回车； 当屏幕显示如下图的时候，把 NAS 重启一次； 启动菜单选第三行回车； 看到刚才修改的 mac 地址已经生效了，并且 IP 也会自动改变，不是之前的 IP 地址了，在浏览器打开新的地址和端口； 在 “Cmdline menu” 处回车； 在 “Add/edit an cmdline item” 处回车； 输入 netif_num 回车，修改网卡数量； 默认是单网口，所以只有 1； NAS 是双网卡的话，把 1 删了，改成 2 回车； 在 “Add/edit an cmdline item” 处回车； 输入 mac2 回车； 输入 mac2 的值，回车； 在 “Show user cmdline” 处回车； 此时屏幕会显示刚才设置的网口数量以及 mac1 和 mac2 的地址，查看一下设置的是否正确，按回车返回； 如果设置不对，就重复上述的动作继续修改，设置正确了就在 “Exit” 处回车； 在 “Build the loader” 处回车； 当屏幕上显示 “Ready!” 的时候，就表示已经修改好了； 屏幕自动跳转到菜单，在 “Boot the loader” 处回车； 引导启动好了以后，屏幕上会显示刚才设置的 SN、网口数量和两个 MAC 值。 登录群晖，控制面板，信息中心，看到有两个网卡信息，设置正确了。"},{"title":"HTML 设置 lang 属性的意义","path":"/article/lang-tag/","text":"如果不设置 lang 属性… 12&lt;p&gt;天&lt;/p&gt;&lt;p lang=\"zh-CN\"&gt;天&lt;/p&gt; 结果为： 这是因为本页面外层设置了 lang=“ja”，因此如果不设置 lang 属性，就会继承外层的设置，使浏览器默认使用日文字体。日文字体的「天」字上长下短，与中文习惯不符，影响用户的阅读体验。 有人会说，我当然不会把页面外层设置为日文。但是，如果页面没有设置 lang 属性，就会使用浏览器或操作系统设置的语言。用户的系统使用何种语言，是网页开发者无法控制的。 又有人会说，「天」字只有两横的长短区别，差别并不大，有必要关注吗？其实，这是很有必要的。 首先，虽然对于「天」字来说，日文字体与中文字体的差别并不大，但还有许多字差别较大，例如： 其次，即使网页使用日文字体，如果所有汉字都使用日文字体显示，达到风格上的统一，在一定程度上尚可接受。但是，许多日文字体缺少中国大陆的简体字，这些字会 fallback 到能显示大陆简体字的日文字体或大陆字体，从而出现字体混杂的问题。例如： 这种问题只需要在网页 html 标签添加属性 lang=\"zh-CN\" 即可解决。 有人会说，为什么会有人使用日文系统浏览中文网页呢？实际上，随着国际交流与合作日益密切，出于工作和学习的原因，不少中国人会使用日文系统，也有不少日本人会浏览中文网页。而且，上述字体问题不仅会在日语环境下出现，在其他外语环境下同样会出现。因此，考虑这一问题是很有必要的。 lang=\"zh-CN\", lang=\"zh-HK\" 与 lang=\"zh-TW\" 的差异 123&lt;p lang=\"zh-CN\"&gt;骨&lt;/p&gt;&lt;p lang=\"zh-HK\"&gt;骨&lt;/p&gt;&lt;p lang=\"zh-TW\"&gt;骨&lt;/p&gt; 这是因为中国大陆「骨」上方朝左，而香港、台湾朝右；大陆、香港「骨」下方作两横，而台湾作「点挑」。设置语言属性后，浏览器分别应用了三地的字体。 lang=\"zh-Hans\" 与 lang=\"zh-Hant\" 的差异 12&lt;p lang=\"zh-Hans\"&gt;骨&lt;/p&gt;&lt;p lang=\"zh-Hant\"&gt;骨&lt;/p&gt; 结果为： 这是因为 zh-Hans 默认使用大陆字形，zh-Hant 默认使用台湾字形。 lang=\"zh-HK\" 与 lang=\"zh-Hant-HK\" 有什么区别？ 一般情况下没有区别，因为香港是使用繁体中文的地区，所以 lang=\"zh-HK\" 就隐含了 lang=\"zh-Hant-HK\"，二者的行为应该是等同的。 但是，在目前最新版的 Mozilla Firefox 中二者行为不同： 12&lt;p lang=\"zh-HK\"&gt;&lt;q&gt;你好&lt;/q&gt;&lt;/p&gt;&lt;p lang=\"zh-Hant-HK\"&gt;&lt;q&gt;你好&lt;/q&gt;&lt;/p&gt; 结果为： 这可能只是一个 bug。 lang 属性在西文中的差异 123&lt;style&gt;.upper { text-transform: uppercase; }&lt;/style&gt;&lt;p class=\"upper\" lang=\"en-US\"&gt;shipping&lt;/p&gt;&lt;p class=\"upper\" lang=\"tr\"&gt;shipping&lt;/p&gt; 结果为： 这是因为土耳其文有带点与不带点两种 i 字母，带点的小写 i 对应的是带点的大写İ。 lang=\"en-GB\" 与 lang=\"en-US\" 的差异 12&lt;textarea lang=\"en-GB\"&gt;center centre&lt;/textarea&gt;&lt;textarea lang=\"en-US\"&gt;center centre&lt;/textarea&gt; 结果为： 这是因为在 Mozilla Firefox 中，拼写检查时会区分英国英语与美国英语。 是不是只要使用了相应地区的汉字字体，就没必要再使用 lang 属性指定地区了？ 有人可能认为，既然 lang 属性会影响浏览器所使用的汉字字体，从而影响字形，那么只要用了相应地区的汉字字体，字形自然也就确定了，所以也就不必再指定 lang 属性了。 这种想法是不正确的。因为现代字体具有 OpenType 的 locl 特性，会根据 lang 属性改变字形。 123&lt;style&gt;.font-k { font-family: 'Source Han Sans SC', sans-serif; }&lt;/style&gt;&lt;p class=\"font-k\"&gt;天&lt;/p&gt;&lt;p class=\"font-k\" lang=\"zh-CN\"&gt;天&lt;/p&gt; 结果为： 这是因为外层设置了 lang=\"ja\"，因此如果不设置 lang 属性，就会继承外层的设置，使浏览器默认使用日文字形。虽然 Source Han Sans SC 默认为中国大陆字形，但是由于 OpenType 的 locl 特性，也会自动变为日文字形。 有人会说，我当然不会把页面外层设置为日文。但是，需要再次重申，如果页面没有设置 lang 属性，就会使用浏览器或操作系统设置的语言。用户的系统使用何种语言，是网页开发者无法控制的。 还有一个更常见的现象是引号问题。 1234&lt;div lang=\"en\"&gt; &lt;p&gt;“你好”&lt;/p&gt; &lt;p lang=\"zh-CN\"&gt;“你好”&lt;/p&gt;&lt;/div&gt; 结果为： 这是因为 Unicode 中并不区分全角与半角引号，具体的显示效果会由于 lang 属性的不同而不同。 中国大陆的简体中文网页应该设置 lang=\"zh\" 还是 lang=\"zh-CN\"？ 从效果上看，二者并没有区别，都会使用大陆字形显示汉字。因此，设置哪个都是没有问题的。 但是，如果网页是简繁混排的，即同一网页中还会出现 lang=\"zh-HK\" 或 lang=\"zh-TW\"，则为了代码的可读性与可维护性，应该使用 lang=\"zh-CN\"。 例如，使用楷体排版的多语言网页可以这样设置 CSS： 1234:lang(zh), :lang(ja), :lang(ko) { text-align: justify; }:lang(zh-CN) { font-family: KaiTi, cursive; }:lang(zh-TW) { font-family: DFKai-SB, cursive; }:lang(zh-HK) { font-family: DFPHKStdKai-B5, cursive; } 西文文本不宜使用两侧对齐，否则会造成川流现象，而中文、日文、韩文可以使用两侧对齐。这时，使用 lang=\"zh\"，可以一次性选择所有中文变体，即所有以 zh 起始的 lang 属性。 如果将 lang=\"zh-CN\" 改为 lang=\"zh\"，则上述 CSS 代码中的 lang=\"zh-CN\" 也必须改为 lang=\"zh\"。在维护过程中，有可能因为维护人员的疏忽，规则之间被调换了顺序，写作： 1234:lang(zh), :lang(ja), :lang(ko) { text-align: justify; }:lang(zh-TW) { font-family: DFKai-SB, cursive; }:lang(zh-HK) { font-family: DFPHKStdKai-B5, cursive; }:lang(zh) { font-family: KaiTi, cursive; } 这样就产生了 bug，因为这会导致:lang(zh-TW) 与:lang(zh-HK) 两条规则都被:lang(zh) 覆盖。 应该使用 lang=\"zh-Hant\" 类属性，还是应该使用 lang=\"zh-TW\" 类属性？ 如前文所述，这在显示效果上是没有差别的，因为 zh-Hant 默认使用台湾字形。但是，二者却有语义上的差别。 如果网页内容是一篇用现代文体写成的、使用繁体字的、讲述古代文化的文章，其地域性并不强，并不能直接看出是台湾、香港，或是其他使用繁体字的地区的文章，因此应该使用 lang=\"zh-Hant\"。同理，如果这样的文章使用简体字写成，其地域性并不强，并不能直接看出是来自中国大陆，还是其他使用简体字的地区，因此应该使用 lang=\"zh-Hans\"。 而如果网页内容是一篇与现代生活紧密相关的文章，则通常需要指明地区。这是因为不同地区的用字、用词与写作习惯均存在差异。例如，在用字上，中国大陆、香港「着」和「著」音义均不同，而台湾则一律用「著」；在用词上，中国大陆称「摩托车」，香港称「电单车」，而台湾称「机车」。这时就应该使用 lang=\"zh-CN\", lang=\"zh-HK\", lang=\"zh-TW\" 等属性。 如何使 lang=\"zh-Hant\" 使用香港或韩国字形？ zh-Hant 默认使用台湾字形。但是有人会说，自己的页面就是需要设置 lang=\"zh-Hant\"，但是又不想使用台湾字形。这时可以使用 CSS 的 font-language-override 属性。 1234567&lt;style&gt;.glyph-hk:lang(zh-Hant) { font-language-override: \"ZHH\"; }.glyph-kr:lang(zh-Hant) { font-language-override: \"KOR\"; }&lt;/style&gt;&lt;p lang=\"zh-Hant\"&gt;霄&lt;/p&gt;&lt;p class=\"glyph-hk\" lang=\"zh-Hant\"&gt;霄&lt;/p&gt;&lt;p class=\"glyph-kr\" lang=\"zh-Hant\"&gt;霄&lt;/p&gt; 结果为： font-language-override 属性的常用取值如下： 大陆字形：ZHS 台湾字形：ZHT 香港字形：ZHH 韩国字形：KOR 日本字形：JAN 为什么一般情况下不应使用以 cdo, cjy, cmn, cnp, cpx, csp, czh, czo, gan, hak, hsn, lzh, mnp, nan, wuu, yue 等起始的属性？ 这有两个原因。 首先是出于兼容性的考量，因为只有一部分较新的浏览器支持这些属性。 例如，吴语维基百科设置了 lang=\"wuu\"。对于日文系统，在目前最新版的 Edge 浏览器中，页面会出现字体混杂的问题。 这是因为 Edge 不能识别 wuu 这类属性。由于系统语言为日语，因此 Edge 优先使用日文字体显示。Edge 默认的日文字体是 Meiryo 字体，该字体缺少中国大陆的简体字，因此 fallback 到宋体，从而出现字体混杂的问题。 当然，由于吴语维基百科使用吴语，与通常所指的汉语并不等同，因此确实需要使用 wuu 这一属性；而一般的汉语页面使用以 zh 起始的属性即可，不需要使用 cmn。这就涉及到第二个原因。 根据中国开发者的习惯，在编写中文页面时，通常会认为页面记录的是「汉语」，而不是「官话」。这是因为在中国人通常的观念中，与「英语」、「日语」等相对的是「汉语」，而「官话」则与「粤语」、「吴语」等相对。如果页面使用以 zh 起始的属性，更能反映这样的语义。而如果编写的页面中同时出现了普通话与粤语，这时对普通话内容使用以 cmn 起始的属性，对粤语内容使用以 yue 起始的属性，是较好的选择。 相关链接 CJKV Information Processing Language subtag lookup app ISO 639-1 列表 ISO 639-3 列表 ISO 15924 列表 OpenType Features in CSS 繁简中文转换概说 思源黑体 HTML 设置 lang 属性的意义 (shn.hk)"},{"title":"黑苹果合盖睡眠问题修复","path":"/article/hackintosh-sleep-issue/","text":"用过 MacBook 系列产品的童鞋应该都会发现，在系统合盖休眠之后，蓝牙进程还是在后台处于开启状态，这对于限制链接数的蓝牙设备就会造成名额占位。 例如，蓝牙耳机，一般的限制最多接入两个音源输入设备，MacBook 上用蓝牙耳机听着音乐，同时平板也保持和耳机的连接，当你合上 MacBook，再想用手机连接蓝牙耳机时，由于接入设备数量已经给平板和 MacBook 占满了，就会让你被迫手动关闭平板或者 Mac 对耳机的链接。 耗电与否先不讨论，在使用蓝牙耳机的体验上已经大打折扣了。如果可以改变 MacBook 的习性，让它合盖之后自动关闭蓝牙，就不用手动释放对蓝牙设备的占用了。So, 果断开工让 MacBook 成为更聪明的宝宝！ CLI 关闭蓝牙 blueutil 是 macOS 平台的控制蓝牙的命令行工具，可以检查蓝牙状态，以及开启 / 关闭等操作。通过 Homebrew 安装十分方便： 1brew install blueutil 关闭蓝牙： 1blueutil -p 0 开启蓝牙： 1blueutil -p 1 短短的命令就可以轻松 开 / 关 蓝牙，这时候只需要把上述 CLI 加入 合盖 / 开盖 监视器即可。 监测休眠及唤醒 SleepWatcher 可以监测 Mac 的休眠唤醒以及空闲状态，并执行用户自指定的命令。通过 Homebrew 获得： 1brew install sleepwatcher 系统自启动 SleepWatcher 后台进程，过程需要 Administrator 密码开启权限： 1brew services start sleepwatcher ==&gt; Successfully started **SleepWatcher** (label: homebrew.mxcl.sleepwatcher) 执行完毕可以检查后台进程是否添加成功： 12$ brew services listName Status User Plist sleepwatcher started Cotes /Users/cotes/Library/LaunchAgents/homebrew.mxcl.sleepwatcher.plist $ ps aux | grep sleepwatcher Cotes 3067 0.0 0.0 4317336 4552 ?? S 7:39PM 0:01.79 /usr/local/sbin/sleepwatcher -V -s ~/.sleep -w ~/.wakeup 从输出看到 SleepWatcher 已经成功进驻后台进程列表。-s 的参数指定监测的休眠指令存放于 ~/.sleep，-w 指定监测的唤醒指令存放于 ~/.wakeup，接下来把蓝牙开关的命令加入这两个文件即可。 指定合盖（休眠）执行蓝牙关闭： 1echo \"$(which blueutil) -p 0\" &gt;&gt; ~/.sleep 注：which 是为了指定 CLI 的绝对路径。 接着，添加开盖（唤醒）自动开启蓝牙，并且自动连上蓝牙设备： 1echo \"$(which blueutil) -p 1 &amp;&amp; $(which blueutil) --connect [ID]\" &gt;&gt; ~/.wakeup 把上述 ID 更换为目标蓝牙设备的 MAC 地址。在蓝牙外设与 MacOS 保持连接的状态下，可通过以下命令查询： 12$ blueutil --pairedaddress: 4e-21-f2-b1-a5-67, not connected, not favourite, paired, name: \"Headphone\", recent access date: 2020-03-23 21:25:48 +0000 输出日志的 address 部分就是设备的 MAC 地址。 最后，为命令文件添加执行权： 1chmod +x ~/.sleep ~/.wakeup OK，一切完毕，自动开闭蓝牙真心爽。不吹不黑，SleepWatcher 是个好东西，日后必另作他用。"},{"title":"Gridea 让你更方便地管理 GitHub Pages","path":"/article/gridea-guide/","text":"前言 当下大多数人可能已经对 GitHub Pages 不再陌生，它是很多喜欢写文章的人第一次接触的用于免费搭建博客建一个简洁却又不失优雅的个人博客 ，直到现在互联网上还有大量的基于它的个人博客，也有大量的搭建方法的教程。我之前就在少数派发表过一篇详细的 GitHub Pages 搭建教程，尚未掌握的朋友可以先从这篇文章读起。 然而搭建虽然简单，但是管理和推送文章却相对麻烦不少，在官方的教程里，我们需要经历繁琐的步骤才能发布一篇文章和修改个人空间界面。相较于官方提供的 GitHub Desktop 和在终端使用 Git 的方法管理 GitHub Pages，Gridea 这款工具则更为的便捷和优雅，它能让作为创作者的你更专注于写作 。 简介 Gridea 是一个静态博客写作客户端，帮助你更容易地构建并管理博客或任何静态站点。 Gridea 最早叫 Hve Notes，开发者为了更易读和好记，重新命名为 Gridea，支持 Windows 和 Mac 平台，它的基础界面非常地小清新。 官网 - https://gridea.dev/ GitHub - https://github.com/getgridea/gridea 第一次使用它需要你进行应用的初始化配置，才能让他和 GitHub Pages 连接，配置很简单，可以参考下面的方法进行配置： 域名：GitHub Pages 对应的域名（例如：https://shiux.github.io 或 https://shiux.com） 仓库：你的静态文件存放的仓库（例如：blog） 分支：你的 GitHub Pages 对应的分支（例如：main） 用户名：仓库所属用户的用户名（通常就是你的 GitHub 账号的昵称） 邮箱：Git 推送时使用的邮箱（通常就是你的 GitHub 账号的邮箱） Token: Git 推送时需要的 Token 用来向 GitHub 提交构建后的文件 GitHub personal access tokens CNAME: 可通过这个选项配置你自己的域名（例如：shiux.com） 注册并解析域名 注册个域名，国内的域名需要备案等操作。 你可以在下方网站注册域名: GoDaddy - https://hk.godaddy.com/ Hostinger - https://www.hostinger.com.hk/ 添加解析记录 添加 CNAME（别名） 主机 blog 指向 &lt;user&gt;.github.io 或 &lt;organization&gt;.github.io Navigate to your DNS provider and create a CNAME record that points your subdomain to the default domain for your site. For example, if you want to use the subdomain www.example.com for your user site, create a CNAME record that points www.example.com to &lt;user&gt;.github.io. If you want to use the subdomain another.example.com for your organization site, create a CNAME record that points another.example.com to &lt;organization&gt;.github.io. The CNAME record should always point to &lt;user&gt;.github.io or &lt;organization&gt;.github.io, excluding the repository name. For more information about how to create the correct record, see your DNS provider’s documentation. For more information about the default domain for your site, see “About GitHub Pages.” 在 GitHub Pages 设置中进行自定义域名绑定 打开 GitHub Pages，进入设置页面，为网站绑定自己的域名。添加刚才解析的记录，如下图所示： 为了安全，记得开启强制 Enforce HTTPS 官网教程 - https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-a-subdomain 下载安装 Gridea 客户端下载地址: https://gridea.dev/ 下载安装过程不做说明 设置代码本地目录 点击此处设置 设置远程服务 点击 \"远程\", 然后选择 “Coding Pages” 按页面提示填写保存后，点击检测远程链接"},{"title":"AdGuard 过滤规则分享","path":"/article/adguard-rules/","text":"使用方法 MacOS 打开 AdGuard -&gt; 设置 -&gt; 内容拦截 -&gt; User rules EasyList 官网 - https://easylist.to/ 订阅地址 官方 - https://easylist.to/easylist/easylist.txt 中国专属 - https://easylist-downloads.adblockplus.org/easylistchina.txt 国内网站广告过滤的主规则。 EasyPrivacy - https://easylist-downloads.adblockplus.org/easyprivacy.txt EasyPrivacy 是隐私保护，不被跟踪。 CJX’s Annoyance List - https://raw.githubusercontent.com/cjx82630/cjxlist/master/cjx-annoyance.txt 过滤烦人的自我推广，并补充 EasyPrivacy 隐私规则。 HalfLife 下列各规则、各规则的不同源不要同时订阅，因为重复了，也就是所有地址选择一个订阅就可以了。 国内推荐使用 jsdelivr。 ad-pc.txt：[推荐桌面端] 合并自乘风视频广告过滤规则、Easylist、EasylistChina、EasyPrivacy、CJX’sAnnoyance，以及补充的一些规则。 jsdelivr - https://cdn.jsdelivr.net/gh/o0HalfLife0o/list@master/ad-pc.txt GitHub - https://raw.githubusercontent.com/o0HalfLife0o/list/master/ad-pc.txt ad-mo.txt：合并自 Easylist、EasylistChina、EasyPrivacy、CJX’sAnnoyance。 jsdelivr - https://cdn.jsdelivr.net/gh/o0HalfLife0o/list@master/ad-mo.txt GitHub - https://raw.githubusercontent.com/o0HalfLife0o/list/master/ad-mo.txt ad.txt：[推荐移动端] 合并自乘风视频广告过滤规则、EasylistChina、EasylistLite、CJX’sAnnoyance，以及补充的一些规则。 jsdelivr - https://cdn.jsdelivr.net/gh/o0HalfLife0o/list@master/ad.txt GitHub - https://raw.githubusercontent.com/o0HalfLife0o/list/master/ad.txt ad2.txt：合并自乘风视频广告过滤规则、EasylistChina、EasylistLite、CJX’sAnnoyance。 jsdelivr - https://cdn.jsdelivr.net/gh/o0HalfLife0o/list@master/ad2.txt GitHub - https://raw.githubusercontent.com/o0HalfLife0o/list/master/ad2.txt ad3.txt：合并自乘风视频广告过滤规则、EasylistChina、EasylistLite、CJX’sAnnoyance、EasyPrivacy。 jsdelivr - https://cdn.jsdelivr.net/gh/o0HalfLife0o/list@master/ad3.txt GitHub - https://raw.githubusercontent.com/o0HalfLife0o/list/master/ad3.txt ad-edentw.txt：合并自 Adblock Warning Removal List、ABP filters、anti-adblock-killer-filters。 jsdelivr - https://cdn.jsdelivr.net/gh/o0HalfLife0o/list@master/ad-edentw.txt GitHub - https://raw.githubusercontent.com/o0HalfLife0o/list/master/ad-edentw.txt anti-AD anti-AD 致力于成为中文区命中率最高的广告过滤列表，实现精确的广告屏蔽和隐私保护。现已支持 AdGuardHome，dnsmasq， Surge，Pi-Hole 等优秀的网络组件。 使用 anti-AD 能够屏蔽广告域名，能屏蔽电视盒子广告，屏蔽 app 内置广告，同时屏蔽了一些日志收集、大数据统计等涉及个人隐私信息的站点，能够保护个人隐私不被偷偷上传。 本工具是通过域名解析层（DNS 服务）来屏蔽广告和保护隐私的，其将各大著名的 hosts，ad filter lists，adblock list 等的列表进行合并去重，再进行一系列的抽象化，例如主动剔除失效域名、easylist 优化模糊匹配、增强的黑白名单机制等措施，最终生成期望的高命中率列表。 不同格式的过滤列表文件会定期自动更新，其分别用于不同服务中的广告过滤规则: https://anti-ad.net/anti-ad-for-dnsmasq.conf https://anti-ad.net/easylist.txt https://anti-ad.net/domains.txt https://anti-ad.net/surge.txt https://anti-ad.net/surge2.txt（据说更节省内存） https://anti-ad.net/anti-ad-for-smartdns.conf https://anti-ad.net/adguard.txt（adguard 专用规则） 文件名 操作参考 适用范围 anti-ad-for-dnsmasq.conf 1. 下载过滤列表文件后，保存到你的 dnsmasq 配置的正确目录下；2. 重启 dnsmasq 服务；3. 已经生效了，enjoy it。 dnsmasq 及其衍生版本 easylist.txt 1. 进入 AdGuardHome 过滤器页面； 2. 选择添加过滤器输入名称 anti-AD，url 地址填 raw 链接或者 jsDelivr； 3. 点击确认后即生效 AdGuardHome adguard.txt 第一步下载 adguard，第二步加载规则，第三步保存 adguard 专用，解决 easylist 误杀的问题 domains.txt 以 Pi-Hole 为例 1. 进入 pi-hole 设置界面 2. 添加本 domains 列表链接到 pi-hole 的过滤器列表中 3. 点击 save &amp; update 4. 更新成功后即可生效 Pi-Hole 及其他。 surge.txt 直接订阅本条链接，保存后生效 Surge 或兼容服务。 anti-ad-for-smartdns.conf 下载链接后保存到合适位置 SmartDNS 生成这些文件的脚本项目也已在 **GitHub 中开源 **。 Hosts 过滤规则 大圣净化 – 针对国内视频网站 https://raw.githubusercontent.com/jdlingyu/ad-wars/master/hosts 1024_hosts – 1024 网站和澳门皇家赌场 https://raw.githubusercontent.com/Goooler/1024_hosts/master/hosts Google hosts – 提高网站访问速度 https://raw.githubusercontent.com/googlehosts/hosts/master/hosts-files/hosts Hblock – 综合多种源集合体屏蔽广告跟踪和恶意软件 https://hblock.molinero.xyz/hosts Mvps – 屏蔽美欧地区英文网站相关的广告 https://winhelp2002.mvps.org/hosts.txt neoHosts – 国内屏蔽挖矿统计 JS&amp;360 &amp; 百度 &amp; 法轮功等 https://hosts.nfz.moe/full/hosts StevenBlack – 屏蔽国外网站广告 - 国外维护 https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts yhosts – 屏蔽国内网站广告 - 国内维护 https://raw.githubusercontent.com/vokins/yhosts/master/hosts YousList – 屏蔽韩国网站广告 https://raw.githubusercontent.com/yous/YousList/master/hosts.txt AdGuard Home 如果你动手能力比较强，可以考虑自己搭建开源免费的 AdGuard Home。 我有写过一片关于 AdGuard Home 的文章，可以进行参考。"},{"title":"AdGuard Home 使用指南","path":"/article/adguard-guide/","text":"简介 AdGuard 是一系列用于 Mozilla Firefox、Google Chrome、Opera、Apple Safari、Yandex Browser、Microsoft Edge 等网页浏览器及跨平台内容过滤的广告拦截和隐私保护软件、开放源代码和共享软件的浏览器扩展程序产品，AdGuard 允许用户使用阻止广告等页面元素的显示，借此保护 Microsoft Windows、Mac OS、Linux、Android 和 iOS 等操作系统用户免受不必要的广告、弹出窗口、视频、文字、横幅、跟踪、淫秽内容、恶意网站及软件和网络钓鱼的危害。据报道，2018 年有超过 500 万人正在使用该软件。 官网 - https://adguard.com/zh_cn/welcome.html 为什么用户不喜欢广告，以及追踪器？ 一个好产品，需要广而告之，才能活下去，一部好影片，需要广而告之，才有好的票房。因此便有了广告。从最初的口口相传发展到今日的「千人千面、猜你喜欢」，广告已从单向的传播形式发展成为基于个人喜好专门投放，用户的接受权由主动变为被动。 但当广告时时刻刻充斥在我们的生活，看新闻有贴片广告，刷朋友圈有欧巴的互动广告，看电视剧有 90 秒片头广告，小网站上还有 * 感荷官在线发牌，在《一千五百万个积点》中，男主居住在一个被屏幕环绕的房子里，屏幕全天候地播放广告，想要屏蔽广告只能选择付费，甚至在你屏蔽广告后还会提醒用户「为了网站的持续发展，请关闭广告屏蔽插件」，为了正常浏览网页，用户也只能妥协。 并非所有广告都是侵入性、影响用户体验的广告，其中不乏制作精良、体验良好的广告，在由 The Coalition for Better Ads 提出的 Better Ads Standards 中，边栏广告、小型贴片广告、顶栏 / 底部广告对用户的浏览体验影响较小，浮窗广告、大型 / 全屏贴片广告、自动播放的视频广告则会影响用户心情。而用户只能选择全部屏蔽，广告商的收益会受到极大的影响。除了广告，一并被屏蔽掉的还有信息收集与分析工具，如 Google Analytics，此类工具可以在不过分侵犯用户隐私的前提下帮助网站主改善网站运营，提供更好的内容。 广告拦截 / 反追踪插件是如何起作用的？ 广告拦截插件的实现原理大致可分为三种。 Url 匹配屏蔽 流量过滤 网页 DOM 过滤 前两者属于 Request Blocking，后者属于 Page Code Filtering &amp; CSS Injection and JavaScript。 Url 匹配屏蔽 广告联盟的广告资源通常会与网站站点分开放置，以百度联盟为例，百度联盟的广告域名为 https://cpro.baidustatic.com/，因此我们可以单独屏蔽来自 https://cpro.baidustatic.com/ 的内容，同时不会影响网站内容的正常加载。当网站域名与广告资源域名相同时，基于 Url 匹配的广告屏蔽方法如同「南橘北枳」。 流量过滤 在实体网关 / 虚拟网关处设置过滤器，对具备广告特征的流量实施拦截，如网站使用了 Https 加密，则采取 MITM（Man-in-the-middle attack，中间人攻击）对 Https 加密流量进行解密，并对其中的广告流量进行拦截，这一功能在部分第三方路由器固件非常常见，如 KoolProxy、广告屏蔽大师 Plus。 在解密前，客户端上需要安装并信任由广告拦截软件生成的证书，如果网站采取了 Https 加密并需要验证证书，流量过滤的广告拦截功能则会影响网页的正常浏览。此外，如果设备性能偏低，这种拦截方式一定程度上会减慢网速。 网页 DOM 过滤 DOM（Document Object Model，文件物件模型），在 W3C DOM 标准 3 下，网页中的任何一个标签、元素都是树状结构中的一个节点。网页 DOM 过滤广告弥补了基于匹配 Url 屏蔽广告的缺点，通过 CSS3 Selector 定位到广告 DOM 元素，使用 display=none!important 等语法隐藏广告。DOM 过滤过程发生在网页加载时，缺点是无法拦截通过 Ajax、Pjax 新加载的广告内容。 以往我们习惯在电脑浏览器上使用 AdBlock Plus、AdGuard、Ghostery、uBlock Origin 之类的广告拦截与隐私防护插件，从而去除网页上扰人的广告。对于 Android 与 iOS，受限于系统权限（如 Root 权限、系统证书与用户证书）、过滤模式，想在手机上「找到一块净土」，需要花费一番功夫。 上述方法操作后只对单个设备生效，随着设备数量的增加，逐个逐个去设置十分麻烦，此外还会增加软件的订阅费用，面对智能电视、智能音箱，传统的广告拦截软件难以应付。而如果家中有使用软路由、NAS 甚至是树莓派，不妨试试在上面安装 DNS 广告拦截软件，实现网关级的广告拦截。 今天向大家介绍的 DNS 广告过滤软件是 AdGuard 团队开发的 AdGuard Home。 AdGuard Home 是 AdGuard 开源的一个私人 DNS 服务端，只需在网关部署，即可实现全局域网的广告拦截与隐私反追踪。在 DNS 解析的过程中，匹配规则库内的 Url 进行拦截，同时在客户端中，还可以通过自定义过滤规则实现网页 DOM 的拦截。"},{"title":"Docker 扩展命令","path":"/article/docker-extension-command/","text":"清理 prune 命令用来删除不再使用的 docker 对象。 删除所有未被 tag 标记和未被容器使用的镜像 1docker image prune 删除所有未被容器使用的镜像 1docker image prune -a 删除所有停止运行的容器 1docker container prune 删除所有未被挂载的卷 1docker volume prune 删除所有网络 1docker network prune 删除 docker 所有资源 1docker system prune 导出全部镜像 导出命令 12#!/bin/bashdocker save $(docker images --format '{{.Repository}}:{{.Tag}}') -o [filename].tar docker images name 和 tag 都为 none 会报错：Error response from daemon: invalid reference format 导入命令 12#!/bin/bashdocker load -i [filename].tar 查看有哪些镜像 12345678910#!/bin/bashIMAGES=$(docker images --format '{{.Repository}}:{{.Tag}}')for element in ${IMAGES[@]}do #echo \"saving ${element} ...\" #docker save ${element} &gt;&gt; allinone.tar #echo \"${element} saved\" echo \"${element}\"done"},{"title":"一键制作 macOS Monterey U 盘 USB 启动安装盘命令方法教程 (全新安装 Mac 系统)","path":"/article/macos-usb-install-drive/","text":"随着苹果 macOS 正式版发布，很多使用 Mac 电脑的同学都已升级到最新版了。但如果你对系统有洁癖或原本系统已凌乱不堪，那么可能还是希望能格式化「全新安装 macOS」的。 不过由于苹果官方只提供了 macOS 的升级程序，并没提供完整 ISO 镜像，想要全新安装的话，只能自己制作一个 macOS 的 U 盘启动盘 / 安装盘了。今天就给大家提供一个简单的制作教程，这样以后给 Mac 重装系统、在没网络的情况下给多台机器装机都方便许多…… 准备和条件 下载 macOS 要保证下载的安装包 Install macOS *.app（“安装 macOS [版本名称]” 的 App）在 “应用程序” 文件夹。 DMG 的软件包，需要打开拖拽到 “应用程序” 文件夹； ISO 格式也可以拖拽到 “应用程序” 文件夹，或者只需要双击挂载更便捷； PKG 格式的软件包，打开根据提示自动安装到 “应用程序” 文件夹； 在 Mac App Store 下载的 App 会自动保存在 “应用程序” 文件夹。 准备启动介质：USB 移动存储设备 可以使用以下三种介质中的一种： U 盘：Catalina 及以上版本需要 16G 及以上容量的 U 盘，其他旧版本 8G 容量的 U 盘即可（SD 卡同理）； USB 移动硬盘，比如 USB SSD 移动硬盘更佳（推荐！）； 使用系统 “磁盘工具” 新建一个分区（非 APFS 卷），适合有经验的用户，大版本更新推荐使用 USB 外置存储抹掉整个内置磁盘。 使用 “磁盘工具” 抹掉上述介质或者分区，要求如下： Mac OS X 扩展（日志式）； GUID 分区图； 分区名称：sysin（这里为示例名称，可以自定义，简单点就直接按照本文操作即可）。 上述对话框无法正确呈现？请确保已经显示所有设备（如下图），针对设备级别操作。 开始制作 首先，准备一个 8 GB 或更大容量的 U 盘，并备份好里面的所有资料。 下载好 MacOS 正式版的安装程序备用，先不要启动安装。 打开应用程序 → 实用工具 → 磁盘工具，将 U 盘「抹掉」(格式化) 成 **「Mac OS X 扩展（日志式）」** 格式、GUID 分区图，并「给 U 盘改一个名字」。 注意：这个盘符名称必须与后面的命令完全一致，需认真检查，很多新手出错在这里！ 记住你刚才给 U 盘改的名字，建议最好是简单的纯英文且「无空格」，比如就叫做 Mac，否则后面容易出错 ！！ 打开 “应用程序→实用工具→终端”，将下面的一段命令复制并粘贴进去 （记得修改替换成你所取的 U 盘名称，注意名称的大小写敏感） 制作命令如下： 提示：以下命令都是针对正式版，早期的 Beta 版本 App 名称通常是加上 beta。 制作 macOS Ventura 13 启动盘： 1sudo /Applications/Install\\ macOS\\ Ventura.app/Contents/Resources/createinstallmedia --volume /Volumes/你的U盘名称 制作 macOS Monterey 12 启动盘： 1sudo /Applications/Install\\ macOS\\ Monterey.app/Contents/Resources/createinstallmedia --volume /Volumes/你的U盘名称 制作 macOS Big Sur 11 启动盘： 1sudo /Applications/Install\\ macOS\\ Big\\ Sur.app/Contents/Resources/createinstallmedia --volume /Volumes/你的U盘名称 制作 macOS Catalina 10.15 启动盘： 1sudo /Applications/Install\\ macOS\\ Catalina.app/Contents/Resources/createinstallmedia --volume /Volumes/你的U盘名称 制作 macOS High Sierra 10.13 启动盘： 1sudo /Applications/Install\\ macOS\\ High\\ Sierra.app/Contents/Resources/createinstallmedia --volume /Volumes/你的U盘名称 如果您的 Mac 运行的是 macOS Sierra 或更低版本，请使用 --applicationpath 参数和安装器路径，具体方法与在适用于 Sierra 的命令中完成这个操作的方法类似。 制作 macOS Sierra 10.12 启动盘： 1sudo /Applications/Install\\ macOS\\ Sierra.app/Contents/Resources/createinstallmedia --volume /Volumes/sysin --applicationpath /Applications/Install\\ macOS\\ Sierra.app --nointeraction 制作 OS X El Capitan 10.11 启动盘： 1sudo /Applications/Install\\ OS\\ X\\ El\\ Capitan.app/Contents/Resources/createinstallmedia --volume /Volumes/sysin --applicationpath /Applications/Install\\ OS\\ X\\ El\\ Capitan.app 制作 OS X Yosemite 10.10 启动盘： 1sudo /Applications/Install\\ OS\\ X\\ Yosemite.app/Contents/Resources/createinstallmedia --volume /Volumes/sysin --applicationpath /Applications/Install\\ OS\\ X\\ Yosemite.app --nointeraction 键入命令后： 按下 Return 键以输入这个命令。 出现提示时，请键入您的管理员密码，然后再次按下 Return 键。在您键入密码时，“终端” 不会显示任何字符。 出现提示时，请键入 Y 以确认您要抹掉宗卷，然后按下 Return 键。在抹掉宗卷的过程中，“终端” 会显示进度。 宗卷被抹掉后，您可能会看到一条提醒，提示 “终端” 要访问可移除宗卷上的文件。点按 “好” 以允许继续拷贝。 当 “终端” 显示操作已完成时，相应宗卷将拥有与您下载的安装器相同的名称，例如 “安装 macOS Big Sur”。您现在可以退出 “终端” 并弹出宗卷。 如果出现 ”mount of outer dmg failed“ 错误，请在终端中执行命令修复权限（Big Sur 为例）： sudo chmod 755 /Applications/Install\\ macOS\\ Big\\ Sur.app/Contents/Resources/createinstallmedia 错误解决方法 如果你执行上面的命令后出现 mount of outer dmg failed 的错误提示，那么需要在终端中执行一句命令来修复权限（这里以 Monterey 为例）： 1sudo chmod 777 /Applications/Install\\ macOS\\ Monterey.app/Contents/Resources/createinstallmedia 在 Windows 下创建 macOS 引导介质 macOS 是一种 Unix 操作系统，其实这个问题跟如何在 Windows 下如何创建 Linux 引导介质同理。 Linux 写入 USB 引导介质，通常需要一个 ISO 镜像，和一个第三方的 USB Boot 创建工具。 这里推荐使用跨平台的开源免费软件 Etcher，该操作也同样适用于 Linux，在 macOS 下无需这种方式，虽然也是可用的。 条件 USB 存储介质（U 盘，macOS 10.15+ 需要 16G 及以上，USB SSD 移动硬盘更佳） macOS dmg 镜像，使用百度搜索（黑苹果引导镜像）获取 Etcher：跨平台的操作系统镜像 USB 引导创建工具 步骤 使用 “磁盘管理” 将 USB 存储介质格式化为 exFAT 格式 打开 balenaEtcher，选择 Flash from file，浏览到下载的 macOS dmg 文件 注意：会提示 Missing partition table，点击 Continue 即可。 选择要写入的 USB 存储介质 本例中为 hp x5000m 已自动选择： 点击 Flash! 开始写入（需要数分钟到数十分钟不等，取决于介质本身） 写入成功的截图： 写入成功的 USB 存储介质格式为 “Mac OS 扩展（日志式）”，Windows 等第三方系统是无法读取的，显示为 RAW 格式。"},{"title":"OhMyZSH 使用指北","path":"/article/oh-my-zsh/","text":"OhMyZsh 是一个令人愉快、开源、社区驱动的框架，用于管理你的 Zsh 配置。它捆绑了数千个有用的功能，助手，插件，主题，和一些让你惊艳的东西… 官网 - https://ohmyz.sh/ 安装 1234# curl安装sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"# wget安装sh -c \"$(wget https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\" 官网教程 - https://ohmyz.sh/#install 插件推荐 git 默认开启 可以使用各种 git 命令缩写。😋 比如 123git add --all ===&gt; gaagit commit -m ===&gt; gcmsg 官方文档 - https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git 或者筛选对应的命令 如和 config 有关的命令 1alias | grep config z 作用 目录间快速跳转，不用再一直 cd 了 😁 使用 cd 命令进入 ~/user/github/Youthink 文件夹，下次还想进入文件夹的时候，直接使用 z youthink 即可，或者只输入 youthink 的一部分 youth 都行。 123456# 删除无效路径z -x &lt;dir&gt;# 打开music文件夹z music# 使用多个参数打开 /home/user/work/inboxz w in 效果图 zsh-syntax-highlighting 作用 平常用的 ls、cd 等命令输入正确会绿色高亮显示，输入错误会显示其他的颜色。 官网 - https://github.com/zsh-users/zsh-syntax-highlighting 安装 克隆项目 1git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting 在 ~/.zshrc 中配置 1plugins=( [plugins...] zsh-syntax-highlighting) 使配置生效 1source ~/.zshrc zsh-autosuggestions 官网 - https://github.com/zsh-users/zsh-autosuggestions 作用 效率神器 👍 如图输入命令时，会给出建议的命令（灰色部分）按键盘 → 补全 如果感觉 → 补全不方便，还可以自定义补全的快捷键，比如我设置的逗号补全 1bindkey ',' autosuggest-accept 在 .zshrc 文件添加这句话即可。 安装 克隆项目 1git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions 在 ~/.zshrc 中配置 1plugins=( [plugins...] zsh-syntax-highlighting) 使配置生效 1source ~/.zshrc"},{"title":"Python 爬虫从入门到放弃（七）PyQuery 库的使用","path":"/article/python-spider-7/","text":"PyQuery 库也是一个非常强大又灵活的网页解析库，如果你有前端开发经验的，都应该接触过 jQuery，那么 PyQuery 就是你非常绝佳的选择，PyQuery 是 Python 仿照 jQuery 的严格实现。语法与 jQuery 几乎完全相同，所以不用再去费心去记一些奇怪的方法了。 官网地址 - https://pyquery.readthedocs.io/en/latest/ jQuery 参考文档 - https://jquery.cuishifeng.cn/ 初始化 初始化的时候一般有三种传入方式：传入字符串，传入 url，传入文件。 字符串初始化 1234567891011121314151617from pyquery import PyQuery as pqhtml = '''&lt;div&gt; &lt;ul&gt; &lt;li class=\"item-0\"&gt;first item&lt;/li&gt; &lt;li class=\"item-1\"&gt;&lt;a href=\"link2.html\"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=\"item-0 active\"&gt;&lt;a href=\"link3.html\"&gt;&lt;span class=\"bold\"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=\"item-1 active\"&gt;&lt;a href=\"link4.html\"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=\"item-0\"&gt;&lt;a href=\"link5.html\"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''doc = pq(html)print(doc)print(type(doc))print(doc('li')) 输出： 由于 PyQuery 写起来比较麻烦，所以我们导入的时候都会添加别名： 1from pyquery import PyQuery as pq 这里我们可以知道上述代码中的 doc 其实就是一个 pyquery 对象，我们可以通过 doc 可以进行元素的选择，其实这里就是一个 css 选择器，所以 css 选择器的规则都可以用，直接 doc(tag_name) 就可以获取所有的该标签的内容，如果想要获取 class 则 doc('.class_name')，如果是 id 则 doc('#id_name')。 URL 初始化 12345from pyquery import PyQuery as pqdoc = pq(url=\"http://www.baidu.com\", encoding='utf-8')print(doc('head')) 文件初始化 我们在 pq() 这里可以传入 url 参数也可以传入文件参数，当然这里的文件通常是一个 html 文件，例如：pq(filename='index.html') 基本的 CSS 选择器 12345678910111213141516from pyquery import PyQuery as pqhtml = '''&lt;div id=\"container\"&gt; &lt;ul class=\"list\"&gt; &lt;li class=\"item-0\"&gt;first item&lt;/li&gt; &lt;li class=\"item-1\"&gt;&lt;a href=\"link2.html\"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=\"item-0 active\"&gt;&lt;a href=\"link3.html\"&gt;&lt;span class=\"bold\"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=\"item-1 active\"&gt;&lt;a href=\"link4.html\"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=\"item-0\"&gt;&lt;a href=\"link5.html\"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;'''doc = pq(html)print(doc('#container .list li')) 这里我们需要注意的一个地方是 doc('#container .list li')，这里的三者之间的并不是必须要挨着，只要是层级关系就可以，下面是常用的 CSS 选择器方法："},{"title":"Python 爬虫从入门到放弃（六）BeautifulSoup 库的使用","path":"/article/python-spider-6/","text":"上一篇文章的正则，其实对很多人来说用起来是不方便的，加上需要记很多规则，所以用起来不是特别熟练，而这篇我们提到的 BeautifulSoup 就是一个非常强大的工具，爬虫利器。 BeautifulSoup “美味的汤，绿色的浓汤” 一个灵活又方便的网页解析库，处理高效，支持多种解析器。 利用它就不用编写正则表达式也能方便的实现网页信息的抓取 快速使用 通过下面的一个例子，对 bs4 有个简单的了解，以及看一下它的强大之处： 12345678910111213141516171819202122232425from bs4 import BeautifulSouphtml = '''&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class=\"title\"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;&lt;p class=\"story\"&gt;Once upon a time there were three little sisters; and their names were&lt;a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"&gt;Elsie&lt;/a&gt;,&lt;a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\"&gt;Lacie&lt;/a&gt; and&lt;a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\"&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=\"story\"&gt;...&lt;/p&gt;'''soup = BeautifulSoup(html,'lxml')print(soup.prettify())print(soup.title)print(soup.title.name)print(soup.title.string)print(soup.title.parent.name)print(soup.p)print(soup.p[\"class\"])print(soup.a)print(soup.find_all('a'))print(soup.find(id='link3')) 结果： 使用 BeautifulSoup 解析这段代码，能够得到一个 BeautifulSoup 的对象，并能按照标准的缩进格式的结构输出。 同时我们通过下面代码可以分别获取所有的链接，以及文字内容： 1234for link in soup.find_all('a'): print(link.get('href'))print(soup.get_text()) 解析器 BeautifulSoup 支持 Python 标准库中的 HTML 解析器，还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python 默认的解析器，lxml 解析器更加强大，速度更快，推荐安装。 下面是常见解析器： 推荐使用 lxml 作为解析器，因为效率更高。 在 Python2.7.3 之前的版本和 Python3 中 3.2.2 之前的版本，必须安装 lxml 或 html5lib，因为那些 Python 版本的标准库中内置的 HTML 解析方法不够稳定。 基本使用 标签选择器 在快速使用中我们添加如下代码： 1234print(soup.title)print(type(soup.title))print(soup.head)print(soup.p) 通过这种 soup.{tag_name} 我们就可以获得这个标签的内容。 这里有个问题需要注意，通过这种方式获取标签，如果文档中有多个这样的标签，返回的结果是第一个标签的内容，如上面我们通过 soup.p 获取 p 标签，而文档中有多个 p 标签，但是只返回第一个 p 标签内容。 获取名称 当我们通过 soup.title.name 的时候就可以获得该标签的名称，即 title 获取属性 12print(soup.p.attrs['name'])print(soup.p['name']) 上面两种方式都可以获取 p 标签的 name 属性值 获取内容 1print(soup.p.string) 结果就可以获取第一个 p 标签的内容。 嵌套选择 我们直接可以通过下面嵌套的方式获取 1print(soup.head.title.string) 子节点和子孙节点 contents 的使用 通过下面例子演示： 123456789101112131415161718192021222324from bs4 import BeautifulSouphtml = \"\"\"&lt;html&gt; &lt;head&gt; &lt;title&gt;The Dormouse's story&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class=\"story\"&gt; Once upon a time there were three little sisters; and their names were &lt;a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; &lt;a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\"&gt;Lacie&lt;/a&gt; and &lt;a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\"&gt;Tillie&lt;/a&gt; and they lived at the bottom of a well. &lt;/p&gt; &lt;p class=\"story\"&gt;...&lt;/p&gt;\"\"\"soup = BeautifulSoup(html, 'lxml')print(soup.p.contents) 结果是将 p 标签下的所有子标签存入到了一个列表中 列表中会存入如下元素 children 的使用 通过下面的方式也可以获取 p 标签下的所有子节点内容和通过 contents 获取的结果是一样的，但是不同的地方是 soup.p.children 是一个迭代对象，而不是列表，只能通过循环的方式获取素有的信息 123print(soup.p.children)for i,child in enumerate(soup.p.children): print(i,child) 通过 contents 以及 children 都是获取子节点，如果想要获取子孙节点可以通过 descendants print(soup.descendants) 同时这种获取的结果也是一个迭代器 父节点和祖先节点 通过 soup.a.parent 就可以获取父节点的信息 通过 list(enumerate(soup.a.parents)) 可以获取祖先节点，这个方法返回的结果是一个列表，会分别将 a 标签的父节点的信息存放到列表中，以及父节点的父节点也放到列表中，并且最后还会将整个文档放到列表中，所有列表的最后一个元素以及倒数第二个元素都是存的整个文档的信息 兄弟节点 soup.a.next_siblings 获取后面的兄弟节点 soup.a.previous_siblings 获取前面的兄弟节点 soup.a.next_sibling 获取下一个兄弟标签 soup.a.previous_sibling 获取上一个兄弟标签 标准选择器 find_all find_all(name, attrs, recursive, text, **kwargs) 可以根据标签名，属性，内容查找文档 name 的用法 123456789101112131415161718192021222324from bs4 import BeautifulSouphtml = '''&lt;div class=\"panel\"&gt; &lt;div class=\"panel-heading\"&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=\"panel-body\"&gt; &lt;ul class=\"list\" id=\"list-1\"&gt; &lt;li class=\"element\"&gt;Foo&lt;/li&gt; &lt;li class=\"element\"&gt;Bar&lt;/li&gt; &lt;li class=\"element\"&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=\"list list-small\" id=\"list-2\"&gt; &lt;li class=\"element\"&gt;Foo&lt;/li&gt; &lt;li class=\"element\"&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;'''soup = BeautifulSoup(html, 'lxml')print(soup.find_all('ul'))print(type(soup.find_all('ul')[0])) 结果是以列表的方式返回。 同时我们是可以针对结果再次 find_all, 从而获取所有的 li 标签信息 12for ul in soup.find_all('ul'): print(ul.find_all('li')) attrs 例子： 123456789101112131415161718192021222324from bs4 import BeautifulSouphtml = '''&lt;div class=\"panel\"&gt; &lt;div class=\"panel-heading\"&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=\"panel-body\"&gt; &lt;ul class=\"list\" id=\"list-1\" name=\"elements\"&gt; &lt;li class=\"element\"&gt;Foo&lt;/li&gt; &lt;li class=\"element\"&gt;Bar&lt;/li&gt; &lt;li class=\"element\"&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=\"list list-small\" id=\"list-2\"&gt; &lt;li class=\"element\"&gt;Foo&lt;/li&gt; &lt;li class=\"element\"&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;'''soup = BeautifulSoup(html, 'lxml')print(soup.find_all(attrs={'id': 'list-1'}))print(soup.find_all(attrs={'name': 'elements'})) attrs 可以传入字典的方式来查找标签，但是这里有个特殊的就是 class, 因为 class 在 python 中是特殊的字段，所以如果想要查找 class 相关的可以更改 attrs={'class_': 'element'} 或者 soup.find_all('',{\"class\":\"element})，特殊的标签属性可以不写 attrs，例如 id text 例子： 1234567891011121314151617181920212223from bs4 import BeautifulSouphtml='''&lt;div class=\"panel\"&gt; &lt;div class=\"panel-heading\"&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=\"panel-body\"&gt; &lt;ul class=\"list\" id=\"list-1\"&gt; &lt;li class=\"element\"&gt;Foo&lt;/li&gt; &lt;li class=\"element\"&gt;Bar&lt;/li&gt; &lt;li class=\"element\"&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=\"list list-small\" id=\"list-2\"&gt; &lt;li class=\"element\"&gt;Foo&lt;/li&gt; &lt;li class=\"element\"&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;'''soup = BeautifulSoup(html, 'lxml')print(soup.find_all(text='Foo')) 结果返回的是查到的所有的 text='Foo' 的文本 find find(name, attrs, recursive, text, **kwargs) find 返回匹配结果的第一个元素 其他一些类似的用法： find_parents() 返回所有祖先节点，find_parent() 返回直接父节点。 find_next_siblings() 返回后面所有兄弟节点，find_next_sibling() 返回后面第一个兄弟节点。 find_previous_siblings() 返回前面所有兄弟节点，find_previous_sibling() 返回前面第一个兄弟节点。 find_all_next() 返回节点后所有符合条件的节点，find_next() 返回第一个符合条件的节点 find_all_previous() 返回节点后所有符合条件的节点，find_previous() 返回第一个符合条件的节点 CSS 选择器 通过 select() 直接传入 CSS 选择器就可以完成选择。 熟悉前端的人对 CSS 可能更加了解，其实用法也是一样的。 . 表示 class，#表示 id tag1, tag2 找到所有的标签 1 和标签 2 tag1 tag1-1 找到标签 1 内部的所有的标签 2 [attr] 可以通过这种方法找到具有某个属性的所有标签 [attr=value] 例子 [target=_blank] 表示查找所有 target=_blank 的标签 完整教程 - https://developer.mozilla.org/zh-CN/docs/Web/CSS 获取内容 通过 get_text() 就可以获取文本内容 [](javascript:void(0)😉 123456789101112131415161718192021222324from bs4 import BeautifulSouphtml='''&lt;div class=\"panel\"&gt; &lt;div class=\"panel-heading\"&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=\"panel-body\"&gt; &lt;ul class=\"list\" id=\"list-1\"&gt; &lt;li class=\"element\"&gt;Foo&lt;/li&gt; &lt;li class=\"element\"&gt;Bar&lt;/li&gt; &lt;li class=\"element\"&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=\"list list-small\" id=\"list-2\"&gt; &lt;li class=\"element\"&gt;Foo&lt;/li&gt; &lt;li class=\"element\"&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;'''soup = BeautifulSoup(html, 'lxml')for li in soup.select('li'): print(li.get_text()) 获取属性 或者属性的时候可以通过 [属性名] 或者 attrs [属性名] [](javascript:void(0)😉 12345678910111213141516171819202122232425from bs4 import BeautifulSouphtml='''&lt;div class=\"panel\"&gt; &lt;div class=\"panel-heading\"&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=\"panel-body\"&gt; &lt;ul class=\"list\" id=\"list-1\"&gt; &lt;li class=\"element\"&gt;Foo&lt;/li&gt; &lt;li class=\"element\"&gt;Bar&lt;/li&gt; &lt;li class=\"element\"&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=\"list list-small\" id=\"list-2\"&gt; &lt;li class=\"element\"&gt;Foo&lt;/li&gt; &lt;li class=\"element\"&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;'''soup = BeautifulSoup(html, 'lxml')for ul in soup.select('ul'): print(ul['id']) print(ul.attrs['id']) 总结 推荐使用 lxml 解析库，必要时使用 html.parser 标签选择筛选功能弱但是速度快 建议使用 find()、find_all() 查询匹配单个结果或者多个结果 如果对 CSS 选择器熟悉建议使用 select() 记住常用的获取属性和文本值的方法 最后 这里只是简单介绍基本操作，高级操作请 look 官方文档。 官方文档 - https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/"},{"title":"Python 爬虫从入门到放弃（五）正则的基本使用","path":"/article/python-spider-5/","text":"什么是正则表达式 正则表达式是对字符串操作的一种逻辑公式，就是事先定义好的一些特定字符及这些特定字符的组合，组成一个 “规则字符”，这个 “规则字符” 来表达对字符的一种过滤逻辑。 正则并不是 Python 独有的，其他语言也都有正则，Python 中的正则，封装成了 re 模块。 python 正则的详细讲解 特殊字符 字符 描述 \\w 匹配字母数字及下划线 \\W 匹配 f 非字母数字下划线 \\s 匹配任意空白字符，等价于 [\\t\\n\\r\\f] \\S 匹配任意非空字符 \\d 匹配任意数字 \\D 匹配任意非数字 \\A 匹配字符串开始 \\Z 匹配字符串结束，如果存在换行，只匹配换行前的结束字符串 \\z 匹配字符串结束 \\G 匹配最后匹配完成的位置 \\n 匹配一个换行符 \\t 匹配一个制表符 ^ 匹配字符串的开头 $ 匹配字符串的末尾 . 匹配任意字符，除了换行符，re.DOTALL 标记被指定时，则可以匹配包括换行符的任意字符 […] 用来表示一组字符，单独列出：[amk] 匹配 a,m 或 k [^…] 不在 [] 中的字符：[^abc] 匹配除了 a,b,c 之外的字符 限定符 字符 描述 * 匹配 0 个或多个的表达式 + 匹配 1 个或者多个的表达式 ? 匹配 0 个或 1 个由前面的正则表达式定义的片段，非贪婪方式 {n} 精确匹配 n 前面的表示 {m,m} 匹配 n 到 m 次由前面的正则表达式定义片段，贪婪模式 a|b 匹配 a 或者 b () 匹配括号内的表达式，也表示一个组 re.match() 尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配的话，match() 就会返回 None，语法格式： 1re.match(pattern,string,flags=0) 最常规的匹配 1234567import recontent = \"hello 123 4567 World_This is a regex Demo\"result = re.match(r\"^hello\\s\\d\\d\\d\\s\\d{4}\\s\\w{10}.*Demo$\", content)print(result)print(result.group())print(result.span()) 结果如下： result.group() - 获取匹配的结果 result.span() - 获去匹配字符串的长度范围 泛匹配 其实相对来说上面的方式并不是非常方便，其实可以将上述的正则规则进行更改 1234567import recontent = \"hello 123 4567 World_This is a regex Demo\"result = re.match(r\"^hello.*Demo$\", content)print(result)print(result.group())print(result.span()) 这段代码的结果和上面常规匹配的结果是一样的，但是写起来会方便很多 匹配目标 如果为了匹配字符串中具体的目标，则需要通过 () 括起来，例子如下： 12345678import recontent = \"hello 1234567 World_This is a regex Demo\"result = re.match(r'^hello\\s(\\d+)\\sWorld.*Demo$', content)print(result)print(result.group())print(result.group(1))print(result.span()) 结果如下： 这里需要说一下的是通过 re.group() 获得结果后，如果正则表达式中有括号，则 re.group(1) 获取的就是第一个括号中匹配的结果 贪婪匹配 先看下面代码： 123456import recontent = \"hello 1234567 World_This is a regex Demo\"result = re.match(r'^hello.*(\\d+).*Demo', content)print(result)print(result.group(1)) 结果： 从结果中可以看出只匹配到了 7，并没有匹配到 1234567，出现这种情况的原因是前面的.* 给匹配掉了，.* 在这里会尽可能的匹配多的内容，也就是我们所说的贪婪匹配， 如果我们想要匹配到 1234567 则需要将正则表达式改为： 1result = re.match(r'^he.*?(\\d+).*Demo', content) 这样结果就可以匹配到 1234567 匹配模式 很多时候匹配的内容是存在换行的问题的，这个时候的就需要用到匹配模式 re.S 来匹配换行的内容 12345678910import recontent = \"\"\"hello 123456 world_thismy name is zhangsan\"\"\"result = re.match(r'^he.*?(\\d+).*?zhangsan$', content, re.S)print(result)print(result.group())print(result.group(1)) 结果： 转义 当我们要匹配的内容中存在特殊字符的时候，就需要用到转移符号 \\，例子如下： 1234567import recontent = \"price is $5.00\"result = re.match(r'price is \\$5\\.00', content)print(result)print(result.group()) 对上面的一个小结： 尽量使用泛匹配，使用括号得到匹配目标，尽量使用非贪婪模式，有换行符就用 re.S 强调 re.match 是从字符串的起始位置匹配一个模式 re.search re.search 扫描整个字符串返回第一个成功匹配的结果 12345678import recontent = \"extra things hello 123455 world_this is a Re Extra things\"result = re.search(r\"hello.*?(\\d+).*?Re\", content)print(result)print(result.group())print(result.group(1)) 结果： 其实这个时候我们就不需要在写 ^ 以及 $，因为 search 是扫描整个字符串 注意：所以为了匹配方便，我们会更多的用 search，不用 match,match 必须匹配头部，所以很多时候不是特别方便 匹配演练 12345678910111213141516171819202122232425262728import rehtml = '''&lt;div id=\"songs-list\"&gt; &lt;h2 class=\"title\"&gt;经典老歌&lt;/h2&gt; &lt;p class=\"introduction\"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id=\"list\" class=\"list-group\"&gt; &lt;li data-view=\"2\"&gt;一路上有你&lt;/li&gt; &lt;li data-view=\"7\"&gt; &lt;a href=\"/2.mp3\" singer=\"任贤齐\"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view=\"4\" class=\"active\"&gt; &lt;a href=\"/3.mp3\" singer=\"齐秦\"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view=\"6\"&gt;&lt;a href=\"/4.mp3\" singer=\"beyond\"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view=\"5\"&gt;&lt;a href=\"/5.mp3\" singer=\"陈慧琳\"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view=\"5\"&gt; &lt;a href=\"/6.mp3\" singer=\"邓丽君\"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''result = re.search(r'&lt;li.*?active.*?singer=\"(.*?)\"&gt;(.*?)&lt;/a&gt;', html, re.S)print(result)print(result.groups())print(result.group(1))print(result.group(2)) 结果： re.findall 搜索字符串，以列表的形式返回全部能匹配的子串 例子： 1234567891011121314151617181920212223242526272829import rehtml = '''&lt;div id=\"songs-list\"&gt; &lt;h2 class=\"title\"&gt;经典老歌&lt;/h2&gt; &lt;p class=\"introduction\"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id=\"list\" class=\"list-group\"&gt; &lt;li data-view=\"2\"&gt;一路上有你&lt;/li&gt; &lt;li data-view=\"7\"&gt; &lt;a href=\"/2.mp3\" singer=\"任贤齐\"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view=\"4\" class=\"active\"&gt; &lt;a href=\"/3.mp3\" singer=\"齐秦\"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view=\"6\"&gt;&lt;a href=\"/4.mp3\" singer=\"beyond\"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view=\"5\"&gt;&lt;a href=\"/5.mp3\" singer=\"陈慧琳\"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view=\"5\"&gt; &lt;a href=\"/6.mp3\" singer=\"邓丽君\"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''results = re.findall(r'&lt;li.*?href=\"(.*?)\".*?singer=\"(.*?)\"&gt;(.*?)&lt;/a&gt;', html, re.S)print(results)print(type(results))for result in results: print(result) print(result[0], result[1], result[2]) 结果： 例子 2： 123456789101112131415161718192021222324252627import rehtml = '''&lt;div id=\"songs-list\"&gt; &lt;h2 class=\"title\"&gt;经典老歌&lt;/h2&gt; &lt;p class=\"introduction\"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id=\"list\" class=\"list-group\"&gt; &lt;li data-view=\"2\"&gt;一路上有你&lt;/li&gt; &lt;li data-view=\"7\"&gt; &lt;a href=\"/2.mp3\" singer=\"任贤齐\"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view=\"4\" class=\"active\"&gt; &lt;a href=\"/3.mp3\" singer=\"齐秦\"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view=\"6\"&gt;&lt;a href=\"/4.mp3\" singer=\"beyond\"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view=\"5\"&gt;&lt;a href=\"/5.mp3\" singer=\"陈慧琳\"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view=\"5\"&gt; &lt;a href=\"/6.mp3\" singer=\"邓丽君\"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''results = re.findall(r'&lt;li.*?&gt;\\s*?(&lt;a.*?&gt;)?(\\w+)(&lt;/a&gt;)?\\s*?&lt;/li&gt;', html, re.S)print(results)for result in results: print(result[1]) 结果： 其实这里我们就可以看出 \\s*? 这种用法其实就是为了解决有的有换行，有的没有换行的问题 (&lt;a.*?&gt;)? 这种用法是因为 html 中有的有 a 标签，有的没有的，？表示匹配一个或 0 个，正好可以用于匹配 re.sub 替换字符串中每一个匹配的子串后返回替换后的字符串 re.sub(pattern, repl, string, count=0, flags=0) 例子 1： 123456import recontent = \"Extra things hello 123455 World_this is a regex Demo extra things\"content = re.sub(r' \\d+', '', content)print(content) 结果为数字替换为空： 例子 2，在有些情况下我们替换字符的时候，还想获取我们匹配的字符串，然后在后面添加一些内容，可以通过下面方式实现： 123456import recontent = \"Extra things hello 12345 World_this is a regex Demo extra things\"content = re.sub(r'(\\d+)', r'\\1 7890',content)print(content) 结果： 这里需要注意的一个问题是 \\1 是获取第一个匹配的结果，为了防止转义字符的问题，我们需要在前面加上 r re.compile 将正则表达式编译成正则表达式对象，方便复用该正则表达式 12345678910import recontent = \"\"\"hello 12345 world_this123 fan\"\"\"pattern = re.compile(\"hello.*fan\", re.S)result = re.match(pattern, content)print(result)print(result.group()) 正则的综合练习 获取豆瓣网书籍的页面的书籍信息，通过正则实现 1234567891011import requestsimport recontent = requests.get('https://book.douban.com/').textpattern = re.compile('&lt;li.*?cover.*?href=\"(.*?)\".*?title=\"(.*?)\".*?more-meta.*?author\"&gt;(.*?)&lt;/span&gt;.*?year\"&gt;(.*?)&lt;/span&gt;.*?&lt;/li&gt;', re.S)results = re.findall(pattern, content)for result in results: url,name,author,date = result author = re.sub('\\s','',author) date = re.sub('\\s','',date) print(url,name,author,date) 最后 这里只是简单介绍基本操作，高级操作请 look 官方文档。 官方文档 - https://docs.python-requests.org/zh_CN/latest/"},{"title":"Python 爬虫从入门到放弃（四）requests 库的基本使用","path":"/article/python-spider-4/","text":"什么是 requests requests 是基于上篇的 urllib 编写的，采用的是 Apache2 Licensed 开源协议的 HTTP 库 如果你看过上篇文章关于 urllib 库的使用，你会发现，其实 urllib 还是非常不方便的，而 requests 它会比 urllib 更加方便，可以节约我们大量的工作。（用了 requests 之后，你基本都不愿意用 urllib 了）一句话，requests 是 python 实现的最简单易用的 HTTP 库，建议爬虫使用 requests 库。 默认安装好 python 之后，是没有安装 requests 模块的，需要单独通过 pip 安装 1pip install -U requests requests 功能详解 总体功能的一个演示 12345678910import requestsresponse = requests.get(\"https://www.baidu.com\")print(type(response))print(response.status_code)print(type(response.text))print(response.text)print(response.cookies)print(response.content)print(response.content.decode(\"utf-8\")) 我们可以看出 response 使用起来确实非常方便，这里有个问题需要注意一下： 很多情况下的网站如果直接 response.text 会出现乱码的问题，所以这个使用 response.content 这样返回的数据格式其实是二进制格式，然后通过 decode() 转换为 utf-8，这样就解决了通过 response.text 直接返回显示乱码的问题. 请求发出后，requests 会基于 HTTP 头部对响应的编码作出有根据的推测。当你访问 response.text 之时，requests 会使用其推测的文本编码。你可以找出 requests 使用了什么编码，并且能够使用 response.encoding 属性来改变它。如： 123response =requests.get(\"http://www.baidu.com\")response.encoding=\"utf-8\"print(response.text) 不管是通过 response.content.decode(\"utf-8) 的方式还是通过 response.encoding=\"utf-8\" 的方式都可以避免乱码的问题发生 各种请求方式 requests 里提供个各种请求方式 123456import requestsrequests.post(\"http://httpbin.org/post\")requests.put(\"http://httpbin.org/put\")requests.delete(\"http://httpbin.org/delete\")requests.head(\"http://httpbin.org/get\")requests.options(\"http://httpbin.org/get\") 基本 GET 请求 1234import requestsresponse = requests.get('http://httpbin.org/get')print(response.text) 带参数的 GET 请求，例子 1 1234import requestsresponse = requests.get(\"http://httpbin.org/get?name=zhaofan&amp;age=23\")print(response.text) 如果我们想要在 URL 查询字符串传递数据，通常我们会通过 httpbin.org/get?key=val 方式传递。requests 模块允许使用 params 关键字传递参数，以一个字典来传递这些参数，例子如下： 12345678import requestsdata = { \"name\":\"张三\", \"age\":22}response = requests.get(\"http://httpbin.org/get\",params=data)print(response.url)print(response.text) 解析 json 12345678import requestsimport jsonresponse = requests.get(\"http://httpbin.org/get\")print(type(response.text))print(response.json())print(json.loads(response.text))print(type(response.json())) 从结果可以看出两者的返回是一样的，阅读源码发现 requests 里面集成的 json 其实就是执行了 json.loads() 方法，两者的结果是一样的 获取二进制数据 在上面提到了 response.content，这样获取的数据是二进制数据，同样的这个方法也可以用于下载图片以及 视频资源 添加 headers 和前面我们将 urllib 模块的时候一样，我们同样可以定制 headers 的信息，如当我们直接通过 requests 请求知乎网站的时候，默认是无法访问的 123import requestsresponse = requests.get(\"https://www.zhihu.com\")print(response.text) 这样会得到如下的错误 因为访问知乎需要头部信息，这个时候我们在谷歌浏览器里输入 chrome://version, 就可以看到用户代理，将用户代理添加到头部信息 1234567import requestsheaders = { \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36\"}response = requests.get(\"https://www.zhihu.com\", headers=headers)print(response.text) 这样就可以正常的访问知乎了 基本 POST 请求 通过在发送 post 请求时添加一个 data 参数，这个 data 参数可以通过字典构造成，这样对于发送 post 请求就非常方便 12345678import requestsdata = { \"name\":\"张三\", \"age\":23}response = requests.post(\"http://httpbin.org/post\", data=data)print(response.text) 同样的在发送 post 请求的时候也可以和发送 get 请求一样通过 headers 参数传递一个字典类型的数据 响应 我们可以通过 response 获得很多属性，例子如下 12345678import requestsresponse = requests.get(\"http://www.baidu.com\")print(type(response.status_code),response.status_code)print(type(response.headers),response.headers)print(type(response.cookies),response.cookies)print(type(response.url),response.url)print(type(response.history),response.history) 状态码判断 requests 还附带了一个内置的状态码查询对象，主要有如下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475100: ('continue',),101: ('switching_protocols',),102: ('processing',),103: ('checkpoint',),122: ('uri_too_long', 'request_uri_too_long'),200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\o/', '✓'),201: ('created',),202: ('accepted',),203: ('non_authoritative_info', 'non_authoritative_information'),204: ('no_content',),205: ('reset_content', 'reset'),206: ('partial_content', 'partial'),207: ('multi_status', 'multiple_status', 'multi_stati', 'multiple_stati'),208: ('already_reported',),226: ('im_used',),# Redirection300: ('multiple_choices',),301: ('moved_permanently', 'moved', '\\o-'),302: ('found',),303: ('see_other', 'other'),304: ('not_modified',),305: ('use_proxy',),306: ('switch_proxy',),307: ('temporary_redirect', 'temporary_moved', 'temporary'),308: ('permanent_redirect','resume_incomplete', 'resume',), # These 2 to be removed in 3.0# Client Error400: ('bad_request', 'bad'),401: ('unauthorized',),402: ('payment_required', 'payment'),403: ('forbidden',),404: ('not_found', '-o-'),405: ('method_not_allowed', 'not_allowed'),406: ('not_acceptable',),407: ('proxy_authentication_required', 'proxy_auth', 'proxy_authentication'),408: ('request_timeout', 'timeout'),409: ('conflict',),410: ('gone',),411: ('length_required',),412: ('precondition_failed', 'precondition'),413: ('request_entity_too_large',),414: ('request_uri_too_large',),415: ('unsupported_media_type', 'unsupported_media', 'media_type'),416: ('requested_range_not_satisfiable', 'requested_range', 'range_not_satisfiable'),417: ('expectation_failed',),418: ('im_a_teapot', 'teapot', 'i_am_a_teapot'),421: ('misdirected_request',),422: ('unprocessable_entity', 'unprocessable'),423: ('locked',),424: ('failed_dependency', 'dependency'),425: ('unordered_collection', 'unordered'),426: ('upgrade_required', 'upgrade'),428: ('precondition_required', 'precondition'),429: ('too_many_requests', 'too_many'),431: ('header_fields_too_large', 'fields_too_large'),444: ('no_response', 'none'),449: ('retry_with', 'retry'),450: ('blocked_by_windows_parental_controls', 'parental_controls'),451: ('unavailable_for_legal_reasons', 'legal_reasons'),499: ('client_closed_request',),# Server Error500: ('internal_server_error', 'server_error', '/o\\', '✗'),501: ('not_implemented',),502: ('bad_gateway',),503: ('service_unavailable', 'unavailable'),504: ('gateway_timeout',),505: ('http_version_not_supported', 'http_version'),506: ('variant_also_negotiates',),507: ('insufficient_storage',),509: ('bandwidth_limit_exceeded', 'bandwidth'),510: ('not_extended',),511: ('network_authentication_required', 'network_auth', 'network_authentication'), 通过下面例子测试：（不过通常还是通过状态码判断更方便） 12345import requestsresponse = requests.get(\"http://www.baidu.com\")if response.status_code == requests.codes.ok: print(\"访问成功\") requests 高级用法 文件上传 实现方法和其他参数类似，也是构造一个字典然后通过 files 参数传递 1234import requestsfiles = {\"files\": open(\"git.jpeg\", \"rb\")}response = requests.post(\"http://httpbin.org/post\", files=files)print(response.text) 结果如下： 获取 cookie 1234567import requestsresponse = requests.get(\"http://www.baidu.com\")print(response.cookies)for key, value in response.cookies.items(): print(key + \"=\" + value) 会话维持 cookie 的一个作用就是可以用于模拟登陆，做会话维持 12345import requestss = requests.Session()s.get(\"http://httpbin.org/cookies/set/number/123456\")response = s.get(\"http://httpbin.org/cookies\")print(response.text) 这是正确的写法，而下面的写法则是错误的 12345import requestsrequests.get(\"http://httpbin.org/cookies/set/number/123456\")response = requests.get(\"http://httpbin.org/cookies\")print(response.text) 因为这种方式是两次 requests 请求之间是独立的，而第一次则是通过创建一个 session 对象，两次请求都通过这个对象访问 证书验证 现在的很多网站都是 https 的方式访问，所以这个时候就涉及到证书的问题 1234import requestsresponse = requests.get(\"https:/www.12306.cn\")print(response.status_code) 默认的 12306 网站的证书是不合法的，这样就会提示如下错误 为了避免这种情况的发生可以通过 verify=False 虽然这样可以访问到页面，但是会提示： InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings InsecureRequestWarning) 解决方法为： 12345import requestsfrom requests.packages import urllib3urllib3.disable_warnings()response = requests.get(\"https://www.12306.cn\", verify=False)print(response.status_code) 这样就不会提示警告信息，当然也可以通过 cert 参数放入证书路径 代理设置 12345678import requestsproxies = { \"http\":\"http://127.0.0.1:7890\", \"https\":\"http://127.0.0.1:7890\"}response = requests.get(\"https://www.baidu.com\", proxies=proxies)print(response.text) 如果代理需要设置账户名和密码，只需要将字典更改为如下： 123proxies = { \"http\":\"http://user:password@127.0.0.1:7890\"} 如果你的代理是通过 socks 这种方式则需要 pip install requests[socks] 1234proxies= { \"http\": \"socks5://127.0.0.1:7890\", \"https\": \"socks5://127.0.0.1:7890\"} 超时设置 通过 timeout 参数可以设置超时的时间 认证设置 如果碰到需要认证的网站可以通过 requests.auth 模块实现 123456import requestsfrom requests.auth import HTTPBasicAuthresponse = requests.get(\"http://120.27.34.24:9001/\", auth=HTTPBasicAuth(\"user\",\"123\"))print(response.status_code) 当然这里还有一种方式 1234import requestsresponse = requests.get(\"http://120.27.34.24:9001/\", auth=(\"user\",\"123\"))print(response.status_code) 异常处理 关于 requests 的异常在这里可以看到详细内容： https://docs.python-requests.org/en/latest/api/#exceptions 所有的异常都是在 requests.exceptions 中 从源码我们可以看出 RequestException 继承 IOError, HTTPError，ConnectionError，Timeout 继承 RequestException ProxyError，SSLError 继承 ConnectionError ReadTimeout 继承 Timeout 异常 这里列举了一些常用的异常继承关系，详细的可以看： https://docs.python-requests.org/en/master/_modules/requests/exceptions/#RequestException 通过下面的例子进行简单的演示 1234567891011121314import requestsfrom requests.exceptions import ReadTimeout,ConnectionError,RequestExceptiontry: response = requests.get(\"http://httpbin.org/get\", timeout=0.1) print(response.status_code)except ReadTimeout: print(\"timeout\")except ConnectionError: print(\"connection Error\")except RequestException: print(\"error\") 其实最后测试可以发现，首先被捕捉的异常是 timeout, 当把网络断掉的 haul 就会捕捉到 ConnectionError，如果前面异常都没有捕捉到，最后也可以通过 RequestException 捕捉到 最后 这里只是简单介绍基本操作，高级操作请 look 官方文档。 官方文档 - https://docs.python.org/3/library/urllib.html 官方文档"},{"title":"Python 爬虫从入门到放弃（三）Urllib 库的基本使用","path":"/article/python-spider-3/","text":"什么是 Urllib Urllib 是 python 内置的 HTTP 请求库，包括以下模块 urllib.request - 请求模块 urllib.error - 异常处理模块 urllib.parse - url 解析模块 urllib.robotparser - robots.txt 解析模块 Urllib 基本使用 urlopen 关于 urllib.request.urlopen 参数的介绍： 1urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None) url：url 地址。 data：发送到服务器的其他数据对象，默认为 None。 timeout：设置访问超时时间。 cafile 和 capath：cafile 为 CA 证书， capath 为 CA 证书的路径，使用 HTTPS 需要用到。 cadefault：已经被弃用。 context：ssl.SSLContext 类型，用来指定 SSL 设置。 url 参数的使用 先写一个简单的例子： 1234import urllib.requestresponse = urllib.request.urlopen('https://www.baidu.com')print(response.read().decode('utf-8')) response.read() 可以获取到网页的内容，如果没有 read()，将返回如下内容 &lt;http.client.HTTPResponse object at 0x00000215D37663A0&gt; data 参数的使用 上述的例子是通过 get 请求获得请求内容，下面使用 urllib 的 post 请求 这里通过 http://httpbin.org/post 演示（该网站可以作为练习使用 urllib 的一个站点使用，可以 模拟各种请求操作）。 1234567import urllib.parseimport urllib.requestdata = bytes(urllib.parse.urlencode({'word': 'hello'}), encoding='utf8')print(data)response = urllib.request.urlopen('http://httpbin.org/post', data=data)print(response.read()) 这里就用到 urllib.parse，通过 bytes(urllib.parse.urlencode()) 可以将 post 数据进行转换放到 urllib.request.urlopen 的 data 参数中。这样就完成了一次 post 请求。 所以如果我们添加 data 参数的时候就是以 post 请求方式请求，如果没有 data 参数就是 get 请求方式 timeout 参数的使用 在某些网络情况不好或者服务器端异常的情况会出现请求慢的情况，或者请求异常，所以这个时候我们需要给请求设置一个超时时间，而不是让程序一直在等待结果。例子如下： 1234import urllib.requestresponse = urllib.request.urlopen('http://httpbin.org/get', timeout=1)print(response.read()) 运行之后我们看到可以正常的返回结果，接着我们将 timeout 时间设置为 0.1，运行程序会提示如下错误： 所以我们需要对异常进行抓取，代码更改为 123456789import socketimport urllib.requestimport urllib.errortry: response = urllib.request.urlopen('http://httpbin.org/get', timeout=0.1)except urllib.error.URLError as e: if isinstance(e.reason, socket.timeout): print('TIME OUT') 这样超时时返回以下内容： 响应 响应类型、状态码、响应头 1234import urllib.requestresponse = urllib.request.urlopen('https://www.python.org')print(type(response)) 可以看到结果为： 我们可以通过 response.status、response.getheaders()，获取状态码以及头部信息 response.read() 获得的是响应体的内容 当然上述的 urlopen 只能用于一些简单的请求，因为它无法添加一些 header 信息，如果后面写爬虫我们可以知道，很多情况下我们是需要添加头部信息去访问目标站的，这个时候就用到了 urllib.request request 设置 Headers 有很多网站为了防止程序爬虫爬网站造成网站瘫痪，会需要携带一些 headers 头部信息才能访问，最长见的有 user-agent 参数 写一个简单的例子： 12345import urllib.requestrequest = urllib.request.Request('https://python.org')response = urllib.request.urlopen(request)print(response.read().decode('utf-8')) 给请求添加头部信息，从而定制自己请求网站是时的头部信息 1234567891011121314from urllib import request, parseurl = 'http://httpbin.org/post'headers = { 'User-Agent': 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)', 'Host': 'httpbin.org'}dict = { 'name': 'zhaofan'}data = bytes(parse.urlencode(dict), encoding='utf8')req = request.Request(url=url, data=data, headers=headers, method='POST')response = request.urlopen(req)print(response.read().decode('utf-8')) 添加请求头的第二种方式 1234567891011from urllib import request, parseurl = 'http://httpbin.org/post'dict = { 'name': 'Germey'}data = bytes(parse.urlencode(dict), encoding='utf8')req = request.Request(url=url, data=data, method='POST')req.add_header('User-Agent', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)')response = request.urlopen(req)print(response.read().decode('utf-8')) 这种添加方式有个好处是自己可以定义一个请求头字典，然后循环进行添加 高级用法各种 handler 代理，ProxyHandler 通过 urllib.request.ProxyHandler() 可以设置代理，网站它会检测某一段时间某个 IP 的访问次数，如果访问次数过多，它会禁止你的访问，所以这个时候需要通过设置代理来爬取数据 123456789import urllib.requestproxy_handler = urllib.request.ProxyHandler({ 'http': 'http://127.0.0.1:9743', 'https': 'https://127.0.0.1:9743'})opener = urllib.request.build_opener(proxy_handler)response = opener.open('http://httpbin.org/get')print(response.read()) cookie,HTTPCookiProcessor cookie 中保存中我们常见的登录信息，有时候爬取网站需要携带 cookie 信息访问，这里用到了 http.cookiejar，用于获取 cookie 以及存储 cookie 1234567import http.cookiejar, urllib.requestcookie = http.cookiejar.CookieJar()handler = urllib.request.HTTPCookieProcessor(cookie)opener = urllib.request.build_opener(handler)response = opener.open('http://www.baidu.com')for item in cookie: print(item.name+\"=\"+item.value) 同时 cookie 可以写入到文件中保存，有两种方式 http.cookiejar.MozillaCookieJar 和 http.cookiejar.LWPCookieJar()，当然你自己用哪种方式都可以 具体代码例子如下： 1234567891011121314151617# http.cookiejar.MozillaCookieJar()import http.cookiejar, urllib.requestfilename = \"cookie.txt\"cookie = http.cookiejar.MozillaCookieJar(filename)handler = urllib.request.HTTPCookieProcessor(cookie)opener = urllib.request.build_opener(handler)response = opener.open('http://www.baidu.com')cookie.save(ignore_discard=True, ignore_expires=True)# http.cookiejar.LWPCookieJar()import http.cookiejar, urllib.requestfilename = 'cookie.txt'cookie = http.cookiejar.LWPCookieJar(filename)handler = urllib.request.HTTPCookieProcessor(cookie)opener = urllib.request.build_opener(handler)response = opener.open('http://www.baidu.com')cookie.save(ignore_discard=True, ignore_expires=True) 同样的如果想要通过获取文件中的 cookie 获取的话可以通过 load 方式，当然用哪种方式写入的，就用哪种方式读取。 12345678import http.cookiejar, urllib.requestcookie = http.cookiejar.LWPCookieJar()cookie.load('cookie.txt', ignore_discard=True, ignore_expires=True)handler = urllib.request.HTTPCookieProcessor(cookie)opener = urllib.request.build_opener(handler)response = opener.open('http://www.baidu.com')print(response.read().decode('utf-8')) 异常处理 在很多时候我们通过程序访问页面的时候，有的页面可能会出现错误，类似 404，500 等错误 这个时候就需要我们捕捉异常，下面先写一个简单的例子 123456from urllib import request,errortry: response = request.urlopen(\"http://pythonsite.com/1111.html\")except error.URLError as e: print(e.reason) 上述代码访问的是一个不存在的页面，通过捕捉异常，我们可以打印异常错误 这里我们需要知道的是在 urllb 异常这里有两个异常错误： URLError，HTTPError —— HTTPError 是 URLError 的子类 URLError 里只有一个属性：reason，即抓异常的时候只能打印错误信息，类似上面的例子 HTTPError 里有三个属性：code,reason,headers，即抓异常的时候可以获得 code，reason，headers 三个信息，例子如下： 123456789101112from urllib import request,errortry: response = request.urlopen(\"http://pythonsite.com/1111.html\")except error.HTTPError as e: print(e.reason) print(e.code) print(e.headers)except error.URLError as e: print(e.reason)else: print(\"reqeust successfully\") 同时，e.reason 其实也可以在做深入的判断，例子如下： 12345678910import socketfrom urllib import error,requesttry: response = request.urlopen(\"http://www.pythonsite.com/\",timeout=0.001)except error.URLError as e: print(type(e.reason)) if isinstance(e.reason,socket.timeout): print(\"time out\") URL 解析 urlparse URL 解析函数的重点是将 URL 字符串拆分为其组件，或者将 URL 组件组合为 URL 字符串。 1urllib.parse.urlparse(urlstring, scheme='', allow_fragments=True) 功能一： 1234from urllib.parse import urlparseresult = urlparse(\"http://www.baidu.com/index.html;user?id=5#comment\")print(result) 输出： 这里就是可以对你传入的 url 地址进行拆分 同时我们是可以指定协议类型： result = urlparse(\"www.baidu.com/index.html;user?id=5#comment\",scheme=\"https\") 这样拆分的时候协议类型部分就会是你指定的部分，当然如果你的 url 里面已经带了协议，你再通过 scheme 指定的协议就不会生效 urlunpars 其实功能和 urlparse 的功能相反，它是用于拼接，例子如下： 1234from urllib.parse import urlunparsedata = ['http','www.baidu.com','index.html','user','a=123','commit']print(urlunparse(data)) 输出： urljoin 这个的功能其实是做拼接的，例子如下： 12345678910from urllib.parse import urljoinprint(urljoin('http://www.baidu.com', 'FAQ.html'))print(urljoin('http://www.baidu.com', 'https://pythonsite.com/FAQ.html'))print(urljoin('http://www.baidu.com/about.html', 'https://pythonsite.com/FAQ.html'))print(urljoin('http://www.baidu.com/about.html', 'https://pythonsite.com/FAQ.html?question=2'))print(urljoin('http://www.baidu.com?wd=abc', 'https://pythonsite.com/index.php'))print(urljoin('http://www.baidu.com', '?category=2#comment'))print(urljoin('www.baidu.com', '?category=2#comment'))print(urljoin('www.baidu.com#comment', '?category=2')) 输出： 从拼接的结果我们可以看出，拼接的时候后面的优先级高于前面的 url urlencode 这个方法可以将字典转换为 url 参数，例子如下 12345678910from urllib.parse import urlencodeparams = { \"name\":\"zhaofan\", \"age\":23,}base_url = \"http://www.baidu.com?\"url = base_url+urlencode(params)print(url) 输出： 最后 这里只是简单介绍基本操作，高级操作请 look 官方文档。 官方文档 - https://docs.python.org/3/library/urllib.html"},{"title":"Python 爬虫从入门到放弃（二）爬虫的原理","path":"/article/python-spider-2/","text":"在上文中我们说了：爬虫就是请求网站并提取数据的自动化程序。其中请求，提取，自动化是爬虫的关键！下面我们分析爬虫的基本流程 爬虫的基本流程 发起请求 通过 HTTP 库向目标站点发起请求，也就是发送一个 Request，请求可以包含额外的 header 等信息，等待服务器响应 获取响应内容 如果服务器能正常响应，会得到一个 Response，Response 的内容便是所要获取的页面内容，类型可能是 HTML,Json 字符串，二进制数据（图片或者视频）等类型 解析内容 得到的内容可能是 HTML, 可以用正则表达式，页面解析库进行解析，可能是 Json, 可以直接转换为 Json 对象解析，可能是二进制数据，可以做保存或者进一步的处理 保存数据 保存形式多样，可以存为文本，也可以保存到数据库，或者保存特定格式的文件 什么是 Request,Response 浏览器发送消息给网址所在的服务器，这个过程就叫做 HTPP Request 服务器收到浏览器发送的消息后，能够根据浏览器发送消息的内容，做相应的处理，然后把消息回传给浏览器，这个过程就是 HTTP Response 浏览器收到服务器的 Response 信息后，会对信息进行相应的处理，然后展示 Request 中包含什么？ 请求方式 主要有：GET/POST 两种类型常用，另外还有 HEAD/PUT/DELETE/OPTIONS GET 和 POST 的区别就是：GET 请求的参数是在 url 中，POST 则是存放在头部 GET：向指定的资源发出 “显示” 请求。使用 GET 方法应该只用在读取数据，而不应当被用于产生 “副作用” 的操作中，例如在 Web Application 中。其中一个原因是 GET 可能会被网络蜘蛛等随意访问 POST：向指定资源提交数据，请求服务器进行处理（例如提交表单或者上传文件）。数据被包含在请求本文中。这个请求可能会创建新的资源或修改现有资源，或二者皆有。 HEAD：与 GET 方法一样，都是向服务器发出指定资源的请求。只不过服务器将不传回资源的本文部分。它的好处在于，使用这个方法可以在不必传输全部内容的情况下，就可以获取其中 “关于该资源的信息”（元信息或称元数据）。 PUT：向指定资源位置上传其最新内容。 OPTIONS：这个方法可使服务器传回该资源所支持的所有 HTTP 请求方法。用’*' 来代替资源名称，向 Web 服务器发送 OPTIONS 请求，可以测试服务器功能是否正常运作。 DELETE：请求服务器删除 Request-URI 所标识的资源。 请求 URL URL，即统一资源定位符，也就是我们说的网址，统一资源定位符是对可以从互联网上得到的资源的位置和访问方法的一种简洁的表示，是互联网上标准资源的地址。互联网上的每个文件都有一个唯一的 URL，它包含的信息指出文件的位置以及浏览器应该怎么处理它。 URL 的格式由三个部分组成： 协议 (或称为服务方式)。 存有该资源的主机 IP 地址 (有时也包括端口号)。 主机资源的具体地址，如目录和文件名等。 爬虫爬取数据时必须要有一个目标的 URL 才可以获取数据，因此，它是爬虫获取数据的基本依据。 请求头 包含请求时的头部信息，如 User-Agent,Host,Cookies 等信息，下图是请求请求百度时，所有的请求头部信息参数 请求体 请求是携带的数据，如提交表单数据时候的表单数据（POST） Response 中包含了什么 所有 HTTP 响应的第一行都是状态行，依次是当前 HTTP 版本号，3 位数字组成的状态代码，以及描述状态的短语，彼此由空格分隔。 响应状态 有多种响应状态，如：200 代表成功，301 跳转，404 找不到页面，502 服务器错误 1xx 消息 —— 请求已被服务器接收，继续处理 2xx 成功 —— 请求已成功被服务器接收、理解、并接受 3xx 重定向 —— 需要后续操作才能完成这一请求 4xx 请求错误 —— 请求含有词法错误或者无法被执行 5xx 服务器错误 —— 服务器在处理某个正确请求时发生错误 常见代码： 200 OK 请求成功 400 Bad Request 客户端请求有语法错误，不能被服务器所理解 401 Unauthorized 请求未经授权，这个状态代码必须和 WWW-Authenticate 报头域一起使用 403 Forbidden 服务器收到请求，但是拒绝提供服务 404 Not Found 请求资源不存在，eg：输入了错误的 URL 500 Internal Server Error 服务器发生不可预期的错误 503 Server Unavailable 服务器当前不能处理客户端的请求，一段时间后可能恢复正常 301 目标永久性转移 302 目标暂时性转移 响应头 如内容类型，类型的长度，服务器信息，设置 Cookie，如下图 响应体 最主要的部分，包含请求资源的内容，如网页 HTMl, 图片，二进制数据等 能爬取什么样的数据 网页文本：如 HTML 文档，Json 格式化文本等 图片：获取到的是二进制文件，保存为图片格式 视频：同样是二进制文件 其他：只要请求到的，都可以获取 如何解析数据 直接处理 Json 解析 正则表达式处理 BeautifulSoup 解析处理 PyQuery 解析处理 XPath 解析处理 关于抓取的页面数据和浏览器里看到的不一样的问题 出现这种情况是因为，很多网站中的数据都是通过 js，ajax 动态加载的，所以直接通过 GET 请求获取的页面和浏览器显示的不同。 如何解决 js 渲染的问题？ 分析 ajax Selenium/webdriver Splash PyV8,Ghost.py 怎样保存数据 文本：纯文本，Json，Xml 等 关系型数据库：如 mysql，oracle，sql server 等结构化数据库 非关系型数据库：MongoDB，Redis 等 key-value 形式存储"},{"title":"前端开发必备 javascript 包","path":"/article/frontend-commonly-used-packages/","text":"js 常用工具类 lodash - https://www.lodashjs.com/ 一致性、模块化、高性能的 JavaScript 实用工具库 开源地址 ramda - https://ramda.cn/ 很重要的库，提供了许多有用的方法，每个 JavaScript 程序员都应该掌握这个工具 开源地址 day.js - https://dayjs.gitee.io/zh-CN/ 轻量的处理时间和日期的 JavaScript 库和 Moment.js 的 API 设计保持完全一样，体积只有 2KB 开源地址 big.js - http://mikemcl.github.io/big.js/ 小型，快速的 JavaScript 库，用于任意精度的十进制算术运算 开源地址 qs - https://github.com/ljharb/qs url 参数转化 (parse 和 stringify) 的轻量级 js 库 DOM 库 JQuery - https://jquery.com/ 封装了各种 DOM 事件操作，设计思想值得研究借鉴 中文文档 开源地址 zepto - https://zeptojs.com/ JQuery 的轻量级版本，适合移动端操作 开源地址 fastclick - https://github.com/ftlabs/fastclick 简单易用的库，它消除了移动端浏览器上的物理点击和触发一个 click 事件之间的 300ms 的延迟。目的就是在不干扰你目前的逻辑的同时，让你的应用感觉不到延迟，反应更加灵敏。 文件处理 FileSaver.js - https://github.com/eligrey/FileSaver.js/ 在客户端保存文件的解决方案，非常适合在客户端上生成文件的 Web 应用程序 SheetJS - https://docs.sheetjs.com/ 强大的解析和编写 excel 文件的库 开源地址 网络请求 Axios - https://axios-http.com/zh/docs/intro 基于 Promise 的 HTTP 库，可用在 Node.js 和浏览器上发起 HTTP 请求，支持所有现代浏览器，甚至包括 IE8+ 开源地址 Superagent - https://visionmedia.github.io/superagent/ 基于 Ajax 的优化，可以与 Node.js HTTP 客户端搭配使用 开源地址 flyio - https://wendux.github.io/dist/#/doc/flyio/readme 基于 promise 的 http 请求库，可以用在 node.js, Weex, 微信小程序，浏览器，React Native 中 开源地址 动画库 Anime.js - https://www.animejs.cn/ JavaScript 动画库，可以处理 CSS 属性，单个 CSS 转换，SVG 或任何 DOM 属性以及 JavaScript 对象 开源地址 Velocity - http://velocityjs.org/ 高效的 Javascript 动画引擎，与 jQuery 的 $.animate () 有相同的 API, 同时还支持彩色动画、转换、循环、画架、SVG 支持和滚动等效果 开源地址 Vivus - https://github.com/maxwellito/vivus 零依赖的 JavaScript 动画库，可以让我们用 SVG 制作动画，使其具有被绘制的外观 Kute.js - https://github.com/thednp/kute.js 强大高性能且可扩展的原生 JavaScript 动画引擎，具有跨浏览器动画的基本功能 开源地址 Typed.js - https://github.com/mattboldt/typed.js/ 轻松实现打字效果的 js 插件 开源地址 fullPage.js - https://github.com/alvarotrigo/fullPage.js/ 可轻易创建全屏滚动网站的 js 滚动动画库，兼容性无可替代 开源地址 iscroll - https://iscrolljs.com/ 移动端使用的一款轻量级滚动插件 开源地址 鼠标 / 键盘相关 KeyboardJS - https://github.com/RobertWHurst/KeyboardJS 在浏览器中使用的库（与 node.js 兼容）. 它使开发人员可以轻松设置键绑定和使用组合键来设置复杂的绑定. SortableJS - https://sortablejs.github.io/Sortable/ 功能强大的 JavaScript 拖拽库 开源地址 中文文档 InteractJS - https://interactjs.io/docs/ JavaScript 模块，它为最新的浏览器（包括 IE8 以上版本）增加了拖放、缩放和多点触控手势，并带有惯性和快照功能。这个库的主要目的是替换 jQuery UI 所提供的功能。 因此，使用 InteractJS 来编写的 web 应用在智能手机和平板上会更加易用。 InteractJS 是一个轻量级的库，可以与 SVG 技术协作，处理多点触控输入，而把渲染元素以及设置其样式的任务留给了应用程序。 开源地址 图形 / 图像处理库 html2canvas - http://html2canvas.hertzen.com/ 强大的使用 js 开发的浏览器网页截图工具 开源地址 dom-to-image - https://github.com/tsayen/dom-to-image 可以将任意 DOM 节点转换为用 JavaScript 编写的矢量（SVG）或光栅（PNG 或 JPEG）图像的库 pica - https://github.com/nodeca/pica 在浏览器中调整图像大小，而不会出现像素失真，处理速度非常快的图片处理库 Lena.js - https://github.com/davidsonfellipe/lena.js/ 轻量级的可以给你图像加各种滤镜的 js 库 Compressor.js - https://github.com/fengyuanchen/compressorjs 使用本地 canvas.toBlob API 进行图像有损压缩的 js 库 Fabric.js - http://fabricjs.com/docs/ 易于使用的基于 HTML5 canvas 元素的图片编辑器 开源地址 merge-images - https://github.com/lukechilds/merge-images 将多张图片合并成一张图的 js 插件 cropperjs - https://github.com/fengyuanchen/cropperjs 强大的图片裁切库，支持灵活的图片裁切方式 Grade - https://github.com/benhowdle89/grade 基于图像中的前 2 种主要颜色生成互补渐变背景的库"},{"title":"Python 爬虫从入门到放弃（一）初始爬虫","path":"/article/python-spider-1/","text":"什么是爬虫？ 网络爬虫（又被称为网页蜘蛛，网络机器人，在 FOAF 社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。 其实通俗的讲就是通过程序去获取 web 页面上自己想要的数据，也就是自动抓取数据 爬虫可以做什么？ 你可以爬去妹子的图片，爬取自己想看看的视频。。等等你想要爬取的数据，只要你能通过浏览器访问的数据都可以通过爬虫获取 爬虫的本质是什么？ 模拟浏览器打开网页，获取网页中我们想要的那部分数据 浏览器打开网页的过程： 当你在浏览器中输入地址后，经过 DNS 服务器找到服务器主机，向服务器发送一个请求，服务器经过解析后发送给用户浏览器结果，包括 html,js,css 等文件内容，浏览器解析出来最后呈现给用户在浏览器上看到的结果 所以用户看到的浏览器的结果就是由 HTML 代码构成的，我们爬虫就是为了获取这些内容，通过分析和过滤 html 代码，从中获取我们想要资源（文本，图片，视频…） 所有的努力都值得期许，每一份梦想都应该灌溉！"},{"title":"Python 爬虫常用包","path":"/article/python-crawler-commonly-used-packages/","text":"可用于爬虫的编程语言有不少，但 Python 绝对是其中的主流之一。下面就为大家介绍下 Python 在编写网络爬虫常常用到的一些包。 请求：实现 HTTP 请求操作 urllib - https://docs.python.org/zh-cn/3/library/urllib.html 一系列用于操作 URL 的功能。 requests - https://docs.python-requests.org/zh_CN/latest/ 基于 urllib 编写的，阻塞式 HTTP 请求库，发出一个请求，一直等待服务器响应后，程序才能进行下一步处理。 aiohttp - https://docs.aiohttp.org/en/stable/ 基于 asyncio 实现的 HTTP 框架。异步操作借助于 async/await 关键字，使用异步库进行数据抓取，可以大大提高效率。 httpx - https://www.python-httpx.org/ 全功能 HTTP 客户端，提供同步和异步 API，并支持 HTTP/1.1 和 HTTP/2。 解析：从网页中提取信息 Beautiful Soup - https://www.crummy.com/software/BeautifulSoup/bs4/doc/ html 和 XML 的解析，从网页中提取信息，同时拥有强大的 API 和多样解析方式。 中文文档 pyquery - https://pyquery.readthedocs.io/en/latest/ jQuery 的 Python 实现，能够以 jQuery 的语法来操作解析 HTML 文档，易用性和解析速度都很好。 lxml - https://lxml.de/ 支持 HTML 和 XML 的解析，支持 XPath 解析方式，而且解析效率非常高。 tesserocr - https://tesseract-ocr.github.io/ 在遇到验证码（图形验证码为主）的时候，可直接用 OCR 进行识别。 feedparser - https://pythonhosted.org/feedparser/ 通用 feed 解析器。 Readability - https://readability-python-library.readthedocs.io/en/latest/ 它提供了对 Parser API 和 Reader API 的访问 存储：Python 与数据库交互 PyMysql - https://pymysql.readthedocs.io/en/latest/ 纯 Python 实现的 MySQL 客户端操作包。 PyMongo - https://pymongo.readthedocs.io/en/stable/ MongoDB 官方开发的操作 MongoDB 数据库的包。 redis - https://redis-py.readthedocs.io/en/stable/ 用于连接 redis 数据库的包。 aioredis - https://aioredis.readthedocs.io/en/latest/ 基于 asyncio 为 Redis 提供简单清晰的接口。 框架 Scrapy - https://docs.scrapy.org/en/latest/ 很强大的爬虫框架，可以满足简单的页面爬取（比如可以明确获知 url pattern 的情况）。用这个框架可以轻松爬下来如亚马逊商品信息之类的数据。但是对于稍微复杂一点的页面，如 weibo 的页面信息，这个框架就满足不了需求了。 Portia - https://portia.readthedocs.io/en/latest/index.html 可视化爬取网页内容。 PySpider - http://docs.pyspider.org/en/latest/ 一个强大的爬虫系统。 Ruia - https://www.howie6879.cn/ruia/ 基于 asyncio 和 aiohttp 的异步爬虫框架，目标在于让开发者编写爬虫尽可能地方便快速。 开源地址 Newspaper - https://newspaper.readthedocs.io/en/latest/ 提取新闻、文章以及内容分析。 Grab - https://grab.readthedocs.io/en/latest/ 你可以构建各种复杂的 web 爬虫，从简单的 5 行脚本到复杂的异步网站爬虫处理数百万个网页。 Cola - https://github.com/qinxuye/cola/wiki 一个分布式爬虫框架。项目整体设计有点糟，模块间耦合度较高。 自动化 selenium - https://www.selenium.dev/documentation/ 自动化测试工具。一个调用浏览器的 driver，通过这个库你可以直接调用浏览器完成某些操作，比如输入验证码。 中文文档 MechanicalSoup - https://mechanicalsoup.readthedocs.io/en/stable/ 用于自动和网络站点交互的 Python 库。 Web 框架 Flask - https://flask.palletsprojects.com/en/2.0.x/ 轻量级的 web 服务程序，简单，易用，灵活，主要来做一些 API 服务。做代理时可能会用到。 Django - https://docs.djangoproject.com/zh-hans/3.2/ 一个 web 服务器框架，提供了一个完整的后台管理，引擎、接口等，使用它可做一个完整网站。 FastAPI - https://fastapi.tiangolo.com/zh/ 用于构建 API 的现代、快速（高性能）的 web 框架，使用 Python 3.6+ 并基于标准的 Python 类型提示。 Masonite - https://docs.masoniteproject.com/ 非常适合初学者开发他们的第一个 Web 应用程序。 Tornado - https://www.tornadoweb.org/en/stable/ 通过使用非阻塞网络 I/O，Tornado 可以扩展到数万个打开的连接，使其成为长轮询、WebSockets 和其他需要与每个用户建立长期连接的应用程序的理想选择。 web2py - http://www.web2py.com/books/default/chapter/35 目前功能最全的开源 web 框架之一。 Quixote - http://quixote.ca/ 灵活和高性能的 web 框架。"},{"title":"使用 Docker 搭建 Mastodon","path":"/article/using-docker-to-build-mastodon/","text":"为什么开始使用 Docker 搭建实例 开始使用 Docker 纯属一个手残意外导致的阴差阳错：我不小心在升级时按了 DigitalOcean 面板里的 “关闭服务器” 按钮，相当于跑着程序突然拔了主机电源，导致整个服务器出现大型罢工。最后由兔子帮（代）助（劳）我迁移了站点，方便起见部署在了 Docker 上。于是在此也提醒各位，想要关闭 Mastodon 服务，一定要使用 systemctl stop 具体服务（mastodon-sidekiq、mastodon-web以及mastodon-streaming）的方法，千万不要硬关。 在使用了一段时间的 Docker 之后，我总结出以下 Docker 搭建的优缺点： 优点 搭建、升级方便，命令简单，不用自行配置环境，比起用官方文档命令行搭建而言，更适合新手。 对内存较小的服务器，可以免除每次升级需要的编译（precompile）步骤给小机器带来的负担。 Mastodon 站点运行在一个隔离的小环境（容器）中，安全性较高，不怕新手操作把整个系统搞崩，出现问题之后只要重启即可，会按镜像自动复原。 缺点 可用教程较少，许多命令需要重新学起。 魔改字数等相对而言不太方便，需要增加一个步骤，在之后的博文会详细列出。 需要学习 docker 相关命令。 总体而言，对于一个新手，docker 维护起来相对还是比较方便（皮实耐操）的。大家可以自行决定。但搜索互联网，官方并没有给出 docker 的搭建指南，而民间指南要么过时、要么有冗余步骤会占用大量时间。因此，希望这篇教程能给大家带来一些帮助。 如何在 Docker 上从头搭建 Mastodon 购买域名、购买服务器、配置 SMTP 服务 这三步为建站基础，请大家参考本站最早教程的前 3 步逐一完成。 其中，服务器可在任何一家服务器提供商购买，不必局限于（也不推荐）DigitalOcean。其他如国人常用的 Vultur、Digital Ocean，或者位于德国的 Contabo、Hetzner 等都可以。你可以参考主机测评网站蹲服务器折扣。此外，O3O 站长搭站指南有更详细的指导意见。 购买时选择操作系统为 Ubuntu 或 Debian 即可。本文教程均以此系统为准。 无论你选择哪家服务器，请都不要使用位于国内的服务器，最好不要选择国内的服务器提供商，否则你可能会面临无法与其他站点互联互通、甚至站点下线的风险。 Mastodon 系统较为庞大，如果运行一个单人实例，请保证内存至少在 1G 以上，储存至少在 25G 以上。如果预计用户数量增加，请相应增加服务器配置。 配置系统 配置 ssh-key： 12mkdir -p ~/.sshnano ~/.ssh/authorized_keys 将通过各种方法（如 Xshell、PuTTy 等软件）生成的 ssh-rsa 公钥粘贴入其中。随后通过 ssh-key 密钥方式登录。 为了安全，官方推荐将 ssh 密码登录方式关闭（不影响通过 VNC、DigitalOcean Console 等方式登录，请确保此时你的 SSH 是依靠密钥而不是密码登录，否则你设置完毕后会被踢出去）： 1nano /etc/ssh/sshd_config 找到 PasswordAuthentication 一行，将其前面的 #删掉（取消注释），在后面将 yes 改成 no。 重启 sshd： 1systemctl restart sshd 安装常用命令： 1apt update &amp;&amp; apt install wget rsync python git curl vim git ufw -y 配置 SWAP，具体请参考配置 SWAP 教程。 请让你的内存 + SWAP 至少达到 4G 以上。可以在 root 用户下通过 free -h 查看。 配置防火墙 12sudo ufw allow OpenSSHsudo ufw enable 打开防火墙，随后打开 80 和 443 端口： 12sudo ufw allow httpsudo ufw allow https 然后可以通过 sudo ufw status 检查防火墙状态，你应该会看到 80 和 443 端口的显示。 安装 docker 和 docker-compose 注意：这里第一步使用了官方提供的一键脚本安装 docker。如果你对此感到不放心，请通过官网步骤自行安装，同样也是复制粘贴命令行。 123bash &lt;(curl -L https://get.docker.com/)sudo curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose 拉取 Mastodon 镜像（2022-04-25 修改) 拉取镜像 1234mkdir -p /home/mastodon/mastodoncd /home/mastodon/mastodondocker pull tootsuite/mastodon:latest #如果需要升级到某稳定版本，请将latest改成v3.5.1等版本号。wget https://raw.githubusercontent.com/tootsuite/mastodon/master/docker-compose.yml 修改 docker-compose.yml 配置文件 1nano docker-compose.yml 依次找到 web、streaming、sidekiq 分类，在每一类的 image: tootsuite/mastodon 后添加:latest 或者你刚才拉取的版本号，变成 image: tootsuite/mastodon:latest 或 image: tootsuite/mastodon:v3.5.1 等等。 此外，官方的 docker-compose.yml 文件里写的是 7.17.4，但目前 elasticsearch 的最高版本为 7.10.2，需要修改。 ctrl+X 退出保存。 初始化 PostgreSQL（2022-04-25 修改） （在 v3.5.0 以后，请注意 Postgres 文件夹所在位置有所修改，从原本的 postgres 改为了 postgres14。本教程已更新。） 刚才 docker-compose.yml 文件中，数据库（db）部分的地址为./postgres14:/var/lib/postgresql/data，因此你的数据库绝对地址为 /home/mastodon/mastodon/postgres14。 运行： 1docker run --name postgres14 -v /home/mastodon/mastodon/postgres14:/var/lib/postgresql/data -e POSTGRES_PASSWORD=设置数据库管理员密码 --rm -d postgres:14-alpine 执行完后，检查 /home/mastodon/mastodon/postgres14，应该出现 postgres 相关的多个文件，不是空文件夹。 然后执行： 1docker exec -it postgres14 psql -U postgres 输入： 1CREATE USER mastodon WITH PASSWORD '数据库密码（最好和数据库管理员密码不一样）' CREATEDB; 创建 mastodon 用户。 1\\q 退出数据库。 最后停止 docker： 1docker stop postgres14 附：如果你参考了 2020-12-12 之前的教程，那个教程未对 postgres 设置密码，有一定的安全隐患，请参考本文新增附录看如何设置密码。 配置 Mastodon（2022-11-21 修改) 配置文件 在 /home/mastodon/mastodon 文件夹中创建空白.env.production 文件： 1touch .env.production root 用户内，运行 1docker-compose run --rm web bundle exec rake mastodon:setup 随后会出现下列问题（此处参考此方更新版教程）： Domain name: 你的域名 Single user mode disables registrations and redirects the landing page to your public profile. Do you want to enable single user mode? No Are you using Docker to run Mastodon? Yes PostgreSQL host: mastodon_db_1 PostgreSQL port: 5432 Name of PostgreSQL database: mastodon Name of PostgreSQL user: mastodon Password of PostgreSQL user: （这里写上面你给 mastodon 设置的数据库密码） Database configuration works! 🎆 Redis host: mastodon_redis_1 Redis port: 6379 Redis password: （这里是直接回车，没有密码） Redis configuration works! 🎆 Do you want to store uploaded files on the cloud? 这个我们先填 No，未来再参考上云教程配置。 Do you want to send e-mails from localhost? No，然后根据刚才配置的邮件服务填写（下文为举例）。 SMTP server: smtp.zoho.eu SMTP port: 587 SMTP username: 你的 zoho 管理员邮箱地址 SMTP password: 你的 zoho 管理员密码 SMTP authentication: plain SMTP OpenSSL verify mode: none E-mail address to send e-mails “from”: 你的 zoho 管理员邮箱地址 Send a test e-mail with this configuration right now? no This configuration will be written to .env.production Save configuration? Yes Below is your configuration, save it to an .env.production file outside Docker: 然后会出现.env.production 配置，请务必复制下来，先存到电脑里，等会儿要用。 之后会要你建立数据库和编译，都选是。 更新：在 4.0.2 版本，因为一些 bug，请先不要建立管理员帐号，稍后再使用 tootctl 工具建立！ 一切成功之后，记得立刻马上： 1nano .env.production 把你刚才复制下来的配置保存进去。 更新：在 4.0.2 版本，需要在.env.production 中增加一行： 1REDIS_URL=redis://@mastodon_redis_1:6379 启动 Mastodon 12docker-compose downdocker-compose up -d 为相应文件夹赋权 1234chown 991:991 -R ./publicchown -R 70:70 ./postgres14docker-compose downdocker-compose up -d 安装并配置 nginx（2022-11-21 修改） 在这一步之前，请记得到您购买域名的网站（如 NameCheap），在 DNS 设置中添加一个 A Record，Host 填写 @（如果没有子域名需求），Value 填写你服务器的 IP 地址，将你设定的域名指向你的服务器。 请注意：此时你的 DNS Setting 里除了你刚才在邮箱配置和本步骤中亲自设置的内容之外，别的任何由域名商自动生成的内容请都删光。 安装 nginx 1sudo apt install nginx -y 配置 nginx 1nano /etc/nginx/sites-available/你的域名 网页打开 nginx 模板，将其中的 example.com 替换成自己域名，将 20 和 43 行的 /home/mastodon/live/public 改成 /home/mastodon/mastodon/public，** 更新：** 并将 try_files $uri =404; 修改为 try_files $uri @proxy;，复制到服务器中保存。 随后配置镜像文件 1ln -s /etc/nginx/sites-available/你的域名 /etc/nginx/sites-enabled/ nginx -t 检查，无误后重启（如果提示 ssl 证书问题，请在 listen 443 ssl http2;、listen [::]:443 ssl http2; 等包含 ssl 的行前加 #号先行注释掉，配置完 ssl 证书后再改回来）： 1systemctl reload nginx 配置 SSL 证书 12345apt install snapdsudo snap install core; sudo snap refresh coresudo snap install --classic certbotsudo ln -s /snap/bin/certbot /usr/bin/certbotsudo certbot certonly --nginx -d 你的域名 重启 nginx 重新打开 nginx 配置文件，将 ssl_certificate 和 ssl_certificate_key 两行前的 #号（以及你刚才添加的 #号）删除。 nginx -t 检查是否有错误。 如果没有错误，则可重启 nginx： 1systemctl reload nginx 检查证书更新 最后，可通过 1certbot renew --dry-run 检查证书是否能自动更新。 如果不放心，可以再至 /home/mastodon/mastodon 文件夹，运行 docker-compose up -d 重启 mastodon。静静等待几分钟后，点开你的域名，你的站点就上线啦！ 更新：此时可通过 tootctl 工具建立管理员帐户 1docker exec mastodon_web_1 tootctl accounts create USERNAME --email EMAIL --confirmed --role Owner 站点上线之后 在站点上线之后，你可以： 开启全文搜索 Docker 的全文搜索开启十分方便，只需要： 12cd /home/mastodon/mastodonnano docker-compose.yml 编辑 docker-compose.yml，去掉 es 部分前所有的 #号，并且去掉 web 部分中 es 前面的 #号。 nano .env.production 编辑.env.production 文件，加上 123ES_ENABLED=trueES_HOST=esES_PORT=9200 三行，重启： 12docker-compose downdocker-compose up -d 待文件夹中出现 elasticsearch 文件夹后，赋权： 1chown 1000:1000 -R elasticsearch 再次重启： 12docker-compose downdocker-compose up -d 全文搜索即搭建完成。 然后 1docker-compose run --rm web bin/tootctl search deploy 建立之前嘟文的搜索索引即可。 修改配置文件 如果在之后需要再对.env.production 配置进行修改，只需： 12cd /home/mastodon/mastodonnano .env.production 进行相应修改，然后 12docker-compose downdocker-compose up -d 重启即可。 使用管理命令行 在 docker 中使用 tootctl 管理命令行的方式有三种： 进入 docker 系统后操作 docker ps 查看你的容器名字，如果你按照刚才设置，那你的容器名字一般为 mastodon_web_1。 12cd /home/mastodon/mastodondocker exec -it mastodon_web_1 /bin/bash #或者将“mastodon_web_1”替换为你的容器名。 进入 docker 系统 mastodon 用户，然后在其中进行相应的 tootctl 操作。 注：如果需要进入 docker 系统的 root 用户进行一些软件安装，则需输入 docker exec --user root -it mastodon_web_1 /bin/bash。 在 /home/mastodon/mastodon 文件夹操作 首先进入 /home/mastodon/mastodon，然后 1docker-compose run --rm web bin/tootctl 具体命令 进行操作。 在任意位置操作 在任意位置： 1docker exec mastodon_web_1 tootctl 具体命令 需要注意的是，这则具体命令需要包括所有必须的参数，并且如果命令本身会要求你进行后续输入，则无法完成（比如 self-distruct 命令无法通过该步骤完成。） 使用脚本简化命令 可参考这篇文章： 12cd /home/mastodon/mastodonnano tootctl.sh 编辑脚本内容为： 123456789101112131415161718192021222324252627282930#!/bin/bashlpwd=$PWDmypath=`dirname $0`cd $mypathif [ $# -ge 1 ]then case $1 in \"restart\" docker-compose restart ;; \"reload\") docker-compose down &amp;&amp; docker-compose up -d ;; \"stop\") docker-compose down ;; \"start\") docker-compose up -d ;; \"psql\") docker-compose exec db $* ;; *) docker-compose run --rm web bin/tootctl $* ;; esacelse echo \"please use tootctl help for help\"ficd $lpwd 随后执行： 123chmod +x /home/mastodon/mastodon/tootctl.shecho \"alias tootctl='/home/mastodon/mastodon/tootctl.sh' \" &gt;&gt; ~/.bashrc source ~/.bashrc 之后 tootctl 相关命令均可在进入 /home/mastodon/mastodon/ 后缩写为 tootctl xxx，且数据库相关命令也可通过 tootctl psql 进入。 定时清理媒体文件 1crontab -e 选择编辑器为 nano 或者你习惯的编辑器，随后输入： 12320 03 * * 1 docker exec mastodon_web_1 tootctl media remove-orphans20 04 * * 2 docker exec mastodon_web_1 tootctl media remove --days=720 05 * * 3 docker exec mastodon_web_1 tootctl preview_cards remove 具体清理时间可以自己设置（参考 Crontab 教程，上述表示在服务器时间周一 / 二 / 三相应时间执行媒体清理命令。 升级 如果你要升级到最新版本，只需要： 12cd /home/mastodon/mastodondocker pull tootsuite/mastodon:latest #或者将latest改成版本号如v3.2.1 如果你升级的是特定版本，则需要编辑 docker-compose.yml，将 web、streaming、sidekiq 三部分的版本号改成相应版本。如果是 latest 则无需改动。 然后 1docker-compose up -d 启动。 如果官方升级提示中包括其他步骤如 docker-compose run --rm web rails db:migrate，则可在启动后进行。 在确认升级没问题之后，运行 1docker system prune -a 清除旧的 docker 镜像文件。 如果在操作过程中出现了任何问题…… 如果没有对站点进行过魔改，只要在 docker 系统外，通过 12docker-compose downdocker-compose up -d 让系统通过 docker 镜像重新搭建容器即可。 利用 Scaleway 备份数据库 本步脚本由兔子写就，感谢 ta！ 首先，请注册 Scaleway，申请 token，创建 Bucket，此三步可参考 Scaleway 上云教程。 注意：下文提到的备份脚本会自动删除 7 天以前的文件，因此 ** 请为备份数据库单独建立一个 bucket，** 不要和媒体文件使用同一个 bucket！ 在服务器中安装 rclone 和 zip： 12curl https://rclone.org/install.sh | sudo bashapt install zip -y 创建 rclone 配置文件夹 1mkdir -p ~/.config/rclone/ 新建配置文件： 1nano ~/.config/rclone/rclone.conf 填入下列内容： 12345678[scaleway]type = s3provider = Scalewayaccess_key_id = 你的ACCESS KEYsecret_access_key = 你的SECRET KEYregion = nl-ams（根据你bucket选择的地区，法国fr-par，荷兰nl-ams，波兰pl-waw）endpoint = s3.nl-ams.scw.cloud （同上）acl = private 保存。 然后创建脚本 1nano /backup.sh 输入 12345678910111213#!/bin/bashsource /etc/profilenow=$(date \"+%Y%m%d-%H%M%S\")origin=\"/home/mastodon/mastodon\"target=\"scaleway:你的bucket名字\"echo `date +\"%Y-%m-%d %H:%M:%S\"` \" now starting export\"/usr/bin/docker exec pg容器名 pg_dump -U postgres -Fc mastodon_production &gt; ${origin}/backup.dump &amp;&amp;echo `date +\"%Y-%m-%d %H:%M:%S\"` \" succeed and upload to s3 now\"/usr/bin/zip -P 密码 ${origin}/backup_${now}.zip ${origin}/backup.dump &amp;&amp;/usr/bin/rclone copy ${origin}/backup_${now}.zip ${target} &amp;&amp;echo `date +\"%Y-%m-%d %H:%M:%S\"` \" ok all done\"rm -f ${origin}/backup.dump ${origin}/backup_${now}.zip/usr/bin/rclone --min-age 7d delete ${target} pg 容器名一般为 mastodon_db_1（通过 docker ps 查看），密码为你设立的解压密码。mastodon_production 为你的数据库名，可至.env.production 查看。 保存。 赋权： 1chmod 751 /backup.sh 然后， 1/backup.sh 试运行一下，看看 Scaleway 中有没有 zip 文件生成。如果出现 zip 文件且大小以 mb 计算，则成功。 之后如果想通过备份文件恢复，则可参考迁移教程。 随后，设置定时任务： 1crontab -e 选择 nano 编辑器， 13 22 * * * /backup.sh &gt;&gt; /backup.log 具体时间自己设置，建议设置在半夜，注意服务器时区（通过 date 查看服务器时间）。 利用 Cloudflare 提升网站速度 请注意，Cloudflare 目前在大陆也时常被阻拦，未必能起到加速作用。是否能提高速度，需要根据服务器本身的在大陆的连接速度判断。 步骤如下： 到 Cloudflare 官网注册账号，选择 Add Website 输入你自己的域名，Cloudflare 会自动读取你的 DNS 记录并且要求你修改域名服务器（NameServer）。如果你是 NameCheap 上购买的域名，则点开你的域名，在 Domain 那一栏下面选择 Custom DNS，填入 Cloudflare 提供的两个 NameServer，静静等待生效即可。如果是其他地方购买的域名，Cloudflare 也提供了相应教程，通常非常简单就能完成。 生效之后会有邮件通知，这时打开 Cloudflare，进入你的域名。 点开 “速度 / Speed - 优化”，下图 Auto Minify 的三个勾勾请勿选上。 注意（2020-12-01 更新）：Auto Minify 在 3.3.0 版本之后会影响网页打开，请勿勾选！ 同时请注意，Rocket Loader™这个开关，请务必确保它关闭，否则你的 Mastodon 会变成白屏。 打开 SSL 设置，将模式改成 Full / 完全： 现在请打开测试，您的网站速度有没有变快？每个人每个地区情况可能不同，对我而言确实有肉眼可见的速度提升，对于各位可能需要测试。如果速度反而变慢，可以直接在 Cloudflare 的 DNS 设定中将橘色的云朵按灰，即可取消代理。 更详细的设置可以参见 O3O 搭站指南。 附：如何修改数据库密码（2022-04-25 更新） 如果在 2020-12-12 前参考本教程，当时本教程未要求大家设置数据库密码，这样做有一定的安全风险。因此，如果你已经建站完毕且未设置数据库密码，请参考本段添加数据库密码。 关闭 mastodon 服务： 1docker-compose down nano docker-compose.yml 修改，将之前教程要求你设置的 12environment: - POSTGRES_HOST_AUTH_METHOD=trust 删掉，保存。 nano .env.production 修改，添加 1DB_PASS=数据库密码 保存。 启动数据库并进入 psql 模式： 12docker run --name postgres14 -v /home/mastodon/mastodon/postgres14:/var/lib/postgresql/data --rm -d postgres:14-alpinedocker exec -it postgres14 psql -U postgres 填入： 123alter user mastodon with password '数据库密码';alter user postgres with password '数据库管理员密码（两者最好不要相同）';\\q 停止数据库运行并启动 mastodon： 12docker stop postgres14docker-compose up -d 数据库管理员密码和数据库密码即添加完毕。 总结 以上就是从头通过 Docker 搭建 Mastodon 的方法，通过单纯复制粘贴很快就能搭建出来。在升级过程中也能免去编译过程对小机器造成的负担。（当然，SWAP 还是要开的！）如果使用官方分支，升级只要几分钟。 目前网络上一些其他的 docker 搭建指南都提到需要 docker-compose build 这一步骤，并无必要，且耗时长、对服务器压力大。 然后有朋友就要问了：我之前是按照 DigitalOcean 一键镜像搭建的 / 用官方文档命令行搭建的，怎么迁移到 docker 上去呢？如果我想对代码进行一点改动要怎么做呢？这些问题，我们将在后续的文章中谈到。"},{"title":"使用 Charles 抓 Android 11 的包 ssl 证书问题","path":"/article/android-11-charles-capture-packet-ssl-certificate/","text":"Android 7 以后，Android 不信任用户安装的证书，所以抓 https 时无法解码请求，对于第三方应用，需要将证书添加为系统证书，网上解决方法较多，比如使用安卓模拟器（兼容性差，很多应用闪退），使用 xposed 框架等，这里使用 Android 手机添加证书。 ps: 需要手机有 root 权限，以下操作以 Redmi 为准，其他品牌手机操作可能有差别。 导出证书（以 Charles 为例） help --&gt; SSL Proxying --&gt; Save Charles Root Certificate… Android 证书存储格式 证书路径 /system/etc/security/cacerts 文件命名格式（如果计算出来的 hash 值已经存在则编号依次 + 1）：&lt;hash&gt;.%d 将导出的证书计算 hash 值 需要安装 openssl 根据导出格式 2 选 1 .cer 格式证书 1openssl x509 -inform DER -subject_hash_old -in filename.cer .pem 格式证书 1openssl x509 -inform PEM -subject_hash_old -in filename.pem"},{"title":"MySQL8 全平台安装教程","path":"/article/mysql-install/","text":"MacOS 安装 MySQL8 MacOS 安装 MySQL 的方法主要分为两种。分别是： 官网下载安装 首先登陆 mysql 官网，下载 dmg 安装包，也就是图片中的第一个。 点最下面的 No thanks 即可。 下载好了之后，长这样。双击打开。 再次双击进行安装 2. 下载完成后，点安装，一路点 “继续”，直到 这里选择第二个。 初步安装成功，这里自己设置的密码要记住，以后连数据库都要用。 3. 如何配置 进入系统偏好，打开 mysql 看一下是不是打开的，一般安装默认安装好了就打开的。 是绿色的就代表是开启状态，这个启动选项可以不选。 4. 打开终端 输入：cd /usr/local/mysql，回车执行 然后输入：sudo vim .bash_profile，回车执行 需要输入 root 用户密码。sudo 是使用 root 用户修改环境变量文件。 进入编辑器后，我们先按”i”，即切换到 “插入” 状态。就可以通过上下左右移动光标，或空格、退格及回车等进行编辑内容了，和 WINDOWS 是一样的了。 在文档的最下方输入：export PATH=${PATH}:/usr/local/mysql/bin 然后按 Esc 退出 insert 状态，并在最下方输入:wq 保存退出 (或直接按 shift+zz，或者切换到大写模式按 ZZ，就可以保存退出了)。 输入：source .bash_profile 回车执行，运行环境变量。 再输入 mysql 命令 mysql -u root -p，即可使用。 5. 以后每次使用的话，打开终端输入 /usr/local/mysql/bin/mysql -u root -p 即可使用。 使用 Homebrew 安装 MySQL Homebrew 安装 macOS 下的 Homebrew 就相当于 CentOS 下的 yum 或者是 Ubuntu 下的 apt-get 1/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Homebrew 安装与启动 MySQL 服务 安装 mysql 1brew install mysql 配置并启动 MySQL 服务 12brew tap homebrew/servicesbrew services start mysql 修改 root 密码 1mysqladmin -u root password&nbsp;'yourpassword' MySQL 安装测试 查看 MySQL 版本 12345#查看MySQL版本mysql -V#输出示例mysql Ver 8.0.19 for osx10.15 on x86_64 (Homebrew) MySQL shell 测试 12345678910111213#进入MySQL shellmysql -u root -p#成功进入会输出以下信息# Welcome to the MySQL monitor. Commands end with ; or \\\\g.# Your MySQL connection id is 12# Server version: 8.0.12 Homebrew#查看数据库mysql&gt; show databases;#退出mysql&gt; exit;"},{"title":"最佳 UX 资源","path":"/article/best-ux-resources/","text":"你想进入 UX 的世界，但不知道从哪里开始？ 你想再次学习基础知识并参加在线课程吗？ 你想改进用户体验，但不知道如何改进？ 你是否已经有一些经验，但需要一些灵感？ 如果你对这些问题中的任何一个回答是，那么你来对地方了！ 阅读本文。你会在其中找到各种资源 —— 知名 UX 网站、UX 项目、公司博客和在线课程。 你最喜欢哪一个？告诉我！ 网站和博客推荐 无论你在团队中扮演什么角色 —— 研究员、设计师、产品经理或开发人员。 借助这些资源，你和你的产品可以更上一层楼。我选择了有关 UX 的顶级网站和博客。 Usability.gov – https://www.usability.gov/ Usability.gov 是用户体验 (UX) 最佳实践与指南，为政府和私营部门的从业者和学生提供服务。 Laws of UX – https://lawsofux.com/ Laws of UX 是设计师在构建用户界面时可以考虑的准则和原则的集合。创建它的是 https://jonyablonski.com/ The UX Collective – https://uxdesign.cc/ UX Collective 是一个平台，旨在提升全世界闻所未闻的设计声音。 关于 UX、视觉和产品设计的策划故事。 Usability Geek – https://usabilitygeek.com/ Usability Geek 是一个博客，提供对可用性、用户体验 (UX)、人机交互 (HCI)、信息架构 (IA) 和相关领域等主题的实用和有用的见解。 A List Apart – https://alistapart.com/ A List Apart 探索了 设计、Web 内容的意义、开发，特别关注 Web 标准和最佳实践。 CustomerThink – https://customerthink.com/ CustomerThink 是一个全球商业领导在线社区，致力于创建以客户为中心的盈利企业。 Smashing Magazine – https://www.smashingmagazine.com/category/user-experience Smashing Magazine 是一个网站，你可以在这里找到最佳技巧，不仅可以让你的 UX 设计过程，还可以让你的体验更上一层楼。一个有意义的经历，持续。这不是我们所有人都想要达到的目标吗？ UX magazine – https://uxmag.com/ UX Magazine 是一个免费的资源社区，探索体验设计的方方面面。他们与精通 UX 各个领域的从业者和行业领导者密切合作，以提供源源不断的引人入胜且有用的内容。 UXmatters – https://www.uxmatters.com/ UXmatters 为在 UX 的各个方面工作经验丰富的专业人士以及那些刚刚开始在该领域发展的人提供见解和灵感。 UX Movement – https://uxmovement.com/ UX Movement 是一份独立出版物，教你如何通过创新的技巧、技术和最佳实践来设计直观的 UX。 UX Myths – https://uxmyths.com/ UX Myths 收集了最常见的 UX 误解，并解释了为什么它们不成立。他们将通过设计和可用性专家向你展示许多研究结果和文章。 UX planet – https://uxplanet.org/ UX Planet 是与 UX 相关的所有内容的一站式资源。为具有 UX 基础知识的初学者提供有用的部分。 The UX Blog – https://theuxblog.com/ The UX Blog 是 UX 设计、用户研究和 UX 策略的资源。他们与来自广泛学科的用户体验从业者和思想领袖合作，为他们的听众提供具有洞察力和可操作性的建议，这些建议在工作场所具有实际应用。 UX Project Checklist – https://uxchecklist.github.io/ UX Project Checklist 是一个简单的工具，它可以让你记住你在正在进行的组织中处理项目时从 UX 的角度考虑的事项。 NNgroup – https://www.nngroup.com/ NNgroup（Nielsen Norman Group）是基于研究 UX 领域的全球领导者。他们分享他们的研究成果，以帮助设计师和团队改善 UX。他们是传奇人物，也是他们的创始人之一 —— Don Norman 创造了 User Experience 一词。 工具 没有强大的工具集，你就不可能成为一名优秀的 UX 专家。如果你不完全是一个初学者，那么你肯定正在使用下面提到的工具之一。 如果你没有关注他们的博客，我建议你关注他们，因为他们发布的内容质量很高。 经过一番探索，你一定会提高自己的技能并找到灵感。 Adobe – https://blog.adobe.com/en/topics/illustrator.html Figma – https://www.figma.com/blog/ Sketch – https://www.sketch.com/blog/ InVision – https://www.invisionapp.com/inside-design/ UXpin – https://www.uxpin.com/studio/blog/ Axure – https://www.axure.com/blog 在线课程 如今，在线课程比以往任何时候都发展迅速。它们是现在参加 UX 课程的唯一途径。 这种类型的教育可能并不适合所有人，但我们向您保证它们值得一试。 以下是您可能感兴趣的建议： Hack Design – https://hackdesign.org/ Coursera: Introduction to User Interface Design – https://www.coursera.org/learn/ui-design Udemy: Adobe XD Professional Course – https://www.udemy.com/courses/search/?q=ux&amp;sort=highest-rated&amp;src=ukw UX Training – https://www.uxtraining.com/ux-design-course-online 如果你觉得还有我没提到的，请告诉我！"},{"title":"Windows 使用 Laragon 快速搭建开发环境","path":"/article/laragon/","text":"简介 自动创建虚拟主机（Virtual Host，Valet 也有这样的功能） 邮件接收和发送 非常方便地切换环境的版本 轻松创建框架应用，如 Laravel、Symfony、WordPress、Joomla 等 基于自己的需求为不同的环境设置不同的配置 所以，从今天起，可以抛弃那些传统的集成开发环境了，Windows 上也可以搭建优雅的开发环境！ 官网 - https://laragon.org/ 安装 GitHub - https://github.com/leokhoa/laragon/releases 咱们在 GitHub 下载便携版，也就是后缀带 portable 的 zip 文件 解压后目录结构如下 双击打开 laragon.exe 后界面如下 点击右上角齿轮按钮，将 General-&gt;language 修改成 ChineseSimplified 可以将界面设置成中文。也可以对系统进行设置。 要启动 Apache、MySQL 服务，需要点击启动所有按钮： 这样点击网站即可打开浏览器访问默认站点 http://localhost： 要访问数据库，可以点击数据库按钮： 默认数据库是 Laragon，用户名是 root，密码是空字符串，点击打开按钮，就可以访问这个默认的数据库： 当然你也可以使用其他自己喜欢的数据库客户端连接到这个数据库进行操作。 点击 Laragon 界面的终端按钮可以进入到一个类 Unix 的终端工具 Cmder 进行命令行操作： 最后，Laragon 界面还有一个根目录按钮，点击之后即可进入文档根目录，我的 Laragon 放在 F 盘下，所以对应的文档根目录是 {LARAGON_ROOT}\\www。 切换环境版本 你可以通过点击 Laragon 界面上的菜单来切换不同软件的版本： 现在默认安装的 Laragon 每个软件都只有一个版本。 下面列出常用环境的官方下载地址 Apache - http://httpd.apache.org/docs/current/platform/windows.html Nginx - http://nginx.org/en/download.html PHP - https://windows.php.net/download MySQL - https://dev.mysql.com/downloads/mysql/ Composer - https://getcomposer.org/download/ MariaDB - https://mariadb.org/download/ phpMyAdmin - https://www.phpmyadmin.net/downloads/ Node.js - https://nodejs.org/zh-cn/download/ MongoDB - https://www.mongodb.com/download-center/community Python - https://www.python.org/downloads/windows/ PostgreSQL - https://www.enterprisedb.com/downloads/postgres-postgresql-downloads Go - https://golang.org/dl/ java - https://www.oracle.com/cn/java/technologies/javase-downloads.html 以 PHP 为例如果想要支持多个版本的切换和测试，需要去下载不同版本（需要下载 Non Thread Safe 版本），然后将下载后的文件解压到 {LARAGON_ROOT}\\bin\\php 目录下： 这样就可以进行版本切换了： 切换 MySQL 和 Apache 的版本也是类似，这里不再赘述，一般这种场景也不多。 注意事项 如果提示端口已被占用，可以修改端口，可以参考下图示例 如果提示 dll 文件缺失，下载运行库安装重启即可。 三方下载地址 - http://dreamcast2.ys168.com/ 更多功能 Laragon 还有更多功能等着你去挖掘，比如也支持基于 Ngrok 进行站点分享，支持 Node、Putty、Yarn、文件传输等等，欢迎你在使用的过程中与我分享。"},{"title":"windows10 垃圾清理","path":"/article/windows-garbage-cleaning/","text":"优化软件很多，比如 TuneUp Utilities, 比如 Advanced SystemCare, 比如 Glary Utilities 。这些软件让你的系统垃圾被清理的很干净，很受小白们欢迎。 然而，作为一个喜欢倒腾电脑的玩家，或许最开始沉醉于这些乱七八糟的优化软件，但是慢慢地，发现有时候他们会删除掉不想删的文件，让系统变得不稳定，有类似经验的童鞋举手！ 所以，我更趋向于让一切在自己的控制之下，手动清理系统垃圾。下面就是我装系统后的一系列操作，我不仅会告诉你如何操作，还会告诉你为什么这样操作： 真正地关闭休眠 休眠文件 hiberfil.sys 是 XP 时代（或者更早）的产物，一直沿用至今，就是当系统暂时不用的时候，让它休眠，然后等用的时候可以快速唤醒。 但是，等到 Vista 时代，有了睡眠模式，虽然休眠和睡眠两个在运行机理上不同，但是对于用户来说功能基本是重复的，并且睡眠是不太占用系统资源的，而休眠文件 hiberfil.sys 往往至少要占 1GB 磁盘空间。所以很多用户就希望关掉它。 然而，想找到真正的关掉休眠的方法并不容易，直接删除休眠文件 hiberfil.sys 并没有效果，系统自带的磁盘清理也往往无法真正关掉它。那么究竟如何才能彻底关掉休眠功能，让休眠文件 hiberfil.sys 彻底消失呢？ 这需要用到命令行，在你的开始菜单里，找到命令提示符，然后右键点击，以管理员身份运行（另一种方法是用 Win+R 打开运行，然后里面输入 cmd）： 然后在里面输入 powercfg -h off (如图)，回车，然后休眠就被关掉了，休眠文件 hiberfil.sys 就被彻底干掉了。 当然，这个时候 C 盘空间并未看到减少，不要急，等清理磁盘后就干净了，具体操作后面会讲到。不过可以肯定的是，这一步已经彻底关掉了休眠功能。 关闭虚拟内存 一般来说，博主这样干是为了备份系统盘的时候可以体积小一点。以 4GB 内存的电脑来讲，虚拟内存（分页文件）一般默认大概 3-4GB，备份 C 盘你不会想让它们占你移动硬盘的空间吧？建议备份 C 盘时只保留 400MB，然后备份完系统后再恢复到 4096MB（对于 4GB 内存来说，8GB 用 4096MB 也没问题，2GB 建议用 2096MB），这些原因后面讲。操作方式如下： 右键点击 “此电脑”，选择 “属性” 接下来的页面按照图示走，高级系统设置&gt;性能-设置&gt;高级&gt;更改&gt;自定义大小为 400MB，然后点击” 设置”，再点击 “确定”，等你看到 “要使改动生效，需要重新启动计算机”，那就说明你设置成功了，如果看不到这一句，说明你没按步骤走，一般是没有点击最后那个 “确定”。 好了，到这里就设置成功了，这里再来解释一下为什么要设置成 400MB，原因是，如果你选择了” 无分页文件 “，虚拟内存成了 0，等到系统报错的时候文件无法转储，那个时候你会面对烦恼的弹出框，设置成 400MB 可以避免这一问题。 为什么不让系统自动管理分页文件大小呢？因为它会一会儿大一会儿小，分页文件可能会被其他文件隔离成碎片，而设置成固定大小的话（即初始大小和最大值设置成一个），分页文件会老老实实呆在磁盘的同一个地方，不会变动大小和位置。 为什么备份好系统后建议恢复到 4096MB，因为 400MB 的话有时候你程序运行多了会出现内存不够的提示，即便 8GB 内存有时候也会碰到这种情况，所以一般设置成 4096MB 足够用了（如果你是 2GB 内存，设置为 2096MB 好了）。 安全删除系统更新文件 系统会越来越臃肿，这是无可置疑的，C 盘的臃肿很大一部分来自于系统更新后的安装文件，也就是说，更新安装成功之后，那些更新文件安装包是可以删除而不对系统造成负面影响的，那么这些文件在哪里呢？ 它们在 C:\\Windows\\SoftwareDistribution\\Download，这个文件夹下的所有文件都是系统更新时下载下来的，等你系统更新完毕之后全部删除即可，遇到提示需要管理员权限才能删除时点击 “继续”，直到清理干净。 这样清理安全吗？不要怀疑，博主这样干好几年了。 删除 C 盘根目录下多余文件夹，只保留下面 5 个（其中 ProgramData 是隐藏文件夹）就可以 关闭系统备份还原 还是右键此电脑，选择属性。 接下来的页面按照图示走，高级系统设置&gt;系统保护&gt;配置&gt;禁用系统保护&gt;确定。 最后，让我们来彻底清空一下上面清理出来的垃圾吧 首先清空回收站，这个大家都会。 再说一个多数人都不会的。调用 “运行”（快捷键 Win+R） ，先输入 cleanmgr /sageset:99，在里面选择所有的项目。然后再次运行，输入 cleanmgr /SAGERUN:99，这样，之前清理出来的垃圾就彻底光光了。 结果 世界清静了！让我们看看删除垃圾以前和以后的 C 盘变化吧，从 102GB 可用，到 112GB 可用，整整腾出来 10GB 空间。"},{"title":"建站程序推荐","path":"/article/best-build-website-tool/","text":"动态网站 WordPress - https://cn.wordpress.org/ WordPress 是一种使用 PHP 语言开发的博客平台，用户可以在支持 PHP 和 MySQL 数据库的服务器上架设属于自己的网站。WordPress 的特点便是开源、简单、易用。而且有很多主题，即时小白用户也能很快上手。 Typecho - https://typecho.org/ Typecho 是一个由中国团队开发的开源跨平台博客程序。它基于 PHP5 构建，并支持多种操作系统 (Linux,Unix,BSD,Windows)、 服务器 (Apache,Lighttpd,IIS,Nginx) 和数据库 (Mysql,PostgreSQL,SQLite)。 Dedecms - http://www.dedecms.com/ 织梦 CMS 是集简单、健壮、灵活、开源几大特点的开源内容管理系统，是国内开源 CMS 的品牌，目前程序安装量已达七十万。 PageAdmin - http://www.pageadmin.net/ PageAdmin 是基于.Net 的网站内容管理系统，安全、稳定、灵活，为企业、学校、政府提供企业级的内容管理解决方案。 YZNCMS - https://gitee.com/ken678/YZNCMS YznCMS (又名御宅男 CMS) 是基于最新 TP5.1x 框架和 layui2.6.x 的后台管理系统。创立于 2017 年初，是一款永久免费可商用的开源项目，他将是您轻松建站的首选利器。框架易于功能扩展，代码维护，方便二次开发，帮助开发者简单高效降低二次开发成本，满足专注业务深度开发的需求。 SiteFactory - https://www.powereasy.net/ SiteFactory 是业界基于微软.NET2.0 平台，采用 ASP.NET 2.0 进行分层开发的内容管理系统。具有灵活的产品架构、严密的安全性、无限的扩展性和伸缩性，能够高效构建起各种信息资讯类网站、企业网站、门户网站等多种网站应用型平台。 Joomla - https://www.joomla.org/ Joomla 是一套获得过多个奖项的内容管理系统 (Content Management System, CMS)。Joomla! 采用 PHP+MySQL 数据库开发，可运行。在 Linux、Windows、MacOSX、Solaris 等各种平台上。 Drupal - https://www.drupal.org/home Drupal 是一个开源的内容管理系统 (CMS) 平台，它是用 PHP 写成的。主要用于构造提供多种功能和服务的动态网站，这些功能包括用户管理 (UserAdministration)、发布工作流 (Publishing Workflow)、讨论、新闻聚合 (NewsAggregation)、元数据 (Metadata) 操作。 静态网站 Hexo - https://hexo.io/zh-cn/ Hexo 最初由 Tommy Chen 于 2012 年创建和维护。从那时起，它已经帮助成千上万的人建立了他们梦想中的网站 / 博客。 Gridea - https://github.com/getgridea/gridea"},{"title":"宝塔 BT 面板 301 重定向不带 www 跳转教程","path":"/article/bt-301redirection/","text":"网站统一 URL 有利于 SEO，宝塔 BT 面板自带 301 重定向功能，将不带 www 的域名跳转到带 www 的域名，LAMPLNMP 分享宝塔面板 301 重定向教程两种： 宝塔 301 重定向后台自带功能 宝塔面板后台自带了 301 重定向功能，可以帮助我们将域名进行 www 和不带 www 之间的跳转转换。 登录到宝塔面板后台：http://[ip address]:8888 点击左侧 “网站”，找到需要设置的域名，点击右侧的 “设置”； 点击切换到 “301 重定向” 选项卡，如下图所示： 上述设置方法，是将不带 www 的域名 301 重定向到带 www 的域名上，至此宝塔面板 301 重定向跳转完成。 代码设置 301 重定向 通过编写宝塔面板后台自带的伪静态规则实现 301 重定向，将不带 www 跳转到带 www 域名规则： 12if ($host ~ '^shiux.com'){return 301 http://www.shiux.com$uri;} 点击切换到 “伪静态” 选项卡，如下图所示： 至此，宝塔面板 301 重定向教程完毕。 http://www.lamplnmp.com/baota/440/"},{"title":"SSH 的使用指南","path":"/article/ssh-guide/","text":"问题描述 做 DL 的经常需要在一台电脑 (本地主机) 上写代码，另一台电脑 (服务器，计算力强) 上进行训练，我们在两台电脑上都安装的是 Ubuntu，为了在 local 主机下也可以随时跑程序，调代码，同时省流量而且迅速 (不考虑这些的话用 teamviewer 也行)，所以在两台电脑主机上进行 SSH 配置。 基础:ssh 命令连接 SSH 程序的安装 确保在服务器上安装好了 openssh-server 程序，在本地主机上安装好了 openssh-client 程序。 12sudo apt install openssh-client #本地主机运行此条，实际上通常是默认安装client端程序的sudo apt install openssh-server #服务器运行此条命令安装 服务器启动 ssh 服务 以下命令都只针对服务器端 (server only)。 一般服务器上安装 ssh 完成后，会自动启动 ssh 服务，并且默认随系统启动，如果没有，请手动启动： 1sudo /etc/init.d/ssh start #服务器启动ssh-server服务， 其他命令： 12sudo /etc/init.d/ssh stop #server停止ssh服务sudo /etc/init.d/ssh restart #server重启ssh服务 查询服务器的 ip 地址 在服务器终端运行以下命令： 1ifconfig #查询ip地址，在返回信息中找到自己的ip地址 从我的返回信息中看到，我的 ip 地址 (inet 地址) 是：10.170.11.147。 如果没有看到 IP 地址，说明你没有安装指定工具： 12sudo apt install net-tools #Ubuntusudo yum install net-tools #CentOS 输入以上命令即可。 在本地主机端 ssh 远程登录服务器 这一步需要知道服务器的用户名 (我的服务器名字也是 shiux) 及 IP 地址。 在本地主机上运行以下命令： 用户端连接服务器用于登录远程桌面 (以下 user 时远程主机的用户名) 12345ssh shiux@10.170.11.147#或ssh -l shiux 10.170.11.147# 如果需要调用图形界面程序ssh -X shiux@10.170.11.147 初次登录时会出现以下信息，请记住要输入的密码是服务器主机本身的登陆密码： 以上表示连接成功，且命令提示副前的用户名 @主机名由本地主机变成服务器的信息，即表明现在该终端所有的命令都是在服务器中执行。 本地主机端登录相关的其他命令 如果服务器的 SSH 服务没有开启在 22 端口，那么 SSH 链接时则需要用 -p 指定端口（如 202）: 123ssh -p 202 shiux@10.170.11.147#或ssh -l shiux -p 202 10.170.11.147 退出远程登录 用 Ctrl+D 或者 1exit 进阶：利用公钥省去口令输入 每次登录远程主机都需要输入密码是很不便捷的，如果要加速这一步骤，可以利用密钥对进行连接，主要思路是：生成一对公钥私钥，私钥在 local 主机上，公钥在远程服务器上，每次建立 ssh 连接自动检查密钥对是否匹配。 生成密钥对 1ssh-keygen -t rsa #-t表示选择类型,类型为rsa 执行以后会在 $HOME 目录下生成一个.ssh 文件夹，其中包含私钥文件 id_rsa 和公钥文件 id_rsa.pub。 复制公钥至服务器 1234567891011121314# 登录远程服务器ssh shiux@10.170.11.147 # 在服务器上创建.ssh文件夹,如果已经存在就跳过此步mkdir .ssh # 为了保证.ssh文件夹的安全，应取消其他用户对文件夹的所有权限chmod 700 .ssh# 退出登录exit# 本地主机的公钥复制到远程服务器,作为已认证密钥scp /home/shiux/.ssh/id_rsa.pub shiux@10.170.44.206:/home/shiux/.ssh/authorized_keys 在进行以上配置以后，再进行连接时，就可以免去口令 (密码) 的输入了。"},{"title":"适用于 Web 开发人员使用的国外 8 款免费图标包","path":"/article/web-development-icon-packages/","text":"使用图标是使您的设计更加有趣和引人注目的最快和最简单的方法之一。添加适当的图标可以使用户界面更加清晰，引导用户浏览页面并向用户显示每个按钮或链接的功能。 在这篇文章中，我们收集了 6 个最可靠，最精美的图标包。我们将它们分为三类：字体图标，SVG 和 CSS 图标。在我们掌握资源之前，让我们快速看看每种类型的优缺点： Feather Icons - https://feathericons.com/ 类型: SVG 图标的数量: 240 许可: MIT Feather 是最流行的开源图标集之一。所有的图标都设计在一个 24x24 的网格上，并具有相同的圆角样式，一致的外观。轻松用于框架集成的项目可用于 Angular，Vue 和 React。 Linea - https://github.com/linea-io/Linea-Iconset 类型: SVG, PNG, IconFont 图标的数量: 730+ 许可: CCBY Linea 提供了大量精美的现代图标，其特点是外观清晰、轮廓分明。所有的图标都有不同的分类，包括基本的，音乐的，电子商务的，软件的等等。 Octicons - https://octicons.github.com/ 类型: SVG 图标的数量: 170+ 许可: GitHub Octicons 是 GitHub 可扩展的手工 SVG 图标集。它包括 GitHub 和编程相关的图标，如数据库图标，git 操作图标，等等。 Glyph - https://glyphicons.com/ 类型: SVG 图标的数量: 800 许可: CC BY-SA 4.0 在项目的 GitHub 中，您可以下载一个 Node.js 脚本来自定义图标包，这种方法适用于仅包含您真正需要的图标。 Font Awesome - https://fontawesome.com/ 网页最受欢迎的图标字体（GitHub 上超过五万颗星），Font Awesome 提供了大量图标，这些图标是为可扩展性，通用浏览器支持和视觉障碍用户的良好可访问性而构建的。 Ionicons - https://ionicons.com/ 类型: Icon Font 图标的数量: 260+ 许可: MIT Ionic Framework 为后面的团队设置了一个非常漂亮的图标。提供超过 260 个漂亮的图标，其中一些是厚重的平面风格，另一些是现代的细线风格。 Material Icons - https://material.io/ 类型: Icon Font 图标的数量: 900+ 许可: Apache Google 的 Material Design 语言的官方图标和 Android 中的所有图标。它包含超过 900 个图标，都是以一致的 Material 风格制作的，保证了你在项目使用起来有一致的风格。 Icono - https://saeedalipoor.github.io/icono/ 类型: CSS Icons 图标的数量: 130 许可: MIT 纯 CSS 图标的集合。要实现它们，只需要下载.css 样式表，创建一个空的 HTML 元素，然后添加相应的类。所有的图标都是这样的，只需要一个 HTML 元素就可以工作。"},{"title":"原生 js 中编码的三种方法","path":"/article/three-coding-methods-in-native-js/","text":"在开发中经常需要对用户输入的数据进行编码然后才能通过 HTTP 请求发送给后台，或者对传递过来的数据进行解码。在 JS 中原生提供了三种编码 / 解码方式，分别是&nbsp;encodeURI、&nbsp;encodeURIComponent 和&nbsp;escape。 encodeURI 该方法不会对 ASCII 表中的字母和数字编码，同时也不会对 ASCII 中的标点符号编码&nbsp;**-_.~*’()**&nbsp;在 URI 中具有特殊含义的符号&nbsp;**;/?:@&amp;=+$,#** 同样不会被编码。 123456let url = 'https://google.com/pathname?a=1&amp;b=abcde&amp;c=黄山#hash';encodeURI(url); // 返回 https://google.com/pathname?a=1&amp;b=abcde&amp;c=%E9%BB%84%E5%B1%B1#hashencodeURI(\"-_.~*'()\"); // 返回 -_.~*'()encodeURI(\";/?:@&amp;=+$,#\"); // 返回 ;/?:@&amp;=+$,# encodeURIComponent 该方法相比 encodeURI 多编码 URI 中具有特殊含义的符号&nbsp;**;/?:@&amp;=+$,#** 123456789101112let url = 'https://google.com/pathname?a=1&amp;b=abcde&amp;c=黄山#hash';encodeURIComponent(url); // 打印 \"https%3A%2F%2Fgoogle.com%2Fpathname%3Fa%3D1%26b%3Dabcde%26c%3D%E9%BB%84%E5%B1%B1%23hash\"encodeURIComponent(\"-_.~*'()\"); // 返回 -_.~*'()encodeURIComponent(\";/?:@&amp;=+$,#\"); // 返回 %3B%2F%3F%3A%40%26%3D%2B%24%2C%23// 通过对比可看出方法`encodeURI`和`encodeURIComponent`编码中文的返回结果是一样的。encodeURI(\"黄山\"); // 返回 %E9%BB%84%E5%B1%B1encodeURIComponent(\"黄山\"); // 返回 %E9%BB%84%E5%B1%B1 escape（不推荐使用，推荐使用上面两个方法代替） 该方法会对 ASCII 中&nbsp;* 字母、数字及符号 @-_+./** 之外的所有字符进行编码。 123456789101112let url = 'https://google.com/pathname?a=1&amp;b=abcde&amp;c=黄山#hash';escape(url); // 返回 https%3A//google.com/pathname%3Fa%3D1%26b%3Dabcde%26c%3D%u9EC4%u5C71%23hashconsole.log(escape(\"*@-_+./\")); // 打印 *@-_+./escape对于汉字的编码和上面两个方法的编码结果并不一样。encodeURI(\"黄山\"); // 返回 %E9%BB%84%E5%B1%B1encodeURIComponent(\"黄山\"); // 返回 %E9%BB%84%E5%B1%B1escape(\"黄山\"); // 返回 %u9EC4%u5C71 解码 三种编码方法对应的解码方法分别是： 编码 解码 encodeURI decodeURI encodeURIComponent decodeURIComponent escape unescape 12345678let res = encodeURI(\"黄山\"); // %E9%BB%84%E5%B1%B1decodeURI(res); // 返回 黄山let res = encodeURIComponent(\"黄山\"); // %E9%BB%84%E5%B1%B1decodeURI(res); // 返回 黄山let res = escape(\"黄山\"); // %u9EC4%u5C71unescape(res); // 返回 黄山"},{"title":"Mac 系统的访达 Finder 侧边栏目录的英文转中文","path":"/article/mac-finder-english/","text":"想把 Mac 电脑的访达 Finder 中的英文目录转成中文，可以参考以下办法： 打开 Mac 电脑终端，按需自取命令即可。比如，我的只有【影片】-【Movies】，我只需选择命令 6 即可。 以下操作如果没生效，需要重启 Finder。 重启步骤为🍎-&gt;强制关闭-&gt;访达 桌面 1touch ~/Desktop/.localized 文稿 1touch ~/Documents/.localized 下载 1touch ~/Downloads/.localized 图片： 1touch ~/Pictures/.localized 音乐： 1touch ~/Music/.localized 影片： 1touch ~/Movies/.localized 以上就是给大家分享的 Mac 电脑 Finder 英文目录转中文的图文教程，是不是简单又实用！希望对大家有所帮助！"},{"title":"独特的 DNS 配置","path":"/article/unique-dns-setup/","text":"众所周知，DNS 的作用与电话簿类似，将人类可读的域名映射到机器可读 IP 地址、使人更方便地访问互联网。DNS 是非常重要的互联网基础设施，对于改善上网冲浪的体验中的重要程度不容小觑。 避免不必要的 DNS 解析 如果想要通过优化 DNS 来改善自己的网络体验，第一步其实是避免不必要的 DNS 解析。 使用 Fake IP 避免本机 DNS 解析 对于不支持设置 SOCKS/HTTP (S) 代理的软件，Surge/Clash 等软件一般选择通过 TUN/TAP 或转发 redir 透明网关接管网络请求，从而拿到原始的 TCP/IP 连接。 在 POSIX 规范下，执行网络请求需要先通过 gethostbyname、getremoteaddr 等操作系统提供的方法进行 DNS 解析，获取到 IP 地址以后发起连接；如果 DNS 解析不成功，网络请求就无从谈起了。因此绝大部分依赖 TUN 和 TAP 的某些软件都会接管系统 DNS 解析。接管 DNS 解析后随之而来的便是一系列问题： DNS 污染：由于特殊的网络环境，通过你本机直接进行 DNS 解析得到的结果可能不可靠。 CDN 优化：如果要访问的目标网站使用了 CDN，最理想的结果是 距离代理服务器最近的 CDN 节点 - 代理服务器 - 你。如果你通过本机直接进行 DNS 解析，获取到的 IP 地址可能并不是距离你远端代理服务器 最近的 CDN 节点。 由于常见的某些协议都运行在 Layer 4 上、支持封装域名；因此 Surge/Clash 等软件在转发流量时，都是封装目标域名，而不是目标域名在本机解析到的 IP 地址，从而规避 DNS 污染和实现 CDN 优化。 如果软件一旦决定将某个域名转发给远端代理服务器，远端代理服务器也需要对拿到的域名进行一次解析，在本机解析的 IP 地址其实没有起任何作用，白白浪费一个 RTT。于是 2001 年四月，IETF 通过了 RFC3089，描述了一种网关通过接管 DNS、返回 Fake IP 来建立 TCP/IP 链接的方法。简单的流程如下： 代理网关接管本机的 DNS 解析 一个软件意图对一个域名发起网络请求，于是先通过 DNS 解析获取域名对应的 IP 代理网关收到 DNS 解析请求后，不做任何 DNS 解析，而是直接返回一个保留 IP 地址（Fake IP） 发起网络请求的软件获取到 Fake IP 后，试图以 Fake IP 为目标发起网络请求 代理网关截获网络请求，通过目标的 Fake IP 反推出目标域名 代理网关将流量和目标域名使用某种协议重新封装后、转发给远端代理服务器 不过在日常使用中，即使有了 Fake IP 也不能完全避免本机进行 DNS 解析。Surge/Clash 使用 Fake IP 后，当且只当以下两种情况时会在本机进行 DNS 解析： 目标域名需要使用 DIRECT 策略（即直连）、此时 Surge/Clash 需要得到真实的目标 IP、不通过代理服务器直接发起连接 Surge/Clash 遇到了基于 IP 分流的策略（如 IP-CIDR、IP-ASN、GEOIP、LAN 等），此时 Surge/Clash 需要得到一个 IP 用于匹配分流 也就是说，如果 Surge 和 Clash 能够匹配到了一条域名规则、指示网络请求需要被转发给远端代理服务器，Surge 和 Clash 便不会在本地进行 DNS 解析。因此在编写 Surge 和 Clash（以及同类软件 Shadowrocket、Quantumult (X)、Surfboard 等）的规则时，将 IP 相关规则（IP-CIDR、IP-ASN、GEOIP 等）放在其余的规则（DOMAIN、DST-PORT、SRC-PORT、PROTOCOL、URL-REGEX）的后面；除此以外，需要代理的域名的规则组越完善、Surge/Clash 匹配到 IP 类规则的概率也就越低，需要本机 DNS 解析的次数也就越少。 使用域名分流规则直接拦截广告 不论是去广告 Hosts 还是 AdGuardHome 等解决方案，本质上都是在 DNS 解析环节拦截域名；由于 DNS 的局限性，这类解决方案只能拦截完整的广告域名，不能拦截某一个域名下的具体 URL，因此要么不够强力、要么误杀严重，不能取代专业的浏览器去广告插件（如 ADBlock Plus、AdGuard for Chrome）和去广告软件（如 AdGuard for Android）。 除此以外，由于 Surge/Clash 等支持使用域名规则进行分流的软件也都提供了对 REJECT 策略的支持（Surge 还额外支持两种特殊的 REJECT 策略：不回复任何数据包、任由链接自行超时的 REJECT-DROP，和返回空白 1 像素 GIF 图像文件的 TINY-GIF）。因此，我们可以编写域名规则拦截广告请求、彻底杜绝被拦截域名的 DNS 解析、加快阻断。 目前 Surge 支持 DOMAIN-SET 格式，可以在一个配置文件里记录数十万条域名，而不会内存泄漏或崩溃；Clash、Quantumult (X) 的域名规则可能不支持上万级别数量的域名、强行导入可能导致内存泄漏或 Panic；Surfboard 虽然完全兼容 Surge 的 DOMAIN-SET 格式，但是可能存在优化程度不够、达不到 Surge 同等速度和效率。 建议先对有关软件进行测试，如果不能很好的处理大量域名规则的，仍然可以使用 AdGuardHome 作为去广告的替代。 中场休息：递归 DNS 是怎么知道哪个 CDN 节点距离我最近的？ 先暂时抛开对我的 DNS 配置的介绍，简单谈谈递归 DNS（Local DNS）是如何实现「CDN 优化」的。 假设你的宽带 IP 是 114.5.1.4，你现在试图访问一个使用了阿里云 CDN 的网站 alicdn.example.com、接入 CDN 的方式是 CNAME 到 alicdn.example.com.w.alikunlun.com。 注意，为了节省篇幅，在接下来的描述中，我刻意省去了 Local DNS 向 Root DNS 查询 com 和 example.com 的权威 DNS 的过程。如果想要了解完整的 DNS 查询过程，可以阅读由 Cloudflare 编写的 What is DNS? | How DNS works。 运营商 DNS 一开始，你使用的是由运营商下发给你的运营商 DNS，假设运营商的递归 DNS 的 IP 是 1.2.3.4，于是： 你向 1.2.3.4 发起 DNS 查询：请问 alicdn.example.com 的解析结果是什么？ 1.2.3.4 问 example.com 的权威 DNS 查询：alicdn.example.com 的解析结果是什么？ example.com 的权威 DNS 告诉 1.2.3.4：alicdn.example.com 用 CNAME 指向了 alicdn.example.com.w.alikunlun.com。 于是 1.2.3.4 把结果返回给你：alicdn.example.com 用 CNAME 指向了 alicdn.example.com.w.alikunlun.com 你问 1.2.3.4：请问 alicdn.example.com.w.alikunlun.com 的解析结果是什么？ 1.2.3.4 问 alikunlun.com 的权威 DNS：alicdn.example.com.w.alikunlun.com 的解析结果是什么？ alikunlun.com 是阿里云 CDN 的域名，阿里的权威 DNS 开始找：地理位置最接近 1.2.3.4 的 CDN 节点是哪些？有 19.19.8.10。 alikunlun.com 告诉 1.2.3.4：alicdn.example.com.w.alikunlun.com 解析到了 19.19.8.10。 1.2.3.4 把结果返回给你：alicdn.example.com.w.alikunlun.com 解析到了 19.19.8.10。 因此，阿里云 CDN 并不是返回「最适合你」的 CDN 节点 IP，而是返回「最适合这个运营商 DNS」的 CDN 节点 IP。只不过由于运营商 DNS 一般都距离你很近，所以也可以把这个结果当作是「最适合你」的 CDN 节点 IP。 公共 DNS 再后来，你听说南京信风提供的公共递归 DNS 114.114.114.114 很有名，于是你手动将你的 DNS 设置为 114.114.114.114。 114.114.114.114 是一个 Anycast IP，即一个 IP 能够对应不同区域、不同 ISP 的多个数据中心、多台服务器。截止到本文写就，南京信风仅在江苏南京的 电信、联通、移动 和 美国伊利诺伊州芝加哥的 Cogent 广播了 114.114.114.114，也就是说 114.114.114.114 仅对应到了这两地的服务器节点。一般的，国内的用户连接 114.114.114.114，都是访问位于江苏南京的节点。 你通过 114.114.114.114 和通过运营商 DNS 获取 alicdn.example.com 的解析结果的过程大同小异，区别在于这一次，alikunlun.com 并不会试图返回最适合 1.2.3.4（你的运营商 DNS）的 CDN 节点，而是试图返回最适合江苏南京的 CDN 节点。 由于中国复杂的互联网环境和封闭的网络基础设施建设，很难将 Anycast 覆盖到中国 30 余省市的十数个主流运营商、如上文所说，南京信风的 114.114.114.114 在国内甚至只有一个节点、只能覆盖三个运营商；即使是腾讯云 DNSPod 和阿里的公共 DNS，在国内也只有不到 10 个节点。 因此，在国内使用公共 DNS，不仅不能够优化 CDN，反而还会劣化 CDN。也是因为同一个原因，运营商要劫持你的 DNS 查询，避免因为你的 DNS 设置不当、反而投诉运营商的网络速度慢、差。 与此同时，公共 DNS 为了解决少数 Anycast 节点无法对应到全国 30 余省市数十个运营商的问题，另辟蹊径想出了一个新的方案： 多出口 IP 的公共 DNS 有的公共 DNS 除了在全国设立 Anycast 节点、负责接收 DNS 查询以外，还在全国 30 余省市均部署了额外的服务器（称作「DNS 出口服务器」）。这些 DNS 出口服务器不会直接接收来自终端用户的 DNS 查询，而是 Anycast 节点接收到终端用户的 DNS 查询后，转交给 DNS 出口服务器再进行解析： 你（114.5.1.4）向 233.5.5.5 发起查询：请问 alicdn.example.com 的解析结果是什么？ 223.5.5.5 的众多 Anycast 节点中的一个收到了你的查询、开始寻找：我在全国部署的上百个 DNS 出口服务器中，哪一个是距离 114.5.1.4 最近的？ 223.5.5.5 将 DNS 查询转交给距离你最近的 DNS 出口服务器（称作「DNS 出口 A」）。 DNS 出口 A 问 alikunlun.com 的权威 DNS：alicdn.example.com.w.alikunlun.com 的解析结果是什么？ 阿里云 CDN 开始找：地理位置最接近 A 的 CDN 节点都是哪些？ alikunlun.com 告诉 A：alicdn.example.com.w.alikunlun.com 解析到了这些 IP。 A 告诉 223.5.5.5：alicdn.example.com.w.alikunlun.com 解析到了这些 IP。 223.5.5.5 告诉你：alicdn.example.com.w.alikunlun.com 解析到了这些 IP。 这样，虽然接收到你查询的公共 DNS 的 Anycast 节点不一定距离你非常非常近，但是最终向权威 DNS 发起查询的，却是距离你尽可能近的「DNS 出口服务器」，因此得到的「最适合 DNS 出口服务器」的 CDN 节点 IP、也是最适合你的。 支持 EDNS Client Subnet 的公共 DNS 为了解决权威 DNS 难以根据终端用户的真实 IP 返回最适合用户的 CDN 节点的问题，IETF 通过了 RFC7871，即 EDNS Client Subnet（ECS）。RFC7871 定义了在 DNS 查询时，用户可以指定一个 IP 网段，权威 DNS 可以据此返回最适合这个 IP 网段的 CDN 节点： 你（114.5.1.4）问支持 ECS 的公共 DNS119.29.29.29：我是 114.5.1.0/24，请问 alicdn.example.com.w.alikunlun.com 的解析结果是什么？ 119.29.29.29 问 alikunlun.com 的权威 DNS：114.5.1.0/24 在问 alicdn.example.com.w.alikunlun.com 的解析结果是什么？ 阿里云 CDN 开始找：地理位置最接近 114.5.1.0/24 的 CDN 节点都是哪些？ alikunlun.com 告诉 119.29.29.29：alicdn.example.com.w.alikunlun.com 解析到了这些 IP。 119.29.29.29 把结果返回给你：alicdn.example.com.w.alikunlun.com 解析到了这些 IP。 虽然 ECS 解决了权威 DNS 无法获取用户真实 IP 的问题，但是在实践中仍然存在一些困难： 使用 ECS 有可能泄漏用户的隐私信息，一些公共 DNS（如 Cloudflare 的 1.1.1.1 和 1.0.0.1）因此拒绝提供 ECS 支持。 在 RFC7871 的 11.2 章节中提到了一种针对 ECS 的攻击（即 Birthday Attack），因此当 DNS 请求 / 响应中的 ECS 信息不完整时、需要彻底忽略 ECS，降级回传统 DNS 查询。 使用 ECS 会降低递归 DNS 的性能、甚至可以被用于发动针对递归 DNS 的攻击：以前一个递归 DNS 可以为所有人缓存同一个 CDN 节点 IP，现在却需要为每个人缓存不同的 CDN 节点 IP。RFC7871 的 11.3 章节也因此指出，并非所有的递归 DNS 都需要支持 ECS。 ECS 需要从用户、到递归 DNS、到权威 DNS 全链路均提供支持才能生效。虽然在 DNSFlagDay 的大力推动下，绝大部分权威 DNS 已经支持 ECS，但在递归 DNS 中 ECS 的普及率仍然不容乐观。 在补充介绍了递归 DNS 是如何优化 CDN 结果后，不难得出结论： 需要被代理的域名、必须在远端代理服务器上进行解析、才能得到最合适的解析结果。 在本地对需要代理的域名进行 DNS 解析，只不过是为了让 Surge/Clash 等软件能够基于 IP 分流（Surge/Clash 的 TUN/TAP 会直接返回 Fake IP、本地 DNS 解析的结果根本不会暴露给外部）罢了。本地 DNS 解析的结果不需要很精确，建议牺牲准确度换更快的速度。 为了能够让被代理的域名在远端服务器上解析，在通过某种协议将代理请求发送给远端代理服务器时，必须直接封装该网络请求的域名。 使用 Surge/Clash 等软件后，完全无需使用 dnsproxy 或 dns2socks 转发本地 DNS 查询。代理此类 DNS 查询不仅没有必要，反而会导致延迟升高、影响上网体验。 正确配置 SmartDNS SmartDNS 是一个运行在本地的 DNS 服务器，它接受来自本地客户端的 DNS 查询请求，然后从多个上游 DNS 服务器获取 DNS 查询结果，并将访问速度最快的结果返回给客户端，以此提高网络访问速度。SmartDNS 同时支持指定特定域名 IP 地址，能够以极高的性能进行匹配，可用于过滤广告或分流。 由于 SmartDNS 的极致性能和强大特性，以及「提高网络访问速度」的功能，许多 YouTube 视频和教程文档都将其奉若神明、称为一切的解药。然而事实上，如果不经过仔细的配置，SmartDNS 不仅不能起到预期的效果，反而还会导致负优化。 如果一个网络请求将会被封装转发给远端代理服务器、会在远端代理服务器进行 DNS 解析，因此在本机进行的 DNS 解析得到的结果是没有任何意义的。因此，需要被代理的域名，并不在乎能否得到延时最低的 IP，只需要不干扰 Surge/Clash 等软件的 IP 分流规则即可，无需非常精确。 不需要对 SmartDNS 产生的 DNS 查询请求和测速握手进行代理。将 DNS 查询转发给远端代理服务器会大幅增加 DNS 解析用时、影响上网体验！ 因此，需要被代理的域名不需要进行测速 —— 测速不仅浪费一个 RTT，而且 ISP 和其它中间人可能会记录你的 ICMP 或 TCP 握手行为。除此以外，考虑到绝大部分递归 DNS（Local DNS）都可能存留日志用作各种用途（如下图所示的「中国科学技术大学 USTC 校园网 DNS 最近 10 分钟查询统计」），需要被代理的域名也最好不要选用位于国内的递归 DNS 作为上游。 中场休息：SmartDNS 是如何避免因测速导致 DNS 解析过慢的 第二个中场休息环节，这次简单讲讲 SmartDNS 的工作原理。 有一些人认为，SmartDNS 配置了数十个上游，需要对上游返回的每一个 IP 都进行测速，反而严重影响 DNS 解析速度。但是实际使用 SmartDNS 后，并没有出现 DNS 解析过慢的情况。这是因为 SmartDNS 早就考虑到了测速与延时的问题、并进行了相关的优化。SmartDNS 在首次 DNS 解析请求时，会同时向所有上游发起并发查询；一旦有一个上游返回了结果，SmartDNS 就会对这第一个返回的结果进行测速，得到其中延时最低的 IP，将其返回给用户、设置 TTL 为 10；与此同时，SmartDNS 仍然会等待剩余上游返回结果、异步进行测速，直到所有上游都返回了结果（或超时）、SmartDNS 将所有的 IP 都进行测速以后，才会得到最优 IP： 假设我们向 SmartDNS 解析一个域名 example.com，由于没有命中 SmartDNS 的缓存，因此不得不向上游获取结果。 SmartDNS 同时向上游 A、B、C 发起查询请求 假设上游 B 最先返回了查询结果，查询结果包含了三个 IP：114.5.1.4、11.45.1.4 和 19.19.8.10。 SmartDNS 立刻开始对这三个 IP 进行测速。假设测得延时最低的 IP 是 11.45.1.4 SmartDNS 会立刻返回 11.45.1.4 给客户端，同时设置 TTL 为 10（即指示 11.45.1.4 只应该在客户端被缓存 10 秒中） 在接下来 10 秒内，客户端都会使用都会使用 11.45.1.4 来处理发往 example.com 的网络连接；与此同时 SmartDNS 仍然在等待上游 A 和 C 的结果。 一旦上游 A 和 C 的查询结果也都返回，SmartDNS 会把上游 A、B、C 的结果进行汇总去重、重新测速，最终得到最快的那个 IP。 由于 SmartDNS 有着非常严格的超时设置，因此上述「等待剩余上游结果并分别进行测速」步骤不会超过 10 秒。 等到 10 秒过去、客户端再次向 SmartDNS 查询 example.com 时，SmartDNS 才会返回最快的 IP、并设置一个「正确」的 TTL。 总而言之，SmartDNS 首先会尽快返回一个「次优」的 IP、要求客户端仅在接下来 10 秒钟内使用「次优」的 IP，之后 SmartDNS 就能返回「最优」的 IP。 不过正如我在前文所说，Surge 支持针对 DNS 返回的多个 IP 同时进行握手、并使用最先完成握手的 TCP 进行后续请求（丢弃其余的 TCP 握手），因此 Surge 使用的 IP 一定是延时最低的、而且能够跳过出现故障的 IP；而且 Surge 复用了并发握手时的 TCP 连接进行后续请求，因此延时比 SmartDNS「先测速、后返回 IP」更低。 因此在搭配 Surge 使用时，上游 DNS 不需要自带测速；最好是能合并多个上游返回的结果，将多个上游返回的一大堆 IP 全部喂给 Surge、让其并发握手。我给 SmartDNS 开了对应的 Feature Request，感兴趣的可以关注一下。 在 SmartDNS 中使用 dnsmasq-china-list 进行分流 felixonmars/dnsmasq-china-list 是一组开源的，覆盖了绝大部分中国大陆的域名的 dnsmasq 配置文件，也可以通过预定义的 Makefile 生成供 unbound、bind9、dnscrypt-proxy、SmartDNS、AdGuardHome、coredns 使用的配置文件。截至本文写就，dnsmasq-china-list 已经收录了 65743 个域名。满足以下任意两条规则之一的域名即会被收录到列表中： 是.cn 后缀的域名（包括.edu.cn、.gov.cn、.org.cn、.ac.cn 等） 满足以下两条规则中任意一条的、非.cn 后缀的域名： 域名使用的权威 DNS（Authoritative DNS）拥有位于中国大陆境内的节点 通过位于中国大陆境内的递归 DNS 解析时，解析得到的 IP 位于中国大陆境内 如果需要设置 SmartDNS 针对指定域名使用与默认配置不同的上游进行解析，可以使用 nameserver，如下所示： 1nameserver /example.cn/domestic 如果需要设置 SmartDNS 针对指定域名不使用默认配置的上游、且采用与默认不同的测速方式，需要使用 domain-rules，如下所示： 1domain-rules /example.cn/ -speed-check-mode tcp:80 -nameserver domestic dnsmasq-china-list 预定义的 Makefile 同时支持生成上述两种配置格式的文件。使用下述命令可以生成使用 nameserver 的配置条目： 1make SERVER=domestic smartdns 我给 dnsmasq-china-list 开了 PR（felixonmars/dnsmasq-china-list#381）且已经被合并，现在已经可以生成使用 domain-rules 的配置条目： 1make SERVER=domestic SMARTDNS_SPEEDTEST_MODE=tcp:80 smartdns-domain-rules 注意，你可能需要安装 make 才可以使用上述命令。在 macOS 上，make 包含在 Xcode Command Line Tools 之中。 配置 SmartDNS 上游和仅测速国内域名 如前文所说，在本地解析需要被代理的域名时，不需要测速、也不一定要绝对准确，只需要解析得到的 IP 不会干扰 Surge/Clash 分流即可；只将国内的递归 DNS 作为上游解析国内直连域名，也只对其进行测速。因此，我们使用「白名单」策略，默认解析不测速、不使用国内递归 DNS 作为上游。 首先需要禁用 SmartDNS 全局的测速设置： 1speed-check-mode none 然后设置两组上游 DNS：默认的一组不位于中国大陆境内的递归 DNS；另一组位于中国大陆境内的递归 DNS，仅用于解析 dnsmasq-china-list 列表中的域名： 123456789101112131415161718192021222324# ----- Default Group -----# 默认使用的上游 DNS 组# OpenDNS 非常规 443 端口、支持 TCP 查询server-tcp 208.67.220.220:443# OpenDNS 的 IP DoHserver-https https://146.112.41.2/dns-query# TWNIC 的 IP DoHserver-https https://101.101.101.101/dns-query# 你也可以配置其它 DNS 作为上游# ----- Domestic Group: domestic -----# 仅用于解析 dnsmasq-china-list 列表中的域名# 腾讯 DNSPod IP DoTserver-tls 1.12.12.12:853 -group domestic -exclude-default-groupserver-tls 120.53.53.53:853 -group domestic -exclude-default-group# 阿里 IP DoTserver-tls 223.5.5.5:853 -group domestic -exclude-default-groupserver-tls 223.6.6.6:853 -group domestic -exclude-default-group# 114 DNS、使用 TCP 查询server-tcp 114.114.114.114 -group domestic -exclude-default-groupserver-tcp 114.114.115.115 -group domestic -exclude-default-group# CNNIC 公共 DNS、仅支持 UDP 查询server 1.2.4.8 -group domestic -exclude-default-groupserver 210.2.4.8 -group domestic -exclude-default-group 其中，设置有 -exclude-default-group 的上游 DNS 默认不会被使用，仅当 domain-rules 或 nameserver 配置明确指定时使用。 你可能注意到，我的配置中添加了 CNNIC（中国互联网络信息中心）的公共 DNS。这是考虑到 CNNIC 的公共 DNS 节点质量较差、出口 IP 位置稀少、基本没有针对 CDN 做任何优化（截至本文写就，1.2.4.8 的 Anycast 仅在浙江杭州阿里云和香港 Zenlayer 广播路由，210.2.4.8 的 Anycast 仅在 北京联通广播路由）。所以，一般情况下，只有 CNNIC 的公共 DNS 一定不能返回距离我位置最近的 CDN 节点（其余的公共 DNS 基本都会返回给我最优的 CDN 节点）。 设想一下，除 CNNIC 外、大部分公共 DNS 都会尽可能返回距离我本地运营商最近的、最优的 CDN 节点；由于 SmartDNS 的测速和优选，CNNIC 返回的非最优 CDN 节点一般会被忽略。然而，假如距离我最近的 CDN 节点出现故障，只有 CNNIC 能够给我返回不一样的 CDN 节点、能够响应 SmartDNS 测速，因此我能够使用并非最优、但是可用的 CDN 节点「救急」、不至于直接「断网」。 简单来说，就是因为 CNNIC 公共 DNS 能够非常稳定地提供质量最差的递归 DNS 服务、不会间歇发生解析质量好转，才得以入选。 最后，引入前文由 dnsmasq-china-list 生成的 domain-rules 配置文件： 12conf-file /path/to/dnsmasq-china-list/accelerated-domains.china.domain.smartdns.confconf-file /path/to/dnsmasq-china-list/apple.china.domain.smartdns.conf"},{"title":"OCC 命令给 ownCloud/NextCloud 手动添加文件","path":"/article/occ-command-to-manually-add-files-to-owncloud-nextcloud/","text":"有时候，直接通过 Web 页面上传文件并不那么方便，于是有的朋友就直接把文件上传到服务器里，然后拷贝到 data 目录下，打开 ownCloud，却还是之前的文件。 这是因为虽然上传了文件，但是 ownCloud/NextCloud 的数据库里并没有这个文件的信息。文件信息都被存储在数据库的 oc_filecache 表 使用 OCC 命令更新文件索引 occ 有三个用于管理 NextCloud 中文件的命令： 1234files files:cleanup #清楚文件缓存 files:scan #重新扫描文件系统 files:transfer-ownership #将所有文件和文件夹都移动到另一个文件夹 我们需要使用 files:scan 来扫描新文件。 12345678910111213格式: files:scan [-p|--path=\"...\"] [-q|--quiet] [-v|vv|vvv --verbose] [--all] [user_id1] ... [user_idN]参数: user_id # 扫描所指定的用户（一个或多个，多个用户ID之间要使用空格分开）的所有文件选项: --path # 限制扫描路径 --all # 扫描所有已知用户的所有文件 --quiet # 不输出统计信息 --verbose # 在扫描过程中显示正在处理的文件和目录 --unscanned # 仅扫描以前未扫描过的文件 示例 12sudo -u www-data php occ files:scan --all #扫描所有用户的所有文件sudo -u www php /www/wwwroot/{site_path}/occ files:scan --all #宝塔面板 执行命令后未进行扫描并列出扫描信息。 如果不想显示扫描信息，可以在后面加上 --quiet 12sudo -u www-data php occ files:scan --all --quietsudo -u www php /www/wwwroot/{site_path}/occ files:scan&nbsp;--all&nbsp;--quiet #宝塔面板 指定扫描位置 总是扫描全部信息并不是那么有必要，还会白白消耗服务器资源。 指定扫描的用户 列出所有用户： 12sudo -u www-data php occ user:listsudo -u www php /www/wwwroot/{site_path}/occ user:list #宝塔面板 为指定用户扫描文件： 12sudo -u www-data php occ files:scan {user_name}sudo -u www php /www/wwwroot/{site_path}/occ files:scan&nbsp;{user_name} #宝塔面板 指定扫描目录 当使用 --path 选项时，该路径必须包含以下部分： 12345\"user_id/files/path\"#或\"user_id/files/mount_name\"#或\"user_id/files/mount_name/path\" /files/ 是必须要加上的，不可忽略。 示例 12sudo -u www-data php occ files:scan --path=\"/{user_name}/files/Photos\" #指向指定用户的Photos文件夹sudo -u www php /www/wwwroot/站点文件夹/occ files:scan --path=\"/{user_name}/files/Photos\" #宝塔面板"},{"title":"如何给 Ubuntu 系统清理垃圾","path":"/article/clean-up-the-garbage-for-ubuntu-system/","text":"使用 Windows 的同学都知道，我们可以利用各种安全卫士以及系统清理工具来清除系统运行时产生的系统垃圾。那么当你禁不住开源系统的诱惑，开始尝试 Ubuntu 系统时，是不是经常在思考该如何在 Ubuntu 下清理系统垃圾呢？下面，就让跟着本文来给你的 Ubuntu 系统来一次大扫除吧。 清理下载的软件包 不过与你想象的可能有很大的不同，Ubuntu 系统在运行时是不会产生无用垃圾的。这一点与 Windows 系统有很大的不同。但是我们在升级系统时，软件管理器下载的软件包，系统则不会自动删除，其实这样做也是考虑到你可能会再次安装从而加快再次安装的速度考虑。当然了，我们普通用户，一旦下载安装完毕，其安装包也就没有存在的必要了，当然如果你是要安装更新并管理一大堆电脑的系统管理员就另当别论咯。更何况，我们再次安装时，只要你选择了一个合适的软件源，那下载速度一样是飞快的。因此，我们隔一段时间就可清理一下 apt 等软件管理器下载下来的安装包咯。 我们先看一下，这些安装包占了多大空间吧。按快捷键 ctrl+alt+t 打开终端，输入命令 1du –h /var/cache/apt/archives 回车之后，我们就可以看到安装包所占用的空间咯。 那我们就来删除这些软件包吧。若你生性小心谨慎，那就只删除那些你已经将其卸载掉的软件的软件。删除你已经卸载掉的软件包的命令为 1sudo apt autoclean 若你想清理出更多的空间，而且网速又比较快的话，那你大可以把电脑上存储的安装包全部卸载咯，命令为 1sudo apt clean 还有一类软件包，我们每个人都应该删除，那就是你已经卸载了，但是一些只有它依赖而别的软件包都不需要的软件包还留在你的系统里。说简单点就是，类似于你在 windows 系统中卸载软件时残留在系统里的垃圾咯。卸载这些孤立包的命令为 1sudo apt autoremove 删除不用的老旧内核 若你的系统更新过好多次，如 Ubuntu，在系统升级的过程中，其所使用 Linux 内核也可能更新。因此，升级多次后，你的 boot 文件夹就会变得比较大，其原因就是因为虽然系统更新升级了新内核，但是老内核依然留在了你的系统中。也许你会说系统太笨了，不知道升级了新的就该把老的删除吗？实际上，不删除掉老的内核也是一种安全测试。虽然说，系统升级包在释放出之前已经进行了广泛的测试，但依然可能有意外存在，所以才不删除掉老的内核，以便于使用新升级的内核无法启动时，你能马上使用老内核进行启动，不至于导致你无法进入系统的悲剧。不过在你升级完毕，重启后能进入系统后，说明新内核已经很好的兼容了你的电脑，那么你就可以放心大胆的删除掉老内核咯，也好腾出更多空间让你使用哦。 不过老内核时一定要小心，那就是 —— 千万不要删错咯。所以删除之前要先看一看你现在正在使用的内核是哪一个。方法是在终端中输入命令 uname –r，然后看其显示的内核版本是多少。看准了自己使用的内核后，你就可以放心大胆的删除那些不用的老内核。 打开终端，敲入命令 1dpkg --get-selections | grep linux 然后将不用的内核文件 image、头文件 headers 删除掉就可以咯。在终端中输入命令 1sudo apt purge 内核文件名 头文件名 删除内核后，就可以省下很多空间哦 清理浏览器的缓存文件 我们在 Ubuntu 中经常使用的浏览器当然是火狐浏览器咯，在我们浏览网页时，它会把网页缓存到本地，因此会在本地保留一些缓存文件，若你是个有洁癖的人，或者喜欢给系统清理垃圾的话，我们也可以删除火狐浏览器的缓存。 方法是打开火狐的首选项 - &gt; 隐私与安全 - &gt; Cookie 和网站数据，点击右边的清除数据按钮就可以咯，如下图所示： 清除已卸载软件的残留配置文件 在我们使用系统的过程中，有时候需要把不用的软件给卸载掉。若你无需再次安装该软件，可以把软件的配置文件也清理掉，此时在卸载软件的时候，尽可能使用 1sudo apt purge xxxxx（xxxx为要卸载的软件名） 这样可以将软件以及它的配置文件均卸载干净。不过由于这样或那样的原因，系统中有时候会残留下某些已卸载软件的配置文件。如果想清除掉这些残留的配置文件，我们可以使用一款常见的软件来完成 —— 新力得软件包管理器（synaptic）来清除已卸载软件的残留配置文件。 这个方法适用于多种 Ubuntu 以及 Debian 系的 Linux 系统，如 Mint 以及深度 Linux 系统。"},{"title":"CENTOS8 宝塔下安装 aria2 和 AriaNg 添加 HTTPS 访问支持","path":"/article/install-aria2-and-ariang-is-ssl/","text":"首先你安装得有一台安装了 CENTOS7 的 KVM 架构的 vps，安装宝塔完毕。 首先安装 ARIA2，这个我们直接用某大佬的一键脚本吧： 1wget -N –no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubiBackup/doubi/master/aria2.sh &amp;&amp; chmod +x aria2.sh &amp;&amp; bash aria2.sh 安装完毕后，会展示出你的服务器地址，你的 NPC 访问密码，端口和默认下载目录。 宝塔里面创建站点，比如创建 https://download.shiux.com/（如果你懒得折腾，而且也愿意用安全的 HTTPS 走你的数据，你直接用我搭建的 AriaNg 前端访问即可，后面都不用看了，填写你的 ARIA2 配置信息即可，反正这个只有你自己填写好你的 NPC 密码，服务器地址，端口等信息后才可以用，而且服务端不会有任何记录） 为了自己的数据传输安全，在宝塔后台申请 Let’s Encrypt 的证书，这个简单，只要你的域名提前做好解析，填写好邮箱，很快就可以申请成功。 去宝塔的后台界面远程下载 AriaNg 下载地址 - https://github.com/mayswind/AriaNg/releases 下载完成后，宝塔后台就可以解压缩，解压缩到根目录。 现在问题来了，你用你创建好的 download.shiux.com 在浏览器里访问，填写我们前面安装 aria2 的 NPC 密码后依然显示未连接。原因？就是因为我们需要更改 ARIA2 的配置文件。 1vi /root/.aria2/aria2.conf 找到，没有可以自行添加到配置文件。 123456#是否启用RPC服务的SSL/TLS加密#rpc-secure=true#申请的域名crt证书文件路径，自行修改#rpc-certificate=/root/xxx.crt##申请的域名key证书文件路径，自行修改#rpc-private-key=/root/xxx.key 首先把上述三行的注释去掉，开启 HTTPS 访问支持，关键是下面两个证书文件路径，哪里找，其实你的站点配置信息里面有，如果你的宝塔安装的是 nginx，在你的站点 nginx 配置文件中包含路径。进入宝塔后台，站点设置里面找到 nginx 配置： 找到： 12ssl_certificate /www/server/panel/vhost/cert/aria2.zhanghaitao.com/fullchain.pem;ssl\\_certificate\\_key /www/server/panel/vhost/cert/aria2.zhanghaitao.com/privkey.pem 先别急，你如果直接填写这两个文件地址不会成功，我在这里耽误了 3 个小时才折腾完毕，记得谢我，评论区见。需要把 privkey.pem 用 openssl 转换一下，进入这个目录： 12cd /www/server/panel/vhost/cert/download.shiux.com/openssl rsa -in privkey.pem -out privkey.key 转换完成后，你得到了 privkey.key 这个文件： 1vi /root/.aria2/aria2.conf 编辑为： 123456# 启用加密后 RPC 服务需要使用 https 或者 wss 协议连接rpc-secure=true# 在 RPC 服务中启用 SSL/TLS 加密时的证书文件(.pem/.crt)rpc-certificate=/www/server/panel/vhost/cert/aria2.shiux.com/fullchain.pem# 在 RPC 服务中启用 SSL/TLS 加密时的私钥文件(.key)rpc-private-key=/www/server/panel/vhost/cert/aria2.shiux.com/privkey.key 重新启动 ARIA2 1service aria2 restart 再访问你的 AriaNg 你会发现连接成功，尽情享受吧：）"},{"title":"使用宝塔面板和 NextCloud 搭建私有云 / 网盘图文教程","path":"/article/build-nextcloud-by-bt-panel/","text":"NextCloud 是一款自由 (开源) 的类 Dropbox 软件，由 ownCloud 分支演化形成。它使用 PHP 和 JavaScript 编写，支持多种数据库系统，比如 MySQL/MariaDB、PostgreSQL、OracleDatabase 和 SQLite。它可以使你的桌面系统和云服务器中的文件保持同步，NextCloud 为 Windows、Linux、Mac、安卓以及苹果手机都提供了客户端支持。 NextCloud 并非只是 Dropbox 的克隆，它还提供了很多附加特性，如日历、联系人、计划任务以及流媒体 Ampache。 在这篇文章中，我将向你展示如何在宝塔面板服务器中安装和配置最新版本的 NextCloud 18.1。我会通过 Nginx 和 PHP7-FPM 来运行 NextCloud，同时使用 MariaDB 做为数据库系统。 安装 NextCloud 的过程 提前把域名解析到 vps 的 IP。 使用宝塔面板（宝塔面板官方网址：点我进入）搭建好 php 环境，安装的时候选择 lnmp 环境，php7 以上版本速度更快，效率更高。 到这个地址 https://NextCloud.com/install/ 下载 NextCloud 最新安装文件，打开后点击 download，在弹窗中右键点击 Download NextCloud，复制链接地址。 进入宝塔面板后台 &gt;&gt; 文件，选择网站根目录，点击远程下载后在弹窗中粘贴上面的下载地址，点击确定开始下载。安装文件才 58M，几秒钟就下载完毕了。 刷新一下当前页面就看到下载后的 NextCloud 安装包了，在名字后面点击解压，会解压缩到 NextCloud 文件夹。进入这个文件夹，全选，剪切，回到网站根目录，粘贴所有（后台右上角），这样就把 NextCloud 的安装文件放到网站根目录了。 以上复制、剪切、粘贴的功能全都在宝塔面板后台的网页端完成的，不需要登陆服务器操作，确实很方便，即使没操作过的新手也能很快上手。 打开域名就看到了创建管理员账号界面，输入管理员账号密码，数据库名和密码，数据库用户名。点击 “安装完成”。 进入 NextCloud 后台界面。看到提示可以下载 PC 端、手机端、苹果系统的 app 使用。 进入 设置 -&gt; 概览 可以看到还有很多安全问题。 报错解决 采用 LAMP 架构安装 NextCloud 私有云盘是一个很简单的过程，但是由于是开源软件，难免会存在一些 BUG 和小问题，这里罗列了安装过程中可能会出现的一些问题并汇总，仅供参考。 先看一下我遇到的问题。 当时看到的时候头都大了，问题太多了，下面咱们来一一解决。 红色问题 您的数据目录和文件可以从互联网直接访问。.htaccess 文件不起作用。强烈建议您配置 Web 服务器，以便数据目录不再可访问，或者您可以将数据目录移动到 Web 服务器文档根目录。 解决方法是修改 NextCloud 绑定的网站配置文件，添加 NextCloud 常用目录禁止访问即可，加入下列代码 123location ~ ^/(?:build|tests|config|lib|3rdparty|templates|data) / { deny all;} 黄色问题 PHP 的安装似乎不正确，无法访问系统环境变量。getenv(\"PATH\") 函数测试返回了一个空值。请参照安装说明文档中的 PHP 配置说明查阅您服务器的 PHP 配置信息，特别是在使用 php-fpm 时。 从宝塔文件管理，打开 /www/server/php/74/etc/php-fpm.conf，在其尾部添加一行 1env[PATH] = /usr/local/bin:/usr/bin:/bin:/usr/local/php/bin 保存并重启 PHP 即可解决该问题。 PHP 内存限制低于建议值 512MB。 在宝塔 PHP 配置修改中把脚本运行内存修改为 512MB 以上就行。这里我修改为 1024MB。然后点击保存即可。 HTTP 请求头 \"X-Content-Type-Options\"没有配置为\"nosniff\"。这是一个潜在的安全或隐私风险，我们建议您调整这项设置。 浏览器会根据响应头的 Content-Type 字段来分辨它们的类型。例如：”text/html” 代表 html 文档，”image/png” 是 PNG 图片，”text/css” 是 CSS 样式文档。然而，有些资源的 Content-Type 是错的或者未定义。这时，某些浏览器会启用 MIME-sniffing 来猜测该资源的类型，解析内容并执行。设置为 nosniff 这个响应头则可以禁用浏览器的类型猜测行为 1add_header X-Content-Type-Options 'nosniff'; HTTP 头 “X-XSS-Protection” 未包含 “1; mode=block”。这是一种潜在的安全或隐私风险，因此推荐调整此项设置。 用于启用浏览器的 XSS 过滤功能，以防止 XSS 跨站脚本攻击。 1add_header X-XSS-Protection '1;mode=block'; 通过 HTTP 访问网站不安全。强烈建议您将服务器设置成要求使用 HTTPS 协议，请查阅安全贴士。 只需在宝塔面板中申请证书，并强制 HTTPS 即可。"},{"title":"CentOS8 64 位如何修改软件源","path":"/article/modify-software-source-in-centos-8-64-bit/","text":"备份，以免出错后可以恢复 1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载新的源文件 阿里云 wget 12345678# CentOS 5wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo# CentOS 6wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo# CentOS 7wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# CentOS 8wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo curl 12345678# CentOS 5curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo# CentOS 6curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo# CentOS 7curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# CentOS 8curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo USTC 1234567891011121314# CentOS7sudo sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://mirror.centos.org/centos|baseurl=https://mirrors.ustc.edu.cn/centos|g' \\ -i.bak \\ /etc/yum.repos.d/CentOS-Base.repo# CentOS8sudo sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=https://mirrors.ustc.edu.cn/centos|g' \\ -i.bak \\ /etc/yum.repos.d/CentOS-Linux-AppStream.repo \\ /etc/yum.repos.d/CentOS-Linux-BaseOS.repo \\ /etc/yum.repos.d/CentOS-Linux-Extras.repo \\ /etc/yum.repos.d/CentOS-Linux-PowerTools.repo \\ /etc/yum.repos.d/CentOS-Linux-Plus.repo 运行以下命令生成缓存 12yum clean allyum makecache"},{"title":"在本地搭建 Hexo 博客框架并部署到 GitHub","path":"/article/build-blog-website-by-hexo-github/","text":"简介 什么是 Hexo ？ Hexo 是一个快速、简单且强大的部落格框架。能够使用 Markdown 语法来新增文章，快速渲染你的文章，有强大的外挂系统及丰富的扩充性，简单易用，让你可以专注与写作中，不被複杂的操作影响写作的体验，对于习惯使用 Markdown 纪录内容的人可说是一大福音，可以套用主题让你的网页变得更加漂亮，重点来了！Hexo 是由台湾人制作的，官方文件都有中文语系的支援，更能降低入门的门槛。 官网 - http://hexo.io GitHub - https://github.com/hexojs/hexo 什么是 GitHub？ GitHub 是一个在线软件源代码托管服务平台，使用 Git 作为版本控制软件，由开发者 Chris Wanstrath、P. J. Hyett 和汤姆・普雷斯顿・沃纳使用 Ruby on Rails 编写而成。在 2018 年，GitHub 被微软公司收购。（维基百科） 官网 - https://github.com 前言 使用 GitHub Pages 服务搭建博客的好处有： 全是静态文件，访问速度快； 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于 GitHub 的； 数据绝对安全，基于 GitHub 的版本管理，想恢复到哪个历史版本都行； 博客内容可以轻松打包、转移、发布到其它平台； 等等； 准备工作 在开始一切之前，你必须已经： 有一个 GitHub 账号，没有的话去注册一个； 安装了 node.js、npm，并了解相关基础知识； 安装了 git for windows（或者其它 git 客户端） 本文所使用的环境： Windows10 node.js@12.14.1node.js@19.3.0 git@2.25.0git@2.39.0 hexo@3.9.0hexo@6.3.0 版本不同内容可能有删改，请酌情使用。 搭建 GitHub 博客 创建仓库 新建一个名为 [username].github.io 的仓库，比如说，如果你的 GitHub 用户名是 test，那么你就新建 test.github.io 的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 https://test.github.io 了，是不是很方便？ 新版 GitHub 将 Pages 功能分割了出来，现在不需要像 [username].github.com 这样设置仓库名了。 由此可见，每一个 GitHub 账户最多只能创建一个这样可以直接使用域名访问的仓库。 几个注意的地方： 注册的邮箱一定要验证，否则不会成功； 仓库名字必须是：username.github.io，其中 username 是你的用户名； 仓库创建成功不会立即生效，需要过一段时间，大概 10-30 分钟，或者更久，我的等了半个小时才生效； 创建成功后，默认会在你这个仓库里生成一些示例页面，以后你的网站所有代码都是放在这个仓库里啦。 安装 hexo 基本框架 新建文件夹 这一步是为了给你的博客找一个合适的位置。新建的文件夹的命名是随意的。如下图。 使用 VSCode 打开文件夹并新建终端 打开 VSCode-&gt; 打开文件夹 -&gt; 选择文件夹 -&gt; 点击打开 点击菜单栏中的终端 -&gt; 新终端 配置 SSH key 为什么要配置这个呢？因为你提交代码肯定要拥有你的 GitHub 权限才可以，但是直接使用用户名和密码太不安全了，所以我们使用 ssh key 来解决本地和服务器的连接问题。 1cd ~/. ssh #检查本机已存在的ssh密钥 如果提示：No such file or directory 说明你是第一次使用 git。 1ssh-keygen -t rsa -C \"邮件地址\" 然后连续 3 次回车，最终会生成一个文件在用户目录下，打开用户目录，找到.ssh\\id_rsa.pub 文件，记事本打开并复制里面的内容，打开你的 GitHub 主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key： 将刚复制的内容粘贴到 key 那里，title 随便填，保存。 测试是否成功 1ssh -T git@github.com # 注意邮箱地址不用改 如果提示 Are you sure you want to continue connecting (yes/no)?，输入 yes，然后会看到： Hi shiux! You’ve successfully authenticated, but GitHub does not provide shell access. 看到这个信息说明 SSH 已配置成功！ 此时你还需要配置： 12git config --global user.name \"shiux\" // 你的GitHub用户名，非昵称git config --global user.email \"xxx@qq.com\" // 填写你的GitHub注册邮箱 如果没有配置 git 的话 使用 hexo 写博客 原理 由于 GitHub Pages 存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，所以 hexo 所做的就是将这些 md 文件都放在本地，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到 GitHub。 注意事项 安装之前先来说几个注意事项： 很多命令既可以用 Windows 的 cmd 来完成，也可以使用 git bash 来完成，但是部分命令会有一些问题，为避免不必要的问题，建议全部使用 git bash 来执行； hexo 不同版本差别比较大，网上很多文章的配置信息都是基于 2.x 的，所以注意不要被误导； hexo 有 2 种_config.yml 文件，一个是根目录下的全局的_config.yml，一个是各个 theme 下的； 自 hexo5.x 以来，基本所有主题的配置文件都需要复制到根目录，为了好更新主题。 安装 1npm install hexo-cli -g 初始化 在电脑的某个地方新建一个名为 hexo 的文件夹（名字可以随便取），比如我的是 F:\\Workspaces\\blog，由于这个文件夹将来就作为你存放代码的地方，所以最好不要随便放。 12cd /f/Workspaces/blog/hexo init # 初始化项目 hexo 会自动下载一些文件到这个目录，包括 node_modules，目录结构如下图： 12hexo g # 生成hexo s # 启动服务 执行以上命令之后，hexo 就会在 public 文件夹生成相关 html 文件，这些文件将来都是要提交到 GitHub 去的： hexo s 是开启本地预览服务，打开浏览器访问 http://localhost:4000 即可看到内容。 修改主题 既然默认主题很丑，那我们别的不做，首先来替换一个好看点的主题。这是 https://hexo.io/themes/。 个人比较喜欢主题： Next - https://github.com/next-theme/hexo-theme-next 首先下载这个主题： 12cd /f/Workspaces/blog/git clone https://github.com/next-theme/hexo-theme-next.git themes/next 修改_config.yml 中的 theme: landscape 改为 theme: next，然后重新执行 hexo g 来重新生成。 如果出现一些莫名其妙的问题，可以先执行 hexo clean 来清理一下 public 的内容，然后再来重新生成和发布。 部署之前 在上传代码到 GitHub 之前，一定要记得先把你以前所有代码下载下来（虽然 GitHub 有版本管理，但备份一下总是好的），因为从 hexo 提交代码时会把你以前的所有代码都删掉。 部署到 GitHub 目前有两种方式进行部署。 使用 GitHub Workflows 进行部署（推荐） 在博客目录新建一个文件.github/workflows/deploy-blog.yml 写入以下内容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445name: 部署博客on: push: branches: # 确保这是你正在使用的分支名称 - mainjobs: deploy-gh-pages: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: fetch-depth: 0 # 如果你文档需要 Git 子模块，取消注释下一行 # submodules: true - name: 安装 pnpm uses: pnpm/action-setup@v2 with: version: 7 run_install: true - name: 设置 Node.js uses: actions/setup-node@v3 with: node-version: 18 cache: pnpm - name: 构建文档 env: NODE_OPTIONS: --max_old_space_size=8192 run: |- pnpm run build - name: 部署文档 uses: JamesIves/github-pages-deploy-action@v4 with: # 这是文档部署到的分支名称 branch: gh-pages folder: public 之后使用以下命令提交代码到 GitHub，之后 GitHub 会自动处理代码并部署到 gh-pages 分支。 123456git initgit add .git commit -m \"Init Blog\"git branch -M maingit remote add origin https://github.com/shiux/shiux.github.io.gitgit push -u origin main GitHub 开始自动部署。 本地插件部署（不推荐）。使用 hexo-deployer-git 插件部署 如果你一切都配置好了，发布上传很容易，一句 hexo d 就搞定，当然关键还是你要把所有东西配置好。 首先，ssh key 肯定要配置好。 其次，配置_config.yml 中有关 deploy 的部分： 正确写法： 1234deploy: type:&nbsp;git repository:&nbsp;git@github.com:shiux/shiux.github.io.git branch: main 错误写法： 1234deploy: type: github repository: https://github.com/shiux/shiux.github.io.git branch: main GitHub 将默认分支从 master 修改为了 main，注意分支选择。 后面一种写法是 hexo2.x 的写法，现在已经不行了，无论是哪种写法，此时直接执行 hexo d 的话一般会报如下错误： Deployer not found: GitHub 或者 Deployer not found: git 原因是还需要安装一个插件： 1npm install hexo-deployer-git --save 其它命令不确定，部署这个命令一定要用 git bash，否则会提示 Permission denied (public key). 打开你的 git bash，输入 hexo d 就会将本次有改动的代码全部提交，没有改动的不会。 开启 pages 功能 如果使用的是本地插件部署，选择 main 分支。 如果使用的是 GitHub 自动部署，选择 gh-pages 分支。 绑定域名 当然，你不绑定域名肯定也是可以的，就用默认的 xxx.github.io 来访问，如果你想更个性一点，想拥有一个属于自己的域名，那也是 OK 的。 首先你要注册一个域名，域名注册以前总是推荐去 godaddy，现在觉得其实国内的阿里云也挺不错的，价格也不贵，毕竟是大公司，放心！ 绑定域名分 2 种情况：带 www 和不带 www 的。 域名配置最常见有 2 种方式，CNAME 和 A 记录，CNAME 填写域名，A 记录填写 IP，由于不带 www 方式只能采用 A 记录，所以必须先 ping 一下 [username].github.io 的 IP，然后到你的域名 DNS 设置页，将 A 记录指向你 ping 出来的 IP，将 CNAME 指向 [username].github.io，这样可以保证无论是否添加 www 都可以访问，如下： 然后到你的 GitHub 项目根目录新建一个名为 CNAME 的文件（无后缀），里面填写你的域名，加不加 www 看你自己喜好，因为经测试： 如果你填写的是没有 www 的，比如 shiux.com，那么无论是访问 https://www.shiux.com 还是 https://shiux.com，都会自动跳转到 https://shiux.com 如果你填写的是带 www 的，比如 www.shiux.com，那么无论是访问 https://www.shiux.com 还是 https://shiux.com，都会自动跳转到 https://www.shiux.com 如果你填写的是其它子域名，比如 abc.shiux.com，那么访问 https://abc.shiux.com 没问题，但是访问 https://shiux.com，不会自动跳转到 https://abc.shiux.com 另外说一句，在你绑定了新域名之后，原来的 username.github.io 并没有失效，而是会自动跳转到你的新域名。 保留 CNAME、README.md 等文件 提交之后网页上一看，发现以前其它代码都没了，此时不要慌，一些非 md 文件可以把他们放到 source 文件夹下，这里的所有文件都会原样复制（除了 md 文件）到 public 目录的： 由于 hexo 默认会把所有 md 文件都转换成 html，包括 README.md，所有需要每次生成之后、上传之前，手动将 README.md 复制到 public 目录，并删除 README.html。 常用 hexo 命令 123456789101112131415161718# 常见命令hexo new \"postName\" #新建文章hexo&nbsp;new&nbsp;page&nbsp;\"pageName\"&nbsp;#新建页面hexo&nbsp;generate&nbsp;#生成静态页面至public目录hexo&nbsp;server&nbsp;#开启预览访问端口（默认端口4000，'ctrl&nbsp;+&nbsp;c'关闭server）hexo&nbsp;deploy&nbsp;#部署到GitHubhexo&nbsp;help&nbsp;&nbsp;#&nbsp;查看帮助hexo version&nbsp;&nbsp;#查看Hexo的版本# 缩写hexo n == hexo newhexo&nbsp;g&nbsp;==&nbsp;hexo&nbsp;generatehexo&nbsp;s&nbsp;==&nbsp;hexo&nbsp;serverhexo d == hexo deploy# 组合命令hexo s -g #生成并本地预览hexo d -g #生成并上传 _config.yml 这里面都是一些全局配置，每个参数的意思都比较简单明了，所以就不作详细介绍了。 需要特别注意的地方是，冒号后面必须有一个空格，否则可能会出问题。 写博客 定位到我们的 hexo 根目录，执行命令： hexo new 'my-first-blog' hexo 会帮我们在_posts 下生成相关 md 文件： 当然你也可以直接自己新建 md 文件，用这个命令的好处是帮我们自动生成了时间。 一般完整格式如下： 12345678title:&nbsp;postName # 文章页面上的显示名称，一般是中文date:&nbsp;2013-12-02&nbsp;15:30:16 # 文章生成时间，一般不改，当然也可以任意修改categories:&nbsp;默认分类 # 分类tags: # 文章标签，可空，多标签请用格式，注意:后面有个空格 - tag1 - tag2 - tag3description:&nbsp;附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面 以下是正文 那么 hexo new page 'postName' 命令和 hexo new 'postName' 有什么区别呢？ hexo new page 'my-second-blog' 最终部署时生成：hexo\\public\\my-second-blog\\index.html，但是它不会作为文章出现在博文目录。 写博客工具 那么用什么工具写博客呢？这个我还没去找，以前自己使用 editor.md 简单弄了个，大家有好用的 hexo 写博客工具可以推荐个。 如何让博文列表不显示全部内容 123456789## 简介### 什么是 Hexo ？Hexo 是一个快速、简单且强大的部落格框架。能够使用`Markdown`语法来新增文章，快速渲染你的文章，有强大的外挂系统及丰富的扩充性，简单易用，让你可以专注与写作中，不被複杂的操作影响写作的体验，对于习惯使用`Markdown`纪录内容的人可说是一大福音，可以套用主题让你的网页变得更加漂亮，重点来了！Hexo 是由台湾人制作的，官方文件都有中文语系的支援，更能降低入门的门槛。**官网** - &lt;http://hexo.io&gt;**GitHub** - &lt;https://github.com/hexojs/hexo&gt;"},{"title":"PHP 和 Node.js：哪个更好，为什么？","path":"/article/php-or-node-js-which-is-better-and-why/","text":"在过去的十年中，这项技术的发展速度前所未有。增长似乎不会停止，并且有望在我们所生活的世界中带来重大的转变。 该技术的基础是由多种语言构成的基础，这些语言将基于多种语言构建，以供不同用途使用。 此类结构平台的语言和开发在其重要性，易用性，性能，兼容性和执行性方面各不相同，因此应根据动机进行明智选择。 在技​​术开发和后端编程领域，Node.js 和 PHP 成为最广泛和最受欢迎的名称。 Node.js 是跨平台的开源 JavaScript 运行时环境，可在浏览器外部执行 JavaScript 代码。 另请阅读：Node.js Web App 开发的正面和负面方面 它是一个基于 Google Chrome 引擎的服务器端平台，用于开发快速且可扩展的网络应用程序。它快速，高度可扩展，克服了缓冲，异步和事件驱动的问题。 另一方面，PHP 是一种开放源代码服务器端脚本语言。根据 W3Tech 的一项调查，通常有 79％的网站是使用 PHP 开发的。 它最初被称为 “个人主页”，但现在被普遍称为 “超文本预处理器”。 一些有趣的事实 超过 244 + 百万个基于 PHP 的网站。 Node.js 于 2019 年 5 月庆祝成立 10 周年。 目前，美国约有 32,000 多个网站正在运行 Node.js。 Node.js 的有效率约为 96％，并帮助减少了 50-60％的网页加载时间。 Node.js 还通过平均降低 58％的成本并将应用程序性能提高约 50％来对成本产生重大影响。 Node.js 和 PHP 之间的相似之处 但是，这些语言在其用法和工作方面会有所不同，Node.js 和 PHP 都显示出一些共同的因素。 口译语言 Node.js 和 PHP 都是解释语言。相应的代码可以在相应的运行时环境中运行，并且也适合初学者和专家。 服务 两种语言都以某种方式用于处理 Web 请求。这些语言有效地处理了动态 Web 内容，并构成了交互式且用户友好的界面。两种语言被认为非常有效地用于为 Web 套接字提供服务。 兼容性 这些语言的最大优势之一是它们都与包括 Linux，macOS 和 Windows 在内的许多操作系统广泛兼容。它们都具有很高的适应性，并且可以轻松修改。 性能 这些语言的性能仅根据创建 Web 平台的目的和意图而有所不同。这些语言具有很高的可行性，并且可以根据各自的专业目的高效使用。 这两个平台在提供性能和预期目的方面都非常成功。 Node.js 和 PHP 之间的区别 PHP 和 Node.js 都为动态高效的平台提供了强大而强大的后端，但是在各自领域中存在各种差异。让我们看看如何。 JavaScript 隶属关系 Node.js 为开发人员提供了一个高效的环境，使开发人员可以使用脚本超越浏览器，并降低了 Flash 上​​Web 平台的可靠性。 另一方面，PHP 具有将内容从服务器传递到浏览器本身的基础。 复杂 与 Node.js 相比，对于初学者来说，这里的 PHP 似乎更容易使用，但是在谈论专业开发人员时，PHP 在比较中是平等的。 Node.js 不太复杂，无法使用，但是与 PHP 相比，它需要更多的代码才能工作。 执行 PHP 更像是一个基本平台，比 Node.js 执行开发的程序要慢，并且与 Node.js 相比，它的权重更高。 可移植性 PHP 作为一种开发 Web 程序的语言似乎具有很高的可移植性，并且可以与不同的操作系统兼容。 与 Node.js 相比，PHP 的虚拟主机更便宜且更易于访问。这也是 PHP 平台以 80％以上的内容统治 Web 的主要原因之一。 同步化 仅当当前行已执行时，一行一行地执行的代码才进入代码的下一行，这称为同步代码，而同时执行的代码称为异步代码。 PHP 是一种同步编码语言，而 Node.js 是一种异步编码语言。同步 Web 平台被认为对执行速度不太可行，异步 Web 平台被认为对提高程序的执行速度更可行。 构架 PHP 是一种流行的服务器端脚本平台语言，易于后端开发。 该语言有许多框架支持，即 Laravel，Codelgniter，Cakephp 等，这些框架非常高效，可用于 Web 程序的敏捷，健壮和安全的后端开发。 哪个更好：PHP 还是 Node.js？ 后端程序员经常被选为执行项目的最佳语言，在两者之间处于选择的困境。两种语言均可确保最终结果为开发人员和最终用户带来大量的 Web 编程经验。 与 Node.js 相比，PHP 的编码相对更快，更简单，因此一开始更具吸引力，并且似乎可以使用。 另一方面，Node.js 似乎是一种更复杂的语言。在 Node.js 的情况下，开发程序的部署是一个复杂且需要基础的项目。 两种语言都有各自的优缺点，如下所示： 许多托管平台都高度支持 PHP 语言，因此更易于使用并将托管部署到 Web 程序。另一方面，节点为此使用虚拟服务器。 但是，PHP 提供了所开发程序的可靠和稳定的性能。Node.js 速度很快，并为 Web 程序提供了快速的周转时间。 Node.js 是一个比 PHP 更灵活，可扩展的平台。它具有有限的边界和依存关系，这使得它在处理大型文件时更加灵活和容易。 尽管 Node.js 具有高响应能力和用户友好性，但它不太适合处理 CPU 密集型活动。 有时，Node.js 平台几乎不会面对的大量代码使 PHP 无法管理。 尾注 从 PHP 和 Node.js 之间的竞争可以看出，这两个平台似乎都有自己的优势，并且在专注于预期结果时很有优势。 选择语言时要问的主要问题是，哪种语言可以更好地用于实现目标，而不是质疑两种语言的工作效率和能力。 因此，我们在此得出的结论是，这两种语言都是可使用的绝佳平台，并带来了许多令人赞叹的收益。我们还发现谁是最有可能与相应语言兼容的人员和工作维度。 结论 没有一种语言比其他语言少。根据要交付的项目的目的和要求使用时，它们都有各自的用途。 这两个平台都以自己的方式高效且强大，但是它们的功能各不相同。它们具有相似之处和不同之处，可以满足不同项目的不同需求。 PHP 是比 Node.js 相对古老的语言，并且在开始阶段就更易于编码人员使用。但是，Node.js 迅速成为竞争中最可行的选择之一。"},{"title":"Node.js 对于基于微服务的应用程序开发有多好？","path":"/article/how-good-is-node-js-for-developing-apps-based-on-microservices/","text":"在不断发展的业务环境中，应用程序开发人员在将微服务集成到应用程序开发流程中的同时，享有多项明显的好处。 当您将 Node.js 连接到微服务时，项目工作流程将得到增强。在本文中，您将了解到在微服务上进行应用程序开发时 Node.js 的兼容性。 世界各地的开发人员都意识到 Node.js 的潜力。 目前，eBay 和 AliExpress 正在使用 Node.js 作为主要的后端语言。首先，您需要对 Node.js 和微服务有清晰的了解。 Node.js Node.js 是一个开放源代码，跨平台的环境和运行时库，旨在在浏览器之外运行用 JavaScript 编写的应用程序。它既不是编程语言，也不是框架。 开发人员主要在 Web 服务，移动应用程序和其他 API 等后端服务中使用 Node.js。Uber，PayPal，Wallmart 和 Netflix 等大公司一直在生产中使用此运行时环境。 微服务 另一方面，微服务是指软件设计模式。这种模式可以将大型应用程序分解为更简单和较小的应用程序的集合。这些应用程序可以单独测试，维护和部署。 此外，它们是根据特定的业务能力松散耦合和组织的。因此，可以将其视为开发软件的面向业务的方式。 微服务对应用开发者的重要性 问题 在大多数软件项目中，开发人员旨在从一开始就解决一个问题。当另一个问题浮出水面时，工程团队也会尝试解决它。项目的规模在不断扩大，没有解决所有问题。 这是整体式的发展。现有应用程序具有新功能，从而增加了整体复杂性。逐渐地，开发人员发现难以扩展项目，并且浪费了资源。 原因是，他们需要同时缩放每个功能。每次开发人员都需要更改几行代码，这使过程变得很困难。 开发人员发现无法应对微小变化的时候到了。添加新功能成为噩梦，并且该产品已过时。 解决方案 微服务旨在解决软件开发的这一问题。基于微服务架构的软件可以由几个较小的组件开发。这些部分可以协同工作，尽管开发人员可以单独构建它们。 此外，他们可以使用任何语言来实现它们。这表明开发人员可以自由使用任何技术，并且它们不限于任何特定的技术。 如果正确实施，微服务可能很小，以至于一个小团队可以在两周内重写它。如果性能似乎很差，那么很快就可以更换服务。 这导致开发风险以及与基础架构运营相关的成本大幅降低。最终，商业公司需要花费更少的钱以获得更好的性能。 微服务与 Node.js 之间的匹配 微服务与 Node.js 共享兼容的连接。应该注意的是，开发 Node 的核心动机是简化微服务上的应用程序开发过程。 因此，连接是明确的，因为运行时环境与软件设计模式完全匹配。这个想法是在开发 Node app 时要使用几个分散的小节点。随着应用程序的工作，这些节点相互通信。 显然，在过去的几年中，大型企业和初创企业都将 Node.js 用于基于微服务的应用程序。看起来开发人员对使用 Node 很满意，并且从提高生产率方面可以看出其受欢迎程度。 使用微服务的主要好处 开发人员了解，在构建应用程序时，技术并不总是很重要。与可用的技术功能相比，一些开发人员认为业务原理更为重要。 将微服务集成到应用程序开发流程中可以大大简化流程。在这里，您将了解微服务为开发人员提供的切实利益。 更好的结构 在结构良好的应用程序中，了解功能变得更加容易。这意味着开发人员必须相应地设计和实现这些功能。 在设计这些应用程序时，微服务会派上用场，从而为它们提供更好的结构。从实践上考虑，它需要较少的时间和金钱进行业务分析。因此，企业可以将资金用于开发过程本身。 无缝开发 有时，开发人员发现概念化，构建和维护复杂的应用程序非常困难。使用微服务，他们可以将它们分成更小的位。在此过程中，任务变得更加易于管理和简化。 更大的可扩展性 与在传统范例中开发的单片应用程序不同，微服务提供更大程度的可伸缩性。开发人员遇到困难的情况，试图扩大规模，因为该过程确实很耗时。 他们需要找出内部情况，这需要大量的努力。微服务使流程更简单，并增强了项目的可伸缩性。 错误更少 使用微服务最终可以减少错误数量。在这种情况下，微服务类似于句子，即人们可以避免错误的一口大小的技术。 因此，修复错误变得更加简单且耗时。目前，开发人员正在探索在应用程序开发期间集成微服务和 Node.js 的好处。 更好的性能 每个微服务都被赋予一个任务。开发人员可以无缝优化和调整它们。微服务的目的是刀对厨师。在竞争激烈的业务环境中，应用程序的性能对于建立业务竞争力大有帮助。 集成 Node.js 和微服务的好处 在业务价值方面，可以评估在应用程序开发过程中将 Node.js 和微服务集成在一起的好处。Node.js 中开发的面向微服务的应用程序具有许多好处。 简化工作流程开发 当工作流程开发得到简化时，开发人员不必干涉彼此的任务。他们只是在正在开发的应用程序的各个部分上工作。 如果在应用程序开发过程中使用整体程序，那么这个问题就会成为一个障碍。Node.js 的优势在于它可以简化工作流程。 由于几个小部分组成了大型应用程序，因此开发人员可以分别处理较小的应用程序，而不是整个遇到问题。 提高生产力 Node.js 有一个程序包管理器，其中包含几个模块，能够由开发人员立即使用。这为他们节省了应用开发过程中的大量工作。 此外，Node.js 中的应用程序是用 JavaScript 编写的。这使得前端开发人员可以很容易地理解发生了什么。因此，他们在应用程序中进行了所需的更改。 整个堆栈中可以使用一种语言。此外，开发人员可以在后端和前端使用相同的模块。这可以帮助他们节省大量时间，并在此过程中发挥生产力。 易于更新和维护 事实证明，执行维护活动更为简单，因为不会出现复杂的整体代码。因此，开发人员可以在应用程序中无缝编写新功能。 即使执行更新，他们也可以以增量方式增强系统，而不必花费巨额成本进行重写。随着应用程序获得面向服务的模块化结构，节点活动促进了这种方法。 资料复制 与 Node.js 完美结合的微服务需要数据复制。此外，开发人员可以从 NoSQL 数据库中受益。 实际上，这是表格式的传统数据库维护模型的替代方法。使用 Node.js，开发人员可以优化此功能的优势。它通常在市场上免费提供。 应用程序的可靠性和性能 在数字化环境中进行操作需要开发健壮的应用程序。这些应用程序的可靠性和性能在很大程度上取决于开发团队的能力。 使用 Node.js，开发人员可以开发出功能强大的应用程序，这些应用程序在性能和可靠性方面都可以实现。此外，他们可以无限扩展应用程序，并且过程不会混乱。 只要预算允许，开发人员就可以根据需要放大或缩小功能。在这种情况下，您应该专注于单线程异步体系结构，这是开发人员可以使用 Node 享受的功能。 当前，Node.js 是获取实时运行的 Web 应用程序的最佳解决方案。由于事件驱动和非阻塞 I / O 模型，这些应用以其高性能而著称。 与面向微服务的应用程序一起，Node 可以处理大量负载，尤其是在响应速度较慢的时候。在无缝集成 Node 和微服务时，仅需要 10％的硬件即可处理负载。 从图中可以明显看出 Node.js 的受欢迎程度。Node Foundation 透露，目前大约有 350 万用户正在使用 Node 开发应用程序，并且增长率为 100％。 在这种环境下，开发人员能够提出带有自定义功能的应用程序。显然，开发人员喜欢使用微服务来开发应用程序的 Node.js。 下一代开发人员在开发解决方案时可能会很大程度上依赖此平台。特别是，不愿意使用静态类型的 #C 语言的开发人员可以从此环境中受益。 结论 现在您可以了解为什么 Node.js 与微服务一起使用效果最佳。这就是开发人员喜欢在这样的环境中工作的原因。 借助微服务，他们可以享受多种好处，例如易于更新和开发，成本控制和轻松扩展。特别是在高流量条件下，微服务和 Node.js 可以完美同步。 创新型企业已经在使用这种微服务和 Node.js 的战术组合。他们能够提高生产率，同时将成本降至最低并实现高性能。开发人员很高兴将 Node.js 用于基于微服务的应用程序。"},{"title":"RHEL/CentOS 7 最小化安装后需做的 30 件事情","path":"/article/rhel-centos-7-after-installation/","text":"CentOS 是一个工业标准的 Linux 发行版，是红帽企业版 Linux 的衍生版本。你安装完后马上就可以使用，但是为了更好地使用你的系统，你需要进行一些升级、安装新的软件包、配置特定服务和应用程序等操作。 阅读帖子的时候请先完成 RHEL/CentOS 最小化安装，这是首选的企业和生产环境。如果还没有，你可以按照下面的指南，它会告诉你两者的最小化安装方法。 最小化安装 CentOS 7 最小化安装 RHEL 7 我们会基于工业标准的需求来介绍以下列出的这些重要工作。我们希望这些东西在你配置服务器的时候能有所帮助。 注册并启用红帽订阅 RHEL 7 最小化安装完成后，就应该注册并启用系统红帽订阅库，并执行一个完整的系统更新。这只当你有一个可用的红帽订阅时才能有用。你要注册才能启用官方红帽系统库，并时不时进行操作系统更新。（LCTT 译注：订阅服务是收费的） 这一步仅适用于有一个有效订阅的红帽企业版 Linux。如果你用的是 CentOS 服务器，请查看后面的章节。 使用静态 IP 地址配置网络 你第一件要做的事情就是为你的 CentOS 服务器配置静态 IP 地址、路由以及 DNS。我们会使用 ip 命令代替 ifconfig 命令。当然，ifconfig 命令对于大部分 Linux 发行版来说还是可用的，还能从默认库安装。 1yum install net-tools # [它提供ifconfig工具，如果你不习惯ip命令，还可以使用它] 但正如我之前说，我们会使用 ip 命令来配置静态 IP 地址。所以，确认你首先检查了当前的 IP 地址。 1ip addr show 现在用你的编辑器打开并编辑文件 /etc/sysconfig/network-scripts/ifcfg-enp0s3。 这里，我使用 vi 编辑器，另外你要确保你是 root 用户才能保存更改。 1vi /etc/sysconfig/network-scripts/ifcfg-enp0s3 我们会编辑文件中的四个地方。注意下面的四个地方并保证不碰任何其它的东西。也保留双引号，在它们中间输入你的数据。 1234IPADDR&nbsp;=&nbsp;\"[在这里输入你的静态&nbsp;IP]\"GATEWAY&nbsp;=&nbsp;\"[输入你的默认网关]\"DNS1&nbsp;=&nbsp;\"[你的DNS&nbsp;1]\"DNS2&nbsp;=&nbsp;\"[你的DNS&nbsp;2]\" 更改了 ifcfg-enp0s3 之后，它看起来像下面的图片。注意你的 IP，网关和 DNS 可能会变化，请和你的 ISP (译者注：互联网服务提供商，即给你提供接入的服务的电信或 IDC) 确认。保存并退出。 重启网络服务并检查 IP 是否和分配的一样。如果一切都顺利，用 Ping 查看网络状态。 1service network restart 重启网络后，确认检查了 IP 地址和网络状态。 12ip addr showping -c4 google.com 设置服务器的主机名称 下一步是更改 CentOS 服务器的主机名称。查看当前分配的主机名称。 1echo $HOSTNAME 要设置新的主机名称，我们需要编辑 /etc/hostsname 文件并用想要的名称替换旧的主机名称。 1vi /etc/hostname 设置完了主机名称之后，务必注销后重新登录确认主机名称。登录后检查新的主机名称。 1echo $HOSTNAME 你也可以用 hostname 命令查看你当前的主机名。 1hostname 更新或升级最小化安装的 CentOS 这样做除了更新安装已有的软件最新版本以及安全升级，不会安装任何新的软件。总的来说更新（update）和升级（upgrade）是相同的，除了事实上升级 = 更新 + 更新时进行废弃处理。 1yum update &amp;&amp; yum upgrade 你也可以运行下面的命令，这不会弹出软件更新的提示，你也就不需要输入‘y’接受更改。 然而，查看服务器上会发生的变化总是一个好主意，尤其是在生产中。因此使用下面的命令虽然可以为你自动更新和升级，但并不推荐。 1yum -y update &amp;&amp; yum -y upgrade 安装命令行 Web 浏览器 大部分情况下，尤其是在生产环境中，我们通常用没有 GUI 的命令行安装 CentOS，在这种情况下我们必须有一个能通过终端查看网站的命令行浏览工具。为了实现这个目的，我们打算安装名为 links 的著名工具。 1yum install links` 安装 Apache HTTP 服务器 不管你因为什么原因使用服务器，大部分情况下你都需要一个 HTTP 服务器运行网站、多媒体、用户端脚本和很多其它的东西。 1yum install httpd 如果你想更改 Apache HTTP 服务器的默认端口号 (80) 为其它端口，你需要编辑配置文件 /etc/httpd/conf/httpd.conf 并查找以下面开始的行： LISTEN 80 把端口号 80 改为其它任何端口 (例如 3221)，保存并退出。 增加刚才分配给 Apache 的端口通过防火墙，然后重新加载防火墙。 允许 http 服务通过防火墙 (永久)。 1firewall-cmd –add-service=http 允许 3221 号端口通过防火墙 (永久)。 1firewall-cmd –permanent –add-port=3221/tcp 重新加载防火墙。 1firewall-cmd –reload 完成上面的所有事情之后，是时候重启 Apache HTTP 服务器了，然后新的端口号才能生效。 1systemctl restart httpd.service 现在添加 Apache 服务到系统层使其随系统自动启动。 12systemctl start httpd.servicesystemctl enable httpd.service 如下图所示，用 links 命令行工具验证 Apache HTTP 服务器。 1links 127.0.0.1`"},{"title":"你家宽带是公网 IP 还是内网 IP，两者体验大不同！","path":"/article/public-ip/","text":"“提速降费” 已经喊了很长时间，很多用户家里都升级安装了百兆宽带，再也不会出现一人看电影，全家缓冲的情况了。 不过随着办理宽带用户的增加，公网 IP 使用分配也已逐渐告罄，很多网民都在抱怨：“自家的公网 IP，被偷偷换为内网 IP” 今天我们就来聊一聊公网 IP 和内网 IP 的使用体验都有哪些不同？ 什么是内网 IP、公网 IP？ 内网 IP： 由图可以看到路由器（第一层），交换机（第二层）然后是自己的电脑，所谓的内网就是从路由器以下开始的。我们内网用户的电脑都是经过交换机和路由器之后才能连到外网。 路由器只需一个公网 IP 就可以供下面多个电脑联网使用。由于不同的内网 IP 能够重复使用。所以内网 IP 通常有以下类型： 10.0.0.0~10.255.255.255 172.16.0.0~172.31.255.255 192.168.0.0~192.168.255.255 这些 IP 就是内网 IP，其中你家的 IP 是否也在其中呢？ 公网 IP： 拥有公网 IP，用户就无需经过路由器或交换机，直接可以上网。除此之外，还能够直接被外界所访问到，无需经如何设备，直接连接电脑。 如何辨别自家网络是公网 IP 呢？其实除了上文中提到的内网 IP，其余基本都是公网 IP。 公网 IP 有什么好处呢？ 其实最早我们使用的网络都是公网 IP，但是随着电脑的普及，运营商没有足够的公网 IPV4 地址分配给用户，所以只能偷偷的将公网 IP 换为内网 IP 分给多个用户使用，不过这也给用户使用体验造成了不少影响。 公网 IP 有更好的下载体验 相信不少用户都曾遇到过使用 P2P 下载电影、游戏资源，搜索不到资源或是下载速度慢的情况。如果拥有公网 IP，当进行 P2P 下载的时候，能够更快地找到其他节点，获取更多下载数据，下载速度更快，下载资源也不容易断流。如果是内网 IP，一些稍微 “冷门” 的资源可能根本无法下载。 公网 IP 更出色的互联体验 随着物联网的快速发展，很多智能设备都支持连接网络（智能电视、智能摄像头等），例如家中的智能安全摄像头，如果用户是公网 IP，用户可以直接通过公网 IP 连接，不经过任何第三方服务器，免去了泄露隐私的风险。 公网 IP 游戏体验更出色 如果你是一名主机玩家，肯定有过此类经历，一些游戏需要 NAT2 类型才能联机而 NAT3 则不能，还有如果在 Steam 上建主机玩救生之路 2，建好房间后发现别人都进不来。这就是内网 IP 和公网 IP 的区别。公网 IP 无需路由器或交换机转发，联机效率更高，而且有些游戏硬性跪地需要公网 IP 才能连接。 如何才能更换公网 IP? 用户如果对公网 IP 有必要需求，可以尝试联系自家网络运营商，可能有机会更换公网 IP，不过由于目前公网 IP（IPV4）基本已经分配完毕，使用出现枯竭，能够长期使用公网 IP 的可能非常渺小，只能希望 IPV6 技术的尽快普及，彻底解决公网 IP 枯竭的问题。"},{"title":"JS 的 Document 属性和方法","path":"/article/javascript-document/","text":"JS 的 Document 属性和调用方法 123456789101112document.title() //设置文档标题等价于HTML的title标签document.bgColor() //设置页面背景色document.fgColor() //设置前景色(文本颜色)document.linkColor() //未点击过的链接颜色document.alinkColor() //激活链接(焦点在此链接上)的颜色document.vlinkColor() //已点击过的链接颜色document.URL() //设置URL属性从而在同一窗口打开另一网页document.fileCreatedDate() //文件建立日期，只读属性document.fileModifiedDate() //文件修改日期，只读属性document.charset() //设置字符集 简体中文:gb2312document.fileSize() //文件大小，只读属性document.cookie() //设置和读出cookie 常用对象方法 12345document.write() //动态向页面写入内容document.createElement(Tag) //创建一个html标签对象document.getElementById(ID) //获得指定ID值的对象document.getElementsByName(Name) //获得指定Name值的对象document.body.appendChild(oTag) body- 主体子对象 1234567891011121314document.body //指定文档主体的开始和结束等价于&lt;body&gt;&lt;/body&gt;document.body.bgColor //设置或获取对象后面的背景颜色document.body.link //未点击过的链接颜色document.body.alink //激活链接(焦点在此链接上)的颜色document.body.vlink //已点击过的链接颜色document.body.text //文本色document.body.innerText //设置&lt;body&gt;…&lt;/body&gt;之间的文本document.body.innerHTML //设置&lt;body&gt;…&lt;/body&gt;之间的HTML代码document.body.topMargin //页面上边距document.body.leftMargin //页面左边距document.body.rightMargin //页面右边距document.body.bottomMargin //页面下边距document.body.background //背景图片document.body.appendChild(oTag) //动态生成一个HTML对象 常用对象事件 123document.body.onclick=\"func()\" //鼠标指针单击对象是触发document.body.onmouseover=\"func()\" //鼠标指针移到对象时触发document.body.onmouseout=\"func()\" //鼠标指针移出对象时触发 location- 位置子对象 123456789101112document.location.hash // #号后的部分document.location.host // 域名+端口号//好像返回的是主机名localhost,没有返回端口号document.location.hostname // 域名document.location.href // 完整URLdocument.location.pathname // 目录部分document.location.port // 端口号document.location.protocol // 网络协议(http:)document.location.search // ?号后的部分document.location.reload() //刷新网页document.location.reload(URL) //打开新的网页document.location.assign(URL) //打开新的网页document.location.replace(URL) //打开新的网页 selection- 选区子对象 document.selection() selection 的 createRange 方法 document.selection.createRange() 根据当前文字选择返回 TextRange 对象，或根据控件选择返回 ControlRange 对象。配合 execCommand，在 HTML 编辑器中很有用，比如：文字加粗、斜体、复制、粘贴、创建超链接等。这些好像都是只有在 IE 下才能实现。。 images 集合 (页面中的图象) 通过集合引用 1234document.images //对应页面上的img标签document.images.length //对应页面上img标签的个数document.images[0] //第1个img标签document.images[i] //第i-1个img标签 通过 name 属性直接引用 12img.name=\"oImage\"document.images.oImage //document.images.name属性 引用图片的 src 属性 1document.images.oImage.src //document.images.name属性.src 创建一个图象 1234var oImageoImage = new Image()document.images.oImage.src=\"1.jpg\"// 同时在页面上建立一个`img`标签与之对应就可以显示 forms 集合 (页面中的表单) 通过集合引用 123456document.forms //对应页面上的form标签document.forms.length //对应页面上/formform标签的个数document.forms[0] //第1个/formform标签document.forms[i] //第i-1个/formform标签document.forms[i].length //第i-1个/formform中的控件数document.forms[i].elements[j] //第i-1个/formform中第j-1个控件 通过标签 name 属性直接引用 123456&lt;form name=\"Myform\"&gt; &lt;input name=\"myctrl\"/&gt;&lt;/form&gt;&lt;script&gt; document.Myform.myctrl() //document.表单名.控件名&lt;/script&gt; 访问表单的属性 12345678910111213document.forms[i].name // 对应form name&gt;属性document.forms[i].action // 对应/formform action&gt;属性document.forms[i].encoding // 对应/formform enctype&gt;属性document.forms[i].target // 对应/formform target&gt;属性document.forms[i].appendChild(oTag) // 动态插入一个控件document.all.oDiv // 引用图层oDivdocument.all.oDiv.style.display=\"\" // 图层设置为可视document.all.oDiv.style.display=\"none\" // 图层设置为隐藏document.getElementId(\"oDiv\") // 通过getElementId引用对象document.getElementId(\"oDiv\").style=\"\"document.getElementId(\"oDiv\").display=\"none\"/*document.all表示document中所有对象的集合只有ie支持此属性，因此也用来判断浏览器的种类*/ 图层对象的 4 个属性 1234document.getElementById(\"ID\").innerText // 动态输出文本document.getElementById(\"ID\").innerHTML // 动态输出HTMLdocument.getElementById(\"ID\").outerText // 同innerTextdocument.getElementById(\"ID\").outerHTML // 同innerHTML"},{"title":"JetBrains 全系列软件激活教程","path":"/article/jetbrains-crack/","text":"无限重置试用 写在前面 永久激活的工具 zhile 的大神已经不再继续开发维护了，此方法一直是跳转到 zhili 的主页，但是经常遇到反馈说目标网站打不开或者不知道怎么安装插件的问题，所以直接转到这个页面并配一下操作图片吧。另外目前只有这种无限重置试用的方法了，最终和永久激活使用无差异，因为插件是每次运行自动续期的！支持 JetBrains 系列软件的所有新旧版本的激活！！！建议大家去 JetBrains 官网下载 JetBrains 系列工具的官方版，一般情况下载很快的。 此方法也适用于 MacOS。 背景 JetBrains 家的产品有一个很良心的地方，他会允许你试用 30 天（这个数字写死在代码里了）以评估是否你真的需要为它而付费。但很多时候会出现一种情况： IDE 并不能按照我们实际的试用时间来计算。 我举个例子： 如果我们开始了试用，然后媳妇生孩子要你回去陪产！陪产时我们并无空闲对 IDE 试用评估，它依旧算试用时间。（只是举个例子，或许你并没有女朋友） 发现了吗？你未能真的有 30 天来对它进行全面的试用评估，你甚至无法作出是否付费的决定。此时你会想要延长试用时间，然而 JetBrains 并未提供相关功能，该怎么办？ 事实上有一款插件可以实现这个功能，你或许可以用它来重置一下试用时间。但切记不要无休止的一直试用，这并不是这个插件的初衷！ 如何安装 提供以下两种方法，二选一即可。 插件市场安装： 在 Settings/Preferences... -&gt; Plugins 内手动添加第三方插件仓库地址：https://plugins.zhile.io 搜索： IDE Eval Reset 插件进行安装。 手动下载安装： 点击这个链接 (v2.2.3) 下载插件的 zip 包（macOS 可能会自动解压，切记使用的是 zip 包，不是解压后的文件夹！），然后打开 Settings/Preferences... -&gt; Plugins 手动安装插件。 如何使用 一般来说，在 IDE 窗口切出去或切回来时（窗口失去 / 得到焦点）会触发事件，检测是否长时间（25 天）没有重置，给通知让你选择。（初次安装因为无法获取上次重置时间，会直接给予提示）。 您也可以手动唤出插件的主界面： 如果 IDE 没有打开项目，在 Welcome 界面点击 IDE 的菜单：Get Help -&gt; Eval Reset 如果 IDE 打开了项目，点击 IDE 的菜单：Help -&gt; Eval Reset 唤出的插件主界面中包含了一些显示信息，有 2 个按钮和 1 个勾选项： 按钮：Reload 用来刷新界面上的显示信息。 按钮：Reset 点击会询问是否重置试用信息并重启 IDE。选择 Yes 则执行重置操作并重启 IDE 生效，选择 No 则什么也不做。（此为手动重置方式） 勾选项：Auto reset before per restart 如果勾选了，则自勾选后每次重启 / 退出 IDE 时会自动重置试用信息，你无需做额外的事情。（此为自动重置方式，推荐此方法！） 如何更新 插件更新机制（推荐）： IDE 会自行检测其自身和所安装插件的更新并给予提示。如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新。 点击 IDE 的 Check for Updates… 菜单手动检测 IDE 和所安装插件的更新。如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新。 插件更新可能会需要重启 IDE。 手动更新： 从本页面下载最新的插件 zip 包安装更新。插件更新需要重启 IDE。 一些说明 市场付费插件的试用信息也会一并重置。 MyBatisCodeHelperPro 插件有两个版本如下，功能完全相同，安装时须看清楚！ MyBatisCodeHelperPro (Marketplace Edition)，可重置！ MyBatisCodeHelperPro，不可重置！ 对于某些付费插件（如：Iedis 2, MinBatis）来说，你可能需要去取掉 javaagent 配置（如果有）后重启 IDE： 如果 IDE 没有打开项目，在 Welcome 界面点击菜单：Configure -&gt; Edit Custom VM Options... -&gt; 移除 -javaagent: 开头的行。 如果 IDE 打开了项目，点击菜单：Help -&gt; Edit Custom VM Options... -&gt; 移除 -javaagent: 开头的行。 重置需要重启 IDE 生效！ 重置后并不弹出 Licenses 对话框让你选择输入 License 或试用，这和之前的重置脚本 / 插件不同（省去这烦人的一步）。 如果长达 25 天不曾有任何重置动作，IDE 会有通知询问你是否进行重置。 如果勾选： Auto reset before per restart，重置是静默无感知的。 简单来说： 勾选了 Auto reset before per restart 则无需再管，一劳永逸。 开源信息 插件是学习研究项目，源代码是开放的。 Gitee - https://gitee.com/pengzhile/ide-eval-resetter 如果你有更好的想法，欢迎给我提 Pull Request 来共同研究完善。 插件源码使用： GPL-2.0 开源协议发布。 插件使用 PHP 编写，毕竟 PHP 是世界上最好的编程语言！ 支持的产品 IntelliJ IDEA AppCode CLion DataGrip GoLand PhpStorm PyCharm Rider RubyMine WebStorm 原文地址 - https://zhile.io/2020/11/18/jetbrains-eval-reset-da33a93d.html 中文汉化包 JetBrains 系列大部分在官方的插件中心直接安装使用了。 以 WebStorm 为例，打开它的设置，点击 Plugins，搜索 chinese，安装即可。 激活码 目前全网 JetBrains 全家桶激活码激活方式都不稳定，请使用无限重置试用的方法。"},{"title":"阿里巴巴矢量图批量下载","path":"/article/iconfont-all-download/","text":"在阿里巴巴矢量图标库中找到一个喜欢的图标库，想要全部下载，但是发现需要挨个点击添加购物车中，如下图所示，居然没找一个可以全选的按钮！！总之不知道为啥要这样设计吧。但是确实很不方便。 想要全选的话，操作如下 按下 F12 或者打开浏览器开发者模式 进入 console 的窗口 输入下列代码，然后回车 1234const iconList = document.querySelectorAll('.icon-gouwuche1');for (let i = 0; i &lt; iconList.length; i++) { iconList[i].click();} 完成，即可进入购物车中查看自己添加的图标。"},{"title":"PHP 环境搭建","path":"/article/php-environment-building/","text":"XAMPP 简介 XAMPP（Apache+MySQL/MariaDB+PHP+Perl） 开头的 X 代表 X-OS，代表可以在任何常见操作系统下使用，包括 Windows、Mac、Linux，开源平台。 XAMPP（Apache+MySQL+PHP+PERL）是一个功能强大的建站集成软件包。这个软件包原来的名字是 LAMPP，但是为了避免误解，最新的几个版本就改名为 XAMPP 了。它可以在 Windows、Linux、Solaris、Mac OS X 等多种操作系统下安装使用，支持多语言：英文、简体中文、繁体中文、韩文、俄文、日文等。 许多人通过他们自己的经验认识到安装 Apache 服务器是件不容易的事儿。如果您想添加&nbsp;MySQL、PHP 和 Perl，那就更难了。XAMPP 是一个易于安装且包含 MySQL、PHP 和 Perl 的 Apache 发行版。XAMPP 的确非常容易安装和使用：只需下载，解压缩，启动即可。 官网 - https://www.apachefriends.org/zh_cn/index.html 上面的是官方地址，100 多 M，很快就下好了。 安装 XMAPP 首先我在 D 盘创建了一个文件夹 XMAPP，然后在 XMAPP 创建了三个文件夹。 package 目录存放软件安装包 path 目录存放软件安装目录 virtualhost 目录是虚拟主机，也就是应用目录 首先下载好 XMAPP，放到一个位置，我放在 D:\\XAMPP\\package 这个位置的。 然后双击，进入安装界面，一直 next…。 我将安装路径选择了 D:\\XAMPP\\path 直到安装完毕是这个样子的。 配置虚拟主机 然后我在 D:\\XMAPP\\virtualhost 中新建了一个文件 index.php 很简单的一个函数，就当做首页了吧 找到 XAMPP的安装目录==&gt;apache==&gt;conf==&gt;extra 然后用编辑器打开 httpd-vhosts.conf 在文件的最下面写如下代码： 123456789101112&lt;VirtualHost *:80&gt; ServerName ceshi.com DocumentRoot \"D:/XAMPP/virtualhost\" &lt;Directory \"D:/XAMPP/virtualhost\"&gt; Options FollowSymLinks IncludesNOEXEC Indexes DirectoryIndex index.html index.htm index.php AllowOverride all Order Deny,Allow Allow from all Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; 修改 hosts 文件 进入 C盘==&gt;Windows==&gt;system32==&gt;drivers==&gt;etc==&gt;hosts 文件 在 hosts 文件添加一行配置即可 ==&gt;127.0.0.1 主机名 测试是否 XAMPP 成功运行 先打开 Apache 在浏览器中输入 主机名 ==&gt; 我的主机名为：localhost 现在 XAMPP 就安装并配置好了。"}]